{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from module.prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL = '../input/m5-forecasting-accuracy/'\n",
    "STORES_IDS = pd.read_csv(ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "STORES_IDS = list(STORES_IDS.unique())\n",
    "FINAL_TARGETS = 'sales'\n",
    "SAV_BASE_PATH = '../cache/ver2'\n",
    "PKL_BASE_PATH = '../cache'\n",
    "START_TRAIN = 0\n",
    "END_TRAIN = 1913\n",
    "P_HORIZON = 28\n",
    "SEED = 42\n",
    "VER = 2\n",
    "LGB_PARAMS = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'regression',\n",
    "                    # 'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.5,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 2**11-1,\n",
    "                    'min_data_in_leaf': 2**12-1,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'max_bin': 100,\n",
    "                    'n_estimators': 1400,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                } \n",
    "\n",
    "CAT_COLUMNS = [\n",
    "    'item_id',\n",
    " 'dept_id',\n",
    " 'cat_id',\n",
    " 'event_name_1',\n",
    " 'event_type_1',\n",
    " 'event_name_2',\n",
    " 'event_type_2',\n",
    " 'snap_CA',\n",
    " 'snap_TX',\n",
    " 'snap_WI'\n",
    "]\n",
    "\n",
    "NUM_COLUMNS = [\n",
    " 'release',\n",
    " 'sell_price',\n",
    " 'price_max',\n",
    " 'price_min',\n",
    " 'price_std',\n",
    " 'price_mean',\n",
    " 'price_norm',\n",
    " 'price_nunique',\n",
    " 'item_nunique',\n",
    " 'price_momentum',\n",
    " 'price_momentum_m',\n",
    " 'price_momentum_y',\n",
    " 'tm_d',\n",
    " 'tm_w',\n",
    " 'tm_m',\n",
    " 'tm_y',\n",
    " 'tm_wm',\n",
    " 'tm_dw',\n",
    " 'tm_w_end',\n",
    " 'enc_store_id_cat_id_mean',\n",
    " 'enc_store_id_cat_id_std',\n",
    " 'enc_store_id_dept_id_mean',\n",
    " 'enc_store_id_dept_id_std',\n",
    " 'enc_store_id_item_id_mean',\n",
    " 'enc_store_id_item_id_std',\n",
    " 'enc_store_id_tm_dw_item_id_mean',\n",
    " 'enc_store_id_tm_dw_item_id_std',\n",
    " 'enc_store_id_tm_dw_mean',\n",
    " 'enc_store_id_tm_dw_std',\n",
    " 'rolling_mean_7',\n",
    " 'rolling_std_7',\n",
    " 'rolling_mean_14',\n",
    " 'rolling_std_14',\n",
    " 'rolling_mean_30',\n",
    " 'rolling_std_30',\n",
    " 'rolling_mean_60',\n",
    " 'rolling_std_60',\n",
    " 'rolling_mean_180',\n",
    " 'rolling_std_180']\n",
    "\n",
    "########################### set seed\n",
    "#################################################################################\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "########################### Train Models\n",
    "#################################################################################\n",
    "def train_model(grid_df, features_columns, categorical_features, target, shift, save_base_path):\n",
    "    \n",
    "    for store_id in STORES_IDS:\n",
    "        print('Train', store_id)\n",
    "        train_mask = (grid_df['d'] > START_TRAIN) & (grid_df['d'] <= (END_TRAIN - P_HORIZON))\n",
    "        valid_mask = (grid_df['d'] > (END_TRAIN - P_HORIZON - 200)) & (grid_df['d'] <= (END_TRAIN))\n",
    "        train_data = lgb.Dataset(grid_df[train_mask][features_columns+categorical_features], label=grid_df[train_mask][target])\n",
    "        valid_data = lgb.Dataset(grid_df[valid_mask][features_columns+categorical_features], label=grid_df[valid_mask][target])\n",
    "        seed_everything(SEED)\n",
    "        estimator = lgb.train(LGB_PARAMS, train_data, valid_sets=[valid_data], verbose_eval=100, categorical_feature=categorical_features)\n",
    "        model_name = f'{save_base_path}/lgb_model_{store_id}_shift{shift}_v{VER}.bin'\n",
    "        pickle.dump(estimator, open(model_name, 'wb'))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46881677 entries, 0 to 46881676\n",
      "Data columns (total 44 columns):\n",
      " #   Column                           Dtype   \n",
      "---  ------                           -----   \n",
      " 0   id                               category\n",
      " 1   item_id                          category\n",
      " 2   dept_id                          category\n",
      " 3   cat_id                           category\n",
      " 4   store_id                         category\n",
      " 5   state_id                         category\n",
      " 6   d                                int16   \n",
      " 7   sales                            float64 \n",
      " 8   release                          int16   \n",
      " 9   sell_price                       float16 \n",
      " 10  price_max                        float16 \n",
      " 11  price_min                        float16 \n",
      " 12  price_std                        float16 \n",
      " 13  price_mean                       float16 \n",
      " 14  price_norm                       float16 \n",
      " 15  price_nunique                    float16 \n",
      " 16  item_nunique                     int16   \n",
      " 17  price_momentum                   float16 \n",
      " 18  price_momentum_m                 float16 \n",
      " 19  price_momentum_y                 float16 \n",
      " 20  event_name_1                     category\n",
      " 21  event_type_1                     category\n",
      " 22  event_name_2                     category\n",
      " 23  event_type_2                     category\n",
      " 24  snap_CA                          category\n",
      " 25  snap_TX                          category\n",
      " 26  snap_WI                          category\n",
      " 27  tm_d                             int8    \n",
      " 28  tm_w                             int8    \n",
      " 29  tm_m                             int8    \n",
      " 30  tm_y                             int8    \n",
      " 31  tm_wm                            int8    \n",
      " 32  tm_dw                            int8    \n",
      " 33  tm_w_end                         int8    \n",
      " 34  enc_store_id_cat_id_mean         float16 \n",
      " 35  enc_store_id_cat_id_std          float16 \n",
      " 36  enc_store_id_dept_id_mean        float16 \n",
      " 37  enc_store_id_dept_id_std         float16 \n",
      " 38  enc_store_id_item_id_mean        float16 \n",
      " 39  enc_store_id_item_id_std         float16 \n",
      " 40  enc_store_id_tm_dw_item_id_mean  float16 \n",
      " 41  enc_store_id_tm_dw_item_id_std   float16 \n",
      " 42  enc_store_id_tm_dw_mean          float16 \n",
      " 43  enc_store_id_tm_dw_std           float16 \n",
      "dtypes: category(13), float16(20), float64(1), int16(3), int8(7)\n",
      "memory usage: 3.3 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "BASE_GRID_DF = load_base_features(PKL_BASE_PATH, SAV_BASE_PATH, FINAL_TARGETS)\n",
    "print(BASE_GRID_DF.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb train CA_1 4 sales\n",
      "Train CA_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/wang/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['cat_id', 'dept_id', 'event_name_1', 'event_name_2', 'event_type_1', 'event_type_2', 'item_id', 'snap_CA', 'snap_TX', 'snap_WI']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.12383\n",
      "[200]\tvalid_0's rmse: 2.10996\n",
      "[300]\tvalid_0's rmse: 2.10514\n",
      "[400]\tvalid_0's rmse: 2.10232\n",
      "[500]\tvalid_0's rmse: 2.0988\n",
      "[600]\tvalid_0's rmse: 2.09385\n",
      "[700]\tvalid_0's rmse: 2.08838\n",
      "[800]\tvalid_0's rmse: 2.08182\n",
      "[900]\tvalid_0's rmse: 2.07616\n",
      "[1000]\tvalid_0's rmse: 2.07125\n",
      "[1100]\tvalid_0's rmse: 2.06655\n",
      "[1200]\tvalid_0's rmse: 2.06257\n",
      "[1300]\tvalid_0's rmse: 2.05858\n",
      "[1400]\tvalid_0's rmse: 2.05494\n",
      "Train CA_2\n",
      "[100]\tvalid_0's rmse: 2.12383\n",
      "[200]\tvalid_0's rmse: 2.10996\n",
      "[300]\tvalid_0's rmse: 2.10514\n",
      "[400]\tvalid_0's rmse: 2.10232\n",
      "[500]\tvalid_0's rmse: 2.0988\n",
      "[600]\tvalid_0's rmse: 2.09385\n",
      "[700]\tvalid_0's rmse: 2.08838\n",
      "[800]\tvalid_0's rmse: 2.08182\n",
      "[900]\tvalid_0's rmse: 2.07616\n",
      "[1000]\tvalid_0's rmse: 2.07125\n",
      "[1100]\tvalid_0's rmse: 2.06655\n",
      "[1200]\tvalid_0's rmse: 2.06257\n",
      "[1300]\tvalid_0's rmse: 2.05858\n",
      "[1400]\tvalid_0's rmse: 2.05494\n",
      "Train CA_3\n",
      "[100]\tvalid_0's rmse: 2.12383\n",
      "[200]\tvalid_0's rmse: 2.10996\n",
      "[300]\tvalid_0's rmse: 2.10514\n",
      "[400]\tvalid_0's rmse: 2.10232\n",
      "[500]\tvalid_0's rmse: 2.0988\n",
      "[600]\tvalid_0's rmse: 2.09385\n",
      "[700]\tvalid_0's rmse: 2.08838\n",
      "[800]\tvalid_0's rmse: 2.08182\n",
      "[900]\tvalid_0's rmse: 2.07616\n",
      "[1000]\tvalid_0's rmse: 2.07125\n",
      "[1100]\tvalid_0's rmse: 2.06655\n",
      "[1200]\tvalid_0's rmse: 2.06257\n",
      "[1300]\tvalid_0's rmse: 2.05858\n",
      "[1400]\tvalid_0's rmse: 2.05494\n",
      "Train CA_4\n",
      "[100]\tvalid_0's rmse: 2.12383\n",
      "[200]\tvalid_0's rmse: 2.10996\n",
      "[300]\tvalid_0's rmse: 2.10514\n",
      "[400]\tvalid_0's rmse: 2.10232\n",
      "[500]\tvalid_0's rmse: 2.0988\n",
      "[600]\tvalid_0's rmse: 2.09385\n",
      "[700]\tvalid_0's rmse: 2.08838\n",
      "[800]\tvalid_0's rmse: 2.08182\n",
      "[900]\tvalid_0's rmse: 2.07616\n",
      "[1000]\tvalid_0's rmse: 2.07125\n",
      "[1100]\tvalid_0's rmse: 2.06655\n",
      "[1200]\tvalid_0's rmse: 2.06257\n",
      "[1300]\tvalid_0's rmse: 2.05858\n",
      "[1400]\tvalid_0's rmse: 2.05494\n",
      "Train TX_1\n",
      "[100]\tvalid_0's rmse: 2.12383\n",
      "[200]\tvalid_0's rmse: 2.10996\n",
      "[300]\tvalid_0's rmse: 2.10514\n"
     ]
    }
   ],
   "source": [
    "start_shift = 4\n",
    "for target in ['sales']:\n",
    "    \n",
    "    for model in ['lgb']:\n",
    "\n",
    "        for store_id in STORES_IDS:\n",
    "        \n",
    "            for shift in range(start_shift,29):\n",
    "        \n",
    "                print(f'{model} train {store_id} {shift} {target}')\n",
    "                rolling_features_df = load_rolling_features(BASE_GRID_DF.copy(), SAV_BASE_PATH, target=FINAL_TARGETS, shift=shift)\n",
    "                grid_df = pd.concat([BASE_GRID_DF, rolling_features_df.iloc[:, 3:]], axis=1)\n",
    "                grid_df = grid_df[grid_df['store_id']==store_id]\n",
    "                del rolling_features_df\n",
    "                lag_columns = [f'sales_lag_{i}' for i in range(shift,shift+15)]\n",
    "                train_model(grid_df, NUM_COLUMNS+lag_columns, CAT_COLUMNS, target, shift, SAV_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
