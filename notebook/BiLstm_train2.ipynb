{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from attention import attention_3d_block\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from module.prepare_data import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "VER = 3                          # Our model version\n",
    "SEED = 42\n",
    "TARGET      = 'sales'            # Our target\n",
    "START_TRAIN = 700                  # We can skip some rows (Nans/faster training)\n",
    "END_TRAIN   = 1913               # End day of our train set\n",
    "P_HORIZON   = 28                 # Prediction horizon\n",
    "#STORES ids\n",
    "ORIGINAL = '../input/m5-forecasting-accuracy/'\n",
    "STORES_IDS = pd.read_csv(ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "STORES_IDS = list(STORES_IDS.unique())\n",
    "#PATHS for Features\n",
    "ORIGINAL = '../input/m5-forecasting-accuracy/'\n",
    "BASE     = '../cache/ori_grid_part_1.pkl'\n",
    "PRICE    = '../cache/ori_grid_part_2.pkl'\n",
    "CALENDAR = '../cache/ori_grid_part_3.pkl'\n",
    "LAGS     = '../cache/ori_lags_df_28.pkl'\n",
    "MEAN_ENC = '../cache/ori_mean_encoding_df.pkl'\n",
    "BASE_PATH = '../cache'\n",
    "FINAL_TARGETS = 'sales'\n",
    "SAV_BASE_PATH = '../cache/ver3'\n",
    "PKL_BASE_PATH = BASE_PATH\n",
    "\n",
    "########################### caculate mean and std\n",
    "#################################################################################\n",
    "# diff_series = []\n",
    "# for id_, group in tqdm(BASE_GRID_DF[['id','d','sales']].groupby('id')):\n",
    "#     diff_series += group['sales'].diff().dropna().tolist()\n",
    "# diff_mean = np.mean(diff_series)\n",
    "# diff_std = np.std(diff_series)\n",
    "diff_mean, diff_std = 0.00022844736211235283, 2.9674834203072016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndataset = tf.data.Dataset.range(10)\\ndataset = dataset.window(5, shift=1, drop_remainder=True)\\ndataset = dataset.flat_map(lambda window: window.batch(5))\\ndataset = dataset.map(lambda window: (window[:-1], window[-1:]))\\ndataset = dataset.shuffle(buffer_size=10)\\ndataset = dataset.batch(2).prefetch(1)\\nfor x, y in dataset:\\n    print('x = ', x.numpy())\\n    print('y = ', y.numpy())\\n    \\na  = gen_dataset(np.arange(100), window_size)\\nb = a.concatenate(gen_dataset(np.arange(2000,2100), window_size))\\nb = b.batch(batch_size).prefetch(1)\\n\\n\\nvalidaton_span = 28\\nwindow_size = 28\\nbatch_size = 5\\nshuffle_buffer = 2000\\ntrain_dataset = train_dataset.shuffle(shuffle_buffer)\\ntrain_dataset = train_dataset.batch(5).prefetch(1)\\nvalid_series = train_dataset.batch(1).prefetch(1)\\n\\ndef windowed_dataset(series, window_size, batch_size, shuffle_buffer):\\n    dataset = tf.data.Dataset.from_tensor_slices(series)\\n    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\\n    dataset = dataset.flat_map(lambda window: window.batch(window_size+1))\\n    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\\n    dataset = dataset.batch(batch_size).prefetch(1)\\n    return dataset\\n    \\n    \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### dataset sample\n",
    "#################################################################################\n",
    "\"\"\"\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
    "dataset = dataset.shuffle(buffer_size=10)\n",
    "dataset = dataset.batch(2).prefetch(1)\n",
    "for x, y in dataset:\n",
    "    print('x = ', x.numpy())\n",
    "    print('y = ', y.numpy())\n",
    "    \n",
    "a  = gen_dataset(np.arange(100), window_size)\n",
    "b = a.concatenate(gen_dataset(np.arange(2000,2100), window_size))\n",
    "b = b.batch(batch_size).prefetch(1)\n",
    "\n",
    "\n",
    "validaton_span = 28\n",
    "window_size = 28\n",
    "batch_size = 5\n",
    "shuffle_buffer = 2000\n",
    "train_dataset = train_dataset.shuffle(shuffle_buffer)\n",
    "train_dataset = train_dataset.batch(5).prefetch(1)\n",
    "valid_series = train_dataset.batch(1).prefetch(1)\n",
    "\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size+1))\n",
    "    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_GRID_DF = load_base_features(PKL_BASE_PATH, SAV_BASE_PATH, FINAL_TARGETS)\n",
    "\n",
    "# BASE_GRID_DF['item_id']= BASE_GRID_DF['item_id'].apply(lambda x: int(x.split('_')[-1]))\n",
    "# BASE_GRID_DF['dept_id']= BASE_GRID_DF['dept_id'].apply(lambda x: int(x.split('_')[-1]))\n",
    "# BASE_GRID_DF['cat_id']= BASE_GRID_DF['cat_id'].replace({'HOBBIES':0, 'HOUSEHOLD':1, 'FOODS':2})\n",
    "# for col in ['event_name_1','event_type_1','event_name_2','event_type_2']:\n",
    "#     BASE_GRID_DF[col] = BASE_GRID_DF[col].replace(dict(zip(BASE_GRID_DF[col].unique(), np.arange(BASE_GRID_DF[col].unique().shape[0]))))\n",
    "# BASE_GRID_DF['snap_CA'] = BASE_GRID_DF['snap_CA'].astype(int)\n",
    "# BASE_GRID_DF['snap_TX'] = BASE_GRID_DF['snap_TX'].astype(int)\n",
    "# BASE_GRID_DF['snap_WI'] = BASE_GRID_DF['snap_WI'].astype(int)\n",
    "\n",
    "# print(BASE_GRID_DF.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_COLUMNS = ['item_id', 'dept_id', 'cat_id', \n",
    "       'release', 'sell_price', 'price_max', 'price_min', 'price_std',\n",
    "       'price_mean', 'price_norm', 'price_nunique', 'item_nunique',\n",
    "       'price_momentum', 'price_momentum_m', 'price_momentum_y',\n",
    "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
    "       'snap_CA', 'snap_TX', 'snap_WI', 'tm_d', 'tm_w', 'tm_m', 'tm_y',\n",
    "       'tm_wm', 'tm_dw', 'tm_w_end', 'enc_store_id_cat_id_mean',\n",
    "       'enc_store_id_cat_id_std', 'enc_store_id_dept_id_mean',\n",
    "       'enc_store_id_dept_id_std', 'enc_store_id_item_id_mean',\n",
    "       'enc_store_id_item_id_std', 'enc_store_id_tm_dw_item_id_mean',\n",
    "       'enc_store_id_tm_dw_item_id_std', 'enc_store_id_tm_dw_mean',\n",
    "       'enc_store_id_tm_dw_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model2():\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[None]),\n",
    "            tf.keras.layers.Conv1D(filters=32,kernel_size=5,strides=1,padding=\"causal\",activation=\"relu\",input_shape=[None,1]),\n",
    "            tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "            tf.keras.layers.LSTM(64),\n",
    "            tf.keras.layers.Dense(1),\n",
    "    #         tf.keras.layers.Lambda(lambda x: x*100),\n",
    "        ]\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum =0.9)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.fit(train_dataset, validation_data=valid_dataset, epochs=20, callbacks=[lr_schedule], verbose=1)\n",
    "    \"\"\"\n",
    "    raise Exception('no implement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_size = 28\n",
    "def gen_dataset(series, window_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 28, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size+28))\n",
    "    dataset = dataset.map(lambda window: (window[:-28], window[-28:]))\n",
    "    return dataset\n",
    "\n",
    "def get_train_valid(grid, window_size = 28):\n",
    "    \n",
    "    X_train, y_train = [],[]\n",
    "    X_train2 = []\n",
    "    for id_, group in grid.groupby('id'):\n",
    "        if group.shape[0] == 0:\n",
    "            continue\n",
    "        train_dataset = gen_dataset(group['sales'], window_size)\n",
    "        old_n_X_train = len(X_train)\n",
    "        for idx, (x, y) in enumerate(train_dataset):\n",
    "            X_train.append(x.numpy())# = np.vstack([X_train, x.numpy()])\n",
    "            y_train.append(y.numpy())# = np.vstack([y_train, y.numpy()])\n",
    "        \n",
    "        if (len(X_train)-old_n_X_train) != (group.iloc[window_size:idx+1+window_size].shape[0]):\n",
    "            print(id_, len(X_train)-old_n_X_train, group.iloc[window_size:idx+1+window_size].shape[0], group.shape[0])\n",
    "        else:\n",
    "            X_train2.append(group.iloc[window_size:idx+1+window_size][MLP_COLUMNS])\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_train2 = np.vstack(X_train2)\n",
    "    \n",
    "    return X_train, y_train, X_train2\n",
    "\n",
    "\n",
    "def build_graph(n_timeseries, n_mlp_features, weights_path=None):\n",
    "    input1 = tf.keras.layers.Input(shape=[n_timeseries])\n",
    "    input2 = tf.keras.layers.Input(shape=[n_mlp_features])\n",
    "    x1 = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[n_timeseries])(input1)\n",
    "    x1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True))(x1)\n",
    "    x1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))(x1)\n",
    "    x1 = tf.keras.layers.Lambda(lambda x: x*100)(x1)\n",
    "    \n",
    "    x2 = input2#tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[n_mlp_features])(input2)\n",
    "    x = tf.keras.layers.concatenate([x1,x2])\n",
    "#     x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "#     x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    output = tf.keras.layers.Dense(28, activation='relu')(x)\n",
    "#     output = tf.keras.layers.Lambda(lambda x: x*100)(x)\n",
    "\n",
    "    model = Model(inputs=[input1, input2], outputs=[output])\n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "        lambda epoch: 1e-8 * 10 **(epoch/20)\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.SGD(lr=1e-6, momentum =0.9)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    if type(None) != type(weights_path):\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X_train, X2_train, y_train, X_valid, X2_valid, y_valid, store_id, base_path, n_timeseries, n_mlp_features, batch_size=10, epochs=1):\n",
    "    model = build_graph(n_timeseries, n_mlp_features, None)\n",
    "    his = model.fit([X_train,X2_train], y_train, validation_data=([X_valid,X2_valid], y_valid), batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "    model.save_weights(f'{base_path}/bilstm_{store_id}.h5')\n",
    "    return model\n",
    "\n",
    "# def predict_series(model, series, mlp_input, n_timeseries):\n",
    "    \n",
    "#     lst = []\n",
    "#     input1 = series\n",
    "#     input2 = mlp_input\n",
    "#     for i in range(29):\n",
    "#         pred = model.predict([input1.reshape(1,n_timeseries), input2])\n",
    "#         input1 = np.hstack((input1,pred[0]))[-n_timeseries:]\n",
    "#         lst.append(pred[0][0])\n",
    "#     return np.array(lst)\n",
    "\n",
    "def predict_samples(grid_df, model):\n",
    "    pred_df = pd.DataFrame(columns=['id']+[f'F{i}' for i in range(1,29)])\n",
    "    idx = 0\n",
    "    for id_, group in tqdm(grid_df.groupby('id')):\n",
    "        if group.shape[0] == 0:\n",
    "            continue\n",
    "        input1 = group[group['d']<=1913]['sales'].values[-28:].reshape(1,28)\n",
    "        input2 = group[group['d']<=1913].iloc[-1][MLP_COLUMNS].values.reshape(1,39)\n",
    "        predictions = model.predict([input1.astype(float), input2.astype(float)])\n",
    "        pred_df.loc[idx] = dict(zip(pred_df.columns.tolist(),[id_,*predictions[0]]))\n",
    "        idx += 1\n",
    "    return pred_df\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_id = 'CA_1'\n",
    "n_fold = 3\n",
    "part_len = (END_TRAIN-START_TRAIN)//n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE_IDS = pd.read_pickle(f'{SAV_BASE_PATH}/BASE_FEATURES.pkl').store_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_2_007_CA_1_validation 0 27 55\n",
      "FOODS_2_031_CA_1_validation 0 13 41\n",
      "FOODS_2_032_CA_1_validation 0 13 41\n",
      "FOODS_2_035_CA_1_validation 0 6 34\n",
      "FOODS_3_044_CA_1_validation 0 6 34\n",
      "FOODS_3_105_CA_1_validation 0 6 34\n",
      "FOODS_3_205_CA_1_validation 0 6 34\n",
      "FOODS_3_229_CA_1_validation 0 20 48\n",
      "FOODS_3_270_CA_1_validation 0 13 41\n",
      "FOODS_3_275_CA_1_validation 0 6 34\n",
      "FOODS_3_359_CA_1_validation 0 27 55\n",
      "FOODS_3_429_CA_1_validation 0 13 41\n",
      "FOODS_3_482_CA_1_validation 0 27 55\n",
      "FOODS_3_521_CA_1_validation 0 6 34\n",
      "FOODS_3_557_CA_1_validation 0 13 41\n",
      "FOODS_3_693_CA_1_validation 0 20 48\n",
      "HOBBIES_1_219_CA_1_validation 0 27 55\n",
      "HOBBIES_1_354_CA_1_validation 0 6 34\n",
      "HOUSEHOLD_1_283_CA_1_validation 0 13 41\n",
      "HOUSEHOLD_1_332_CA_1_validation 0 6 34\n",
      "HOUSEHOLD_1_384_CA_1_validation 0 6 34\n",
      "HOUSEHOLD_2_114_CA_1_validation 0 20 48\n",
      "HOUSEHOLD_2_132_CA_1_validation 0 6 34\n",
      "HOUSEHOLD_2_307_CA_1_validation 0 6 34\n",
      "HOUSEHOLD_2_360_CA_1_validation 0 6 34\n",
      "HOUSEHOLD_2_487_CA_1_validation 0 27 55\n",
      "HOUSEHOLD_2_515_CA_1_validation 0 6 34\n",
      "FOODS_2_084_CA_1_validation 0 25 53\n",
      "FOODS_2_185_CA_1_validation 0 25 53\n",
      "FOODS_3_038_CA_1_validation 0 25 53\n",
      "FOODS_3_047_CA_1_validation 0 25 53\n",
      "FOODS_3_119_CA_1_validation 0 25 53\n",
      "FOODS_3_134_CA_1_validation 0 11 39\n",
      "FOODS_3_500_CA_1_validation 0 25 53\n",
      "FOODS_3_796_CA_1_validation 0 11 39\n",
      "HOUSEHOLD_2_248_CA_1_validation 0 25 53\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 327s 654us/sample - loss: 14.5747 - root_mean_squared_error: 3.8177 - val_loss: 9.0699 - val_root_mean_squared_error: 3.0116\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 323s 647us/sample - loss: 12.6028 - root_mean_squared_error: 3.5500 - val_loss: 8.8189 - val_root_mean_squared_error: 2.9697\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 325s 650us/sample - loss: 12.3943 - root_mean_squared_error: 3.5206 - val_loss: 8.5539 - val_root_mean_squared_error: 2.9247\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 322s 643us/sample - loss: 12.3036 - root_mean_squared_error: 3.5077 - val_loss: 8.5381 - val_root_mean_squared_error: 2.9220\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 320s 641us/sample - loss: 12.2478 - root_mean_squared_error: 3.4997 - val_loss: 8.5000 - val_root_mean_squared_error: 2.9155\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 12.2195 - root_mean_squared_error: 3.4956 - val_loss: 8.4924 - val_root_mean_squared_error: 2.9142\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 322s 645us/sample - loss: 12.1958 - root_mean_squared_error: 3.4923 - val_loss: 8.4652 - val_root_mean_squared_error: 2.9095\n",
      "Epoch 8/20\n",
      "500000/500000 [==============================] - 325s 649us/sample - loss: 12.1614 - root_mean_squared_error: 3.4873 - val_loss: 8.4563 - val_root_mean_squared_error: 2.9080\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 12.1580 - root_mean_squared_error: 3.4868 - val_loss: 8.5216 - val_root_mean_squared_error: 2.9192\n",
      "Epoch 10/20\n",
      "500000/500000 [==============================] - 325s 650us/sample - loss: 12.1315 - root_mean_squared_error: 3.4830 - val_loss: 8.4582 - val_root_mean_squared_error: 2.9083\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 324s 647us/sample - loss: 11.9594 - root_mean_squared_error: 3.4582 - val_loss: 8.1338 - val_root_mean_squared_error: 2.8520\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 325s 651us/sample - loss: 11.6349 - root_mean_squared_error: 3.4110 - val_loss: 8.0755 - val_root_mean_squared_error: 2.8417\n",
      "Epoch 13/20\n",
      "500000/500000 [==============================] - 325s 649us/sample - loss: 11.6087 - root_mean_squared_error: 3.4072 - val_loss: 8.0702 - val_root_mean_squared_error: 2.8408\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 11.5856 - root_mean_squared_error: 3.4038 - val_loss: 8.0362 - val_root_mean_squared_error: 2.8348\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 11.5676 - root_mean_squared_error: 3.4011 - val_loss: 8.1467 - val_root_mean_squared_error: 2.8542\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 11.5641 - root_mean_squared_error: 3.4006 - val_loss: 8.0738 - val_root_mean_squared_error: 2.8414\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 326s 652us/sample - loss: 11.5388 - root_mean_squared_error: 3.3969 - val_loss: 8.2361 - val_root_mean_squared_error: 2.8699\n",
      "Epoch 18/20\n",
      "500000/500000 [==============================] - 322s 645us/sample - loss: 11.5393 - root_mean_squared_error: 3.3969 - val_loss: 8.0183 - val_root_mean_squared_error: 2.8317\n",
      "Epoch 19/20\n",
      "500000/500000 [==============================] - 322s 645us/sample - loss: 11.5263 - root_mean_squared_error: 3.3950 - val_loss: 8.0289 - val_root_mean_squared_error: 2.8335\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 323s 647us/sample - loss: 11.5120 - root_mean_squared_error: 3.3929 - val_loss: 8.0731 - val_root_mean_squared_error: 2.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 30361/30490 [02:02<00:00, 251.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_3_418_CA_2_validation 0 6 34\n",
      "FOODS_3_482_CA_2_validation 0 6 34\n",
      "FOODS_3_557_CA_2_validation 0 6 34\n",
      "FOODS_3_693_CA_2_validation 0 20 48\n",
      "FOODS_3_761_CA_2_validation 0 13 41\n",
      "HOBBIES_1_219_CA_2_validation 0 27 55\n",
      "HOBBIES_1_334_CA_2_validation 0 6 34\n",
      "HOBBIES_1_339_CA_2_validation 0 6 34\n",
      "HOBBIES_1_354_CA_2_validation 0 6 34\n",
      "HOUSEHOLD_1_018_CA_2_validation 0 20 48\n",
      "HOUSEHOLD_1_022_CA_2_validation 0 13 41\n",
      "HOUSEHOLD_1_267_CA_2_validation 0 20 48\n",
      "HOUSEHOLD_1_283_CA_2_validation 0 6 34\n",
      "HOUSEHOLD_1_332_CA_2_validation 0 20 48\n",
      "HOUSEHOLD_1_384_CA_2_validation 0 13 41\n",
      "HOUSEHOLD_2_132_CA_2_validation 0 6 34\n",
      "HOUSEHOLD_2_175_CA_2_validation 0 6 34\n",
      "HOUSEHOLD_2_177_CA_2_validation 0 13 41\n",
      "HOUSEHOLD_2_307_CA_2_validation 0 13 41\n",
      "FOODS_2_305_CA_2_validation 0 18 46\n",
      "FOODS_3_003_CA_2_validation 0 25 53\n",
      "FOODS_3_047_CA_2_validation 0 25 53\n",
      "FOODS_3_119_CA_2_validation 0 25 53\n",
      "FOODS_3_134_CA_2_validation 0 4 32\n",
      "FOODS_3_147_CA_2_validation 0 18 46\n",
      "FOODS_3_166_CA_2_validation 0 25 53\n",
      "FOODS_3_169_CA_2_validation 0 18 46\n",
      "FOODS_3_500_CA_2_validation 0 25 53\n",
      "FOODS_3_517_CA_2_validation 0 11 39\n",
      "FOODS_3_647_CA_2_validation 0 18 46\n",
      "FOODS_3_796_CA_2_validation 0 11 39\n",
      "HOBBIES_1_125_CA_2_validation 0 4 32\n",
      "HOUSEHOLD_1_020_CA_2_validation 0 4 32\n",
      "HOUSEHOLD_1_066_CA_2_validation 0 11 39\n",
      "HOUSEHOLD_1_120_CA_2_validation 0 4 32\n",
      "HOUSEHOLD_1_245_CA_2_validation 0 4 32\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 7.4314 - root_mean_squared_error: 2.7261 - val_loss: 6.7698 - val_root_mean_squared_error: 2.6019\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 324s 647us/sample - loss: 5.9209 - root_mean_squared_error: 2.4333 - val_loss: 6.5441 - val_root_mean_squared_error: 2.5581\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 325s 649us/sample - loss: 5.8461 - root_mean_squared_error: 2.4179 - val_loss: 6.4734 - val_root_mean_squared_error: 2.5443\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 323s 645us/sample - loss: 5.8181 - root_mean_squared_error: 2.4121 - val_loss: 6.4426 - val_root_mean_squared_error: 2.5382\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 5.8008 - root_mean_squared_error: 2.4085 - val_loss: 6.4119 - val_root_mean_squared_error: 2.5322\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 320s 640us/sample - loss: 5.7893 - root_mean_squared_error: 2.4061 - val_loss: 6.4046 - val_root_mean_squared_error: 2.5307\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 322s 645us/sample - loss: 5.7792 - root_mean_squared_error: 2.4040 - val_loss: 6.4198 - val_root_mean_squared_error: 2.5337\n",
      "Epoch 8/20\n",
      "500000/500000 [==============================] - 323s 645us/sample - loss: 5.7715 - root_mean_squared_error: 2.4024 - val_loss: 6.3808 - val_root_mean_squared_error: 2.5260\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 5.7646 - root_mean_squared_error: 2.4010 - val_loss: 6.3531 - val_root_mean_squared_error: 2.5205\n",
      "Epoch 10/20\n",
      "500000/500000 [==============================] - 321s 643us/sample - loss: 5.7574 - root_mean_squared_error: 2.3995 - val_loss: 6.3768 - val_root_mean_squared_error: 2.5252\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 5.7520 - root_mean_squared_error: 2.3983 - val_loss: 6.3655 - val_root_mean_squared_error: 2.5230\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 321s 642us/sample - loss: 5.7470 - root_mean_squared_error: 2.3973 - val_loss: 6.3439 - val_root_mean_squared_error: 2.5187\n",
      "Epoch 13/20\n",
      "500000/500000 [==============================] - 322s 643us/sample - loss: 5.5874 - root_mean_squared_error: 2.3638 - val_loss: 6.1481 - val_root_mean_squared_error: 2.4795\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 322s 643us/sample - loss: 5.5499 - root_mean_squared_error: 2.3558 - val_loss: 6.0821 - val_root_mean_squared_error: 2.4662\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 325s 650us/sample - loss: 5.5464 - root_mean_squared_error: 2.3551 - val_loss: 6.1316 - val_root_mean_squared_error: 2.4762\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 323s 645us/sample - loss: 5.5421 - root_mean_squared_error: 2.3542 - val_loss: 6.1407 - val_root_mean_squared_error: 2.4780\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 324s 649us/sample - loss: 5.5320 - root_mean_squared_error: 2.3520 - val_loss: 6.0705 - val_root_mean_squared_error: 2.4638\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 5.5292 - root_mean_squared_error: 2.3514 - val_loss: 6.0706 - val_root_mean_squared_error: 2.4639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:10<00:00, 234.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_2_096_CA_3_validation 0 20 48\n",
      "FOODS_3_044_CA_3_validation 0 6 34\n",
      "FOODS_3_084_CA_3_validation 0 27 55\n",
      "FOODS_3_105_CA_3_validation 0 6 34\n",
      "FOODS_3_218_CA_3_validation 0 6 34\n",
      "FOODS_3_229_CA_3_validation 0 6 34\n",
      "FOODS_3_270_CA_3_validation 0 20 48\n",
      "FOODS_3_275_CA_3_validation 0 27 55\n",
      "FOODS_3_359_CA_3_validation 0 27 55\n",
      "FOODS_3_429_CA_3_validation 0 13 41\n",
      "FOODS_3_482_CA_3_validation 0 27 55\n",
      "FOODS_3_525_CA_3_validation 0 13 41\n",
      "HOBBIES_1_219_CA_3_validation 0 13 41\n",
      "HOBBIES_1_354_CA_3_validation 0 6 34\n",
      "HOBBIES_2_041_CA_3_validation 0 27 55\n",
      "HOUSEHOLD_1_018_CA_3_validation 0 20 48\n",
      "HOUSEHOLD_1_332_CA_3_validation 0 20 48\n",
      "HOUSEHOLD_1_384_CA_3_validation 0 6 34\n",
      "HOUSEHOLD_1_435_CA_3_validation 0 13 41\n",
      "HOUSEHOLD_1_450_CA_3_validation 0 6 34\n",
      "HOUSEHOLD_1_495_CA_3_validation 0 6 34\n",
      "HOUSEHOLD_2_005_CA_3_validation 0 6 34\n",
      "HOUSEHOLD_2_060_CA_3_validation 0 13 41\n",
      "HOUSEHOLD_2_114_CA_3_validation 0 20 48\n",
      "HOUSEHOLD_2_132_CA_3_validation 0 6 34\n",
      "HOUSEHOLD_2_175_CA_3_validation 0 20 48\n",
      "HOUSEHOLD_2_177_CA_3_validation 0 20 48\n",
      "HOUSEHOLD_2_225_CA_3_validation 0 20 48\n",
      "HOUSEHOLD_2_263_CA_3_validation 0 6 34\n",
      "HOUSEHOLD_2_280_CA_3_validation 0 20 48\n",
      "HOUSEHOLD_2_307_CA_3_validation 0 13 41\n",
      "HOUSEHOLD_2_360_CA_3_validation 0 20 48\n",
      "HOUSEHOLD_2_515_CA_3_validation 0 13 41\n",
      "FOODS_2_185_CA_3_validation 0 18 46\n",
      "FOODS_3_047_CA_3_validation 0 25 53\n",
      "FOODS_3_134_CA_3_validation 0 11 39\n",
      "FOODS_3_166_CA_3_validation 0 25 53\n",
      "FOODS_3_278_CA_3_validation 0 25 53\n",
      "FOODS_3_647_CA_3_validation 0 18 46\n",
      "FOODS_3_796_CA_3_validation 0 18 46\n",
      "HOBBIES_1_125_CA_3_validation 0 18 46\n",
      "HOBBIES_1_269_CA_3_validation 0 4 32\n",
      "HOBBIES_1_279_CA_3_validation 0 11 39\n",
      "HOUSEHOLD_1_098_CA_3_validation 0 4 32\n",
      "HOUSEHOLD_1_120_CA_3_validation 0 11 39\n",
      "HOUSEHOLD_1_245_CA_3_validation 0 4 32\n",
      "HOUSEHOLD_1_320_CA_3_validation 0 4 32\n",
      "HOUSEHOLD_1_421_CA_3_validation 0 4 32\n",
      "HOUSEHOLD_1_496_CA_3_validation 0 4 32\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 328s 656us/sample - loss: 30.4230 - root_mean_squared_error: 5.5157 - val_loss: 19.1291 - val_root_mean_squared_error: 4.3737\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 323s 645us/sample - loss: 28.1200 - root_mean_squared_error: 5.3028 - val_loss: 19.1551 - val_root_mean_squared_error: 4.3767\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 28.0088 - root_mean_squared_error: 5.2923 - val_loss: 19.1315 - val_root_mean_squared_error: 4.3740\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 27.9766 - root_mean_squared_error: 5.2893 - val_loss: 19.2287 - val_root_mean_squared_error: 4.3851\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 27.9705 - root_mean_squared_error: 5.2887 - val_loss: 19.2506 - val_root_mean_squared_error: 4.3875\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 325s 650us/sample - loss: 27.9471 - root_mean_squared_error: 5.2865 - val_loss: 19.7612 - val_root_mean_squared_error: 4.4454\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 325s 649us/sample - loss: 27.8814 - root_mean_squared_error: 5.2803 - val_loss: 19.5681 - val_root_mean_squared_error: 4.4236\n",
      "Epoch 8/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 27.8948 - root_mean_squared_error: 5.2816 - val_loss: 19.2432 - val_root_mean_squared_error: 4.3867\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 323s 645us/sample - loss: 27.8758 - root_mean_squared_error: 5.2798 - val_loss: 19.1314 - val_root_mean_squared_error: 4.3739\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 27.8497 - root_mean_squared_error: 5.2773 - val_loss: 19.1389 - val_root_mean_squared_error: 4.3748\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 324s 649us/sample - loss: 27.8639 - root_mean_squared_error: 5.2786 - val_loss: 19.4452 - val_root_mean_squared_error: 4.4097\n",
      "Epoch 13/20\n",
      "500000/500000 [==============================] - 324s 647us/sample - loss: 27.8401 - root_mean_squared_error: 5.2764 - val_loss: 19.1587 - val_root_mean_squared_error: 4.3771\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 27.8243 - root_mean_squared_error: 5.2749 - val_loss: 19.0189 - val_root_mean_squared_error: 4.3611\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 27.8418 - root_mean_squared_error: 5.2765 - val_loss: 19.1493 - val_root_mean_squared_error: 4.3760\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 27.8686 - root_mean_squared_error: 5.2791 - val_loss: 19.0972 - val_root_mean_squared_error: 4.3700\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 323s 647us/sample - loss: 27.7585 - root_mean_squared_error: 5.2686 - val_loss: 19.1012 - val_root_mean_squared_error: 4.3705\n",
      "Epoch 18/20\n",
      "500000/500000 [==============================] - 322s 645us/sample - loss: 27.7993 - root_mean_squared_error: 5.2725 - val_loss: 19.0914 - val_root_mean_squared_error: 4.3694\n",
      "Epoch 19/20\n",
      "500000/500000 [==============================] - 325s 649us/sample - loss: 26.8698 - root_mean_squared_error: 5.1836 - val_loss: 18.4444 - val_root_mean_squared_error: 4.2947\n",
      "Epoch 20/20\n",
      "495860/500000 [============================>.] - ETA: 2s - loss: 26.7292 - root_mean_squared_error: 5.1700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:13<00:00, 228.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_1_056_CA_4_validation 0 20 48\n",
      "FOODS_2_031_CA_4_validation 0 13 41\n",
      "FOODS_2_032_CA_4_validation 0 6 34\n",
      "FOODS_2_035_CA_4_validation 0 13 41\n",
      "FOODS_2_301_CA_4_validation 0 27 55\n",
      "FOODS_3_044_CA_4_validation 0 6 34\n",
      "FOODS_3_084_CA_4_validation 0 6 34\n",
      "FOODS_3_105_CA_4_validation 0 6 34\n",
      "FOODS_3_169_CA_4_validation 0 6 34\n",
      "FOODS_3_218_CA_4_validation 0 6 34\n",
      "FOODS_3_229_CA_4_validation 0 6 34\n",
      "FOODS_3_359_CA_4_validation 0 20 48\n",
      "FOODS_3_521_CA_4_validation 0 6 34\n",
      "FOODS_3_525_CA_4_validation 0 13 41\n",
      "FOODS_3_557_CA_4_validation 0 6 34\n",
      "FOODS_3_583_CA_4_validation 0 6 34\n",
      "FOODS_3_693_CA_4_validation 0 20 48\n",
      "FOODS_3_761_CA_4_validation 0 20 48\n",
      "HOBBIES_1_149_CA_4_validation 0 13 41\n",
      "HOBBIES_1_219_CA_4_validation 0 20 48\n",
      "HOBBIES_1_265_CA_4_validation 0 13 41\n",
      "HOBBIES_2_084_CA_4_validation 0 27 55\n",
      "HOUSEHOLD_1_283_CA_4_validation 0 6 34\n",
      "HOUSEHOLD_1_384_CA_4_validation 0 6 34\n",
      "HOUSEHOLD_1_435_CA_4_validation 0 6 34\n",
      "HOUSEHOLD_1_450_CA_4_validation 0 6 34\n",
      "HOUSEHOLD_2_058_CA_4_validation 0 13 41\n",
      "HOUSEHOLD_2_060_CA_4_validation 0 6 34\n",
      "HOUSEHOLD_2_114_CA_4_validation 0 13 41\n",
      "HOUSEHOLD_2_132_CA_4_validation 0 6 34\n",
      "HOUSEHOLD_2_177_CA_4_validation 0 13 41\n",
      "HOUSEHOLD_2_225_CA_4_validation 0 6 34\n",
      "HOUSEHOLD_2_307_CA_4_validation 0 13 41\n",
      "FOODS_2_084_CA_4_validation 0 25 53\n",
      "FOODS_2_185_CA_4_validation 0 11 39\n",
      "FOODS_3_038_CA_4_validation 0 25 53\n",
      "FOODS_3_134_CA_4_validation 0 18 46\n",
      "FOODS_3_429_CA_4_validation 0 25 53\n",
      "FOODS_3_466_CA_4_validation 0 11 39\n",
      "FOODS_3_500_CA_4_validation 0 25 53\n",
      "FOODS_3_563_CA_4_validation 0 11 39\n",
      "FOODS_3_647_CA_4_validation 0 18 46\n",
      "HOBBIES_1_125_CA_4_validation 0 4 32\n",
      "HOBBIES_1_186_CA_4_validation 0 25 53\n",
      "HOBBIES_1_269_CA_4_validation 0 4 32\n",
      "HOBBIES_1_279_CA_4_validation 0 4 32\n",
      "HOUSEHOLD_1_242_CA_4_validation 0 18 46\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 326s 653us/sample - loss: 5.0299 - root_mean_squared_error: 2.2428 - val_loss: 3.4840 - val_root_mean_squared_error: 1.8666\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 324s 649us/sample - loss: 3.8197 - root_mean_squared_error: 1.9544 - val_loss: 2.9106 - val_root_mean_squared_error: 1.7061\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 321s 642us/sample - loss: 3.6744 - root_mean_squared_error: 1.9169 - val_loss: 2.8300 - val_root_mean_squared_error: 1.6823\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 3.6235 - root_mean_squared_error: 1.9035 - val_loss: 2.8090 - val_root_mean_squared_error: 1.6760\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 319s 638us/sample - loss: 3.5974 - root_mean_squared_error: 1.8967 - val_loss: 2.7828 - val_root_mean_squared_error: 1.6682\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 3.5691 - root_mean_squared_error: 1.8892 - val_loss: 2.7658 - val_root_mean_squared_error: 1.6631\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 322s 645us/sample - loss: 3.5412 - root_mean_squared_error: 1.8818 - val_loss: 2.6913 - val_root_mean_squared_error: 1.6405\n",
      "Epoch 10/20\n",
      "500000/500000 [==============================] - 320s 640us/sample - loss: 3.4441 - root_mean_squared_error: 1.8558 - val_loss: 2.6848 - val_root_mean_squared_error: 1.6385\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 320s 641us/sample - loss: 3.4354 - root_mean_squared_error: 1.8535 - val_loss: 2.6750 - val_root_mean_squared_error: 1.6355\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 321s 641us/sample - loss: 3.4228 - root_mean_squared_error: 1.8501 - val_loss: 2.6606 - val_root_mean_squared_error: 1.6311\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 323s 647us/sample - loss: 3.4186 - root_mean_squared_error: 1.8489 - val_loss: 2.6684 - val_root_mean_squared_error: 1.6335\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 320s 639us/sample - loss: 3.4144 - root_mean_squared_error: 1.8478 - val_loss: 2.6641 - val_root_mean_squared_error: 1.6322\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 322s 643us/sample - loss: 3.4110 - root_mean_squared_error: 1.8469 - val_loss: 2.6642 - val_root_mean_squared_error: 1.6322\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 322s 645us/sample - loss: 3.4049 - root_mean_squared_error: 1.8452 - val_loss: 2.6571 - val_root_mean_squared_error: 1.6300\n",
      "Epoch 19/20\n",
      "500000/500000 [==============================] - 320s 639us/sample - loss: 3.4029 - root_mean_squared_error: 1.8447 - val_loss: 2.6629 - val_root_mean_squared_error: 1.6318\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 3.3996 - root_mean_squared_error: 1.8438 - val_loss: 2.6605 - val_root_mean_squared_error: 1.6311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29674/30490 [02:10<00:03, 225.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_3_044_TX_1_validation 0 6 34\n",
      "FOODS_3_072_TX_1_validation 0 27 55\n",
      "FOODS_3_084_TX_1_validation 0 6 34\n",
      "FOODS_3_105_TX_1_validation 0 6 34\n",
      "FOODS_3_229_TX_1_validation 0 27 55\n",
      "FOODS_3_270_TX_1_validation 0 27 55\n",
      "FOODS_3_359_TX_1_validation 0 27 55\n",
      "FOODS_3_429_TX_1_validation 0 6 34\n",
      "FOODS_3_482_TX_1_validation 0 27 55\n",
      "FOODS_3_583_TX_1_validation 0 27 55\n",
      "FOODS_3_662_TX_1_validation 0 27 55\n",
      "FOODS_3_693_TX_1_validation 0 13 41\n",
      "HOBBIES_1_219_TX_1_validation 0 13 41\n",
      "HOBBIES_1_241_TX_1_validation 0 13 41\n",
      "HOBBIES_2_084_TX_1_validation 0 6 34\n",
      "HOUSEHOLD_1_190_TX_1_validation 0 6 34\n",
      "HOUSEHOLD_1_384_TX_1_validation 0 13 41\n",
      "HOUSEHOLD_1_435_TX_1_validation 0 13 41\n",
      "HOUSEHOLD_1_450_TX_1_validation 0 6 34\n",
      "HOUSEHOLD_2_060_TX_1_validation 0 13 41\n",
      "HOUSEHOLD_2_114_TX_1_validation 0 13 41\n",
      "HOUSEHOLD_2_132_TX_1_validation 0 13 41\n",
      "HOUSEHOLD_2_360_TX_1_validation 0 13 41\n",
      "HOUSEHOLD_2_515_TX_1_validation 0 13 41\n",
      "FOODS_2_185_TX_1_validation 0 25 53\n",
      "FOODS_2_390_TX_1_validation 0 18 46\n",
      "FOODS_3_003_TX_1_validation 0 11 39\n",
      "FOODS_3_038_TX_1_validation 0 25 53\n",
      "FOODS_3_047_TX_1_validation 0 18 46\n",
      "FOODS_3_119_TX_1_validation 0 18 46\n",
      "FOODS_3_134_TX_1_validation 0 25 53\n",
      "FOODS_3_166_TX_1_validation 0 25 53\n",
      "FOODS_3_500_TX_1_validation 0 25 53\n",
      "FOODS_3_647_TX_1_validation 0 18 46\n",
      "HOBBIES_1_158_TX_1_validation 0 11 39\n",
      "HOUSEHOLD_2_067_TX_1_validation 0 4 32\n",
      "HOUSEHOLD_2_196_TX_1_validation 0 4 32\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 325s 651us/sample - loss: 9.3666 - root_mean_squared_error: 3.0605 - val_loss: 5.6217 - val_root_mean_squared_error: 2.3710\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 320s 641us/sample - loss: 7.9864 - root_mean_squared_error: 2.8260 - val_loss: 5.2826 - val_root_mean_squared_error: 2.2984\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 7.8737 - root_mean_squared_error: 2.8060 - val_loss: 5.4429 - val_root_mean_squared_error: 2.3330\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 321s 642us/sample - loss: 7.8510 - root_mean_squared_error: 2.8020 - val_loss: 5.1679 - val_root_mean_squared_error: 2.2733\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 320s 641us/sample - loss: 7.8148 - root_mean_squared_error: 2.7955 - val_loss: 5.1865 - val_root_mean_squared_error: 2.2774\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 325s 650us/sample - loss: 7.7951 - root_mean_squared_error: 2.7920 - val_loss: 5.1280 - val_root_mean_squared_error: 2.2645\n",
      "Epoch 10/20\n",
      "500000/500000 [==============================] - 320s 640us/sample - loss: 7.7845 - root_mean_squared_error: 2.7901 - val_loss: 5.4903 - val_root_mean_squared_error: 2.3431\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 7.7855 - root_mean_squared_error: 2.7902 - val_loss: 5.1548 - val_root_mean_squared_error: 2.2704\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 7.7621 - root_mean_squared_error: 2.7861 - val_loss: 5.1113 - val_root_mean_squared_error: 2.2608\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 7.7616 - root_mean_squared_error: 2.7860 - val_loss: 5.1340 - val_root_mean_squared_error: 2.2658\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 321s 642us/sample - loss: 7.7520 - root_mean_squared_error: 2.7842 - val_loss: 5.1837 - val_root_mean_squared_error: 2.2768\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 7.7393 - root_mean_squared_error: 2.7820 - val_loss: 5.2445 - val_root_mean_squared_error: 2.2901\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 7.4360 - root_mean_squared_error: 2.7269 - val_loss: 4.9383 - val_root_mean_squared_error: 2.2222\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 325s 650us/sample - loss: 7.4420 - root_mean_squared_error: 2.7280 - val_loss: 4.8873 - val_root_mean_squared_error: 2.2107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:14<00:00, 226.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_2_007_TX_2_validation 0 27 55\n",
      "FOODS_2_035_TX_2_validation 0 13 41\n",
      "FOODS_2_096_TX_2_validation 0 27 55\n",
      "FOODS_2_301_TX_2_validation 0 20 48\n",
      "FOODS_3_044_TX_2_validation 0 6 34\n",
      "FOODS_3_084_TX_2_validation 0 20 48\n",
      "FOODS_3_105_TX_2_validation 0 6 34\n",
      "FOODS_3_229_TX_2_validation 0 27 55\n",
      "FOODS_3_275_TX_2_validation 0 27 55\n",
      "FOODS_3_359_TX_2_validation 0 20 48\n",
      "FOODS_3_521_TX_2_validation 0 6 34\n",
      "FOODS_3_525_TX_2_validation 0 6 34\n",
      "FOODS_3_693_TX_2_validation 0 20 48\n",
      "HOBBIES_1_219_TX_2_validation 0 20 48\n",
      "HOBBIES_1_241_TX_2_validation 0 13 41\n",
      "HOBBIES_1_334_TX_2_validation 0 13 41\n",
      "HOBBIES_1_339_TX_2_validation 0 6 34\n",
      "HOBBIES_1_354_TX_2_validation 0 6 34\n",
      "HOBBIES_2_015_TX_2_validation 0 6 34\n",
      "HOBBIES_2_041_TX_2_validation 0 13 41\n",
      "HOUSEHOLD_1_190_TX_2_validation 0 6 34\n",
      "HOUSEHOLD_1_384_TX_2_validation 0 6 34\n",
      "HOUSEHOLD_1_435_TX_2_validation 0 13 41\n",
      "HOUSEHOLD_2_060_TX_2_validation 0 13 41\n",
      "HOUSEHOLD_2_114_TX_2_validation 0 13 41\n",
      "HOUSEHOLD_2_175_TX_2_validation 0 27 55\n",
      "HOUSEHOLD_2_177_TX_2_validation 0 13 41\n",
      "HOUSEHOLD_2_225_TX_2_validation 0 20 48\n",
      "HOUSEHOLD_2_280_TX_2_validation 0 13 41\n",
      "HOUSEHOLD_2_307_TX_2_validation 0 6 34\n",
      "HOUSEHOLD_2_360_TX_2_validation 0 6 34\n",
      "HOUSEHOLD_2_381_TX_2_validation 0 27 55\n",
      "HOUSEHOLD_2_515_TX_2_validation 0 6 34\n",
      "FOODS_3_003_TX_2_validation 0 11 39\n",
      "FOODS_3_038_TX_2_validation 0 4 32\n",
      "FOODS_3_047_TX_2_validation 0 11 39\n",
      "FOODS_3_134_TX_2_validation 0 25 53\n",
      "FOODS_3_166_TX_2_validation 0 11 39\n",
      "FOODS_3_278_TX_2_validation 0 25 53\n",
      "FOODS_3_366_TX_2_validation 0 4 32\n",
      "FOODS_3_500_TX_2_validation 0 18 46\n",
      "FOODS_3_647_TX_2_validation 0 18 46\n",
      "FOODS_3_760_TX_2_validation 0 25 53\n",
      "HOBBIES_1_125_TX_2_validation 0 18 46\n",
      "HOBBIES_1_269_TX_2_validation 0 11 39\n",
      "HOBBIES_1_279_TX_2_validation 0 4 32\n",
      "HOUSEHOLD_1_245_TX_2_validation 0 4 32\n",
      "HOUSEHOLD_2_196_TX_2_validation 0 4 32\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 327s 654us/sample - loss: 14.7853 - root_mean_squared_error: 3.8452 - val_loss: 8.1872 - val_root_mean_squared_error: 2.8613\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 12.9504 - root_mean_squared_error: 3.5987 - val_loss: 7.9781 - val_root_mean_squared_error: 2.8246\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 12.7842 - root_mean_squared_error: 3.5755 - val_loss: 7.8711 - val_root_mean_squared_error: 2.8055\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 323s 645us/sample - loss: 12.3089 - root_mean_squared_error: 3.5084 - val_loss: 7.4304 - val_root_mean_squared_error: 2.7259\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 323s 647us/sample - loss: 11.8114 - root_mean_squared_error: 3.4368 - val_loss: 6.9302 - val_root_mean_squared_error: 2.6325\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 326s 651us/sample - loss: 11.2868 - root_mean_squared_error: 3.3596 - val_loss: 6.9039 - val_root_mean_squared_error: 2.6275\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 324s 647us/sample - loss: 11.2231 - root_mean_squared_error: 3.3501 - val_loss: 7.0747 - val_root_mean_squared_error: 2.6598\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 11.1896 - root_mean_squared_error: 3.3451 - val_loss: 6.9269 - val_root_mean_squared_error: 2.6319\n",
      "Epoch 13/20\n",
      "500000/500000 [==============================] - 323s 647us/sample - loss: 11.1964 - root_mean_squared_error: 3.3461 - val_loss: 6.9405 - val_root_mean_squared_error: 2.6345\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 326s 652us/sample - loss: 11.1920 - root_mean_squared_error: 3.3454 - val_loss: 6.8790 - val_root_mean_squared_error: 2.6228\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 11.1718 - root_mean_squared_error: 3.3424 - val_loss: 6.8828 - val_root_mean_squared_error: 2.6235\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 329s 659us/sample - loss: 11.1617 - root_mean_squared_error: 3.3409 - val_loss: 6.9897 - val_root_mean_squared_error: 2.6438\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 326s 652us/sample - loss: 11.1512 - root_mean_squared_error: 3.3393 - val_loss: 6.8436 - val_root_mean_squared_error: 2.6160\n",
      "Epoch 18/20\n",
      "500000/500000 [==============================] - 326s 652us/sample - loss: 11.1146 - root_mean_squared_error: 3.3339 - val_loss: 6.9670 - val_root_mean_squared_error: 2.6395\n",
      "Epoch 19/20\n",
      "500000/500000 [==============================] - 326s 652us/sample - loss: 11.1292 - root_mean_squared_error: 3.3360 - val_loss: 6.8248 - val_root_mean_squared_error: 2.6124\n",
      "Epoch 20/20\n",
      "498980/500000 [============================>.] - ETA: 0s - loss: 11.0775 - root_mean_squared_error: 3.3283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:19<00:00, 218.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_2_007_TX_3_validation 0 6 34\n",
      "FOODS_2_035_TX_3_validation 0 13 41\n",
      "FOODS_2_115_TX_3_validation 0 13 41\n",
      "FOODS_2_132_TX_3_validation 0 27 55\n",
      "FOODS_2_265_TX_3_validation 0 27 55\n",
      "FOODS_2_269_TX_3_validation 0 27 55\n",
      "FOODS_2_273_TX_3_validation 0 27 55\n",
      "FOODS_3_044_TX_3_validation 0 13 41\n",
      "FOODS_3_072_TX_3_validation 0 27 55\n",
      "FOODS_3_077_TX_3_validation 0 6 34\n",
      "FOODS_3_084_TX_3_validation 0 20 48\n",
      "FOODS_3_105_TX_3_validation 0 6 34\n",
      "FOODS_3_229_TX_3_validation 0 27 55\n",
      "FOODS_3_270_TX_3_validation 0 27 55\n",
      "FOODS_3_275_TX_3_validation 0 27 55\n",
      "FOODS_3_359_TX_3_validation 0 20 48\n",
      "FOODS_3_429_TX_3_validation 0 6 34\n",
      "FOODS_3_525_TX_3_validation 0 6 34\n",
      "FOODS_3_557_TX_3_validation 0 27 55\n",
      "FOODS_3_583_TX_3_validation 0 27 55\n",
      "HOBBIES_1_219_TX_3_validation 0 20 48\n",
      "HOBBIES_1_241_TX_3_validation 0 13 41\n",
      "HOUSEHOLD_1_267_TX_3_validation 0 6 34\n",
      "HOUSEHOLD_1_332_TX_3_validation 0 20 48\n",
      "HOUSEHOLD_2_060_TX_3_validation 0 13 41\n",
      "HOUSEHOLD_2_114_TX_3_validation 0 20 48\n",
      "HOUSEHOLD_2_132_TX_3_validation 0 6 34\n",
      "HOUSEHOLD_2_175_TX_3_validation 0 6 34\n",
      "HOUSEHOLD_2_263_TX_3_validation 0 13 41\n",
      "HOUSEHOLD_2_280_TX_3_validation 0 13 41\n",
      "HOUSEHOLD_2_307_TX_3_validation 0 6 34\n",
      "HOUSEHOLD_2_360_TX_3_validation 0 6 34\n",
      "FOODS_2_185_TX_3_validation 0 25 53\n",
      "FOODS_3_038_TX_3_validation 0 25 53\n",
      "FOODS_3_119_TX_3_validation 0 18 46\n",
      "FOODS_3_134_TX_3_validation 0 25 53\n",
      "FOODS_3_166_TX_3_validation 0 18 46\n",
      "FOODS_3_254_TX_3_validation 0 18 46\n",
      "FOODS_3_260_TX_3_validation 0 25 53\n",
      "FOODS_3_278_TX_3_validation 0 11 39\n",
      "FOODS_3_647_TX_3_validation 0 18 46\n",
      "HOBBIES_1_344_TX_3_validation 0 25 53\n",
      "HOUSEHOLD_2_196_TX_3_validation 0 4 32\n",
      "HOUSEHOLD_2_248_TX_3_validation 0 25 53\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 9.8870 - root_mean_squared_error: 3.1444 - val_loss: 7.8777 - val_root_mean_squared_error: 2.8067\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 9.3503 - root_mean_squared_error: 3.0578 - val_loss: 7.4584 - val_root_mean_squared_error: 2.7310\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 323s 647us/sample - loss: 9.1839 - root_mean_squared_error: 3.0305 - val_loss: 7.3388 - val_root_mean_squared_error: 2.7090\n",
      "Epoch 5/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 9.1355 - root_mean_squared_error: 3.0225 - val_loss: 7.3019 - val_root_mean_squared_error: 2.7022\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 331s 663us/sample - loss: 9.0773 - root_mean_squared_error: 3.0129 - val_loss: 7.2929 - val_root_mean_squared_error: 2.7005\n",
      "Epoch 8/20\n",
      "500000/500000 [==============================] - 329s 657us/sample - loss: 9.0615 - root_mean_squared_error: 3.0102 - val_loss: 7.3084 - val_root_mean_squared_error: 2.7034\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 323s 645us/sample - loss: 9.0382 - root_mean_squared_error: 3.0064 - val_loss: 7.3274 - val_root_mean_squared_error: 2.7069\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 9.0259 - root_mean_squared_error: 3.0043 - val_loss: 7.2556 - val_root_mean_squared_error: 2.6936\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 322s 645us/sample - loss: 9.0139 - root_mean_squared_error: 3.0023 - val_loss: 7.2655 - val_root_mean_squared_error: 2.6955\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 8.9992 - root_mean_squared_error: 2.9999 - val_loss: 7.2685 - val_root_mean_squared_error: 2.6960\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 324s 649us/sample - loss: 8.9923 - root_mean_squared_error: 2.9987 - val_loss: 7.2572 - val_root_mean_squared_error: 2.6939\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 324s 647us/sample - loss: 8.9838 - root_mean_squared_error: 2.9973 - val_loss: 7.3336 - val_root_mean_squared_error: 2.7081\n",
      "Epoch 18/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 8.9782 - root_mean_squared_error: 2.9964 - val_loss: 7.2763 - val_root_mean_squared_error: 2.6975\n",
      "Epoch 19/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 8.9791 - root_mean_squared_error: 2.9965 - val_loss: 7.2723 - val_root_mean_squared_error: 2.6967\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 323s 647us/sample - loss: 8.9715 - root_mean_squared_error: 2.9953 - val_loss: 7.4149 - val_root_mean_squared_error: 2.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:16<00:00, 222.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_2_035_WI_1_validation 0 13 41\n",
      "FOODS_2_115_WI_1_validation 0 13 41\n",
      "FOODS_2_310_WI_1_validation 0 27 55\n",
      "FOODS_3_044_WI_1_validation 0 6 34\n",
      "FOODS_3_084_WI_1_validation 0 6 34\n",
      "FOODS_3_105_WI_1_validation 0 6 34\n",
      "FOODS_3_205_WI_1_validation 0 6 34\n",
      "FOODS_3_229_WI_1_validation 0 27 55\n",
      "FOODS_3_270_WI_1_validation 0 20 48\n",
      "FOODS_3_275_WI_1_validation 0 20 48\n",
      "FOODS_3_359_WI_1_validation 0 20 48\n",
      "FOODS_3_429_WI_1_validation 0 6 34\n",
      "FOODS_3_482_WI_1_validation 0 20 48\n",
      "FOODS_3_521_WI_1_validation 0 6 34\n",
      "FOODS_3_662_WI_1_validation 0 13 41\n",
      "FOODS_3_693_WI_1_validation 0 27 55\n",
      "FOODS_3_707_WI_1_validation 0 6 34\n",
      "HOBBIES_1_219_WI_1_validation 0 27 55\n",
      "HOBBIES_1_241_WI_1_validation 0 6 34\n",
      "HOUSEHOLD_1_190_WI_1_validation 0 6 34\n",
      "HOUSEHOLD_1_267_WI_1_validation 0 20 48\n",
      "HOUSEHOLD_1_283_WI_1_validation 0 13 41\n",
      "HOUSEHOLD_2_060_WI_1_validation 0 13 41\n",
      "HOUSEHOLD_2_114_WI_1_validation 0 13 41\n",
      "HOUSEHOLD_2_164_WI_1_validation 0 20 48\n",
      "HOUSEHOLD_2_177_WI_1_validation 0 27 55\n",
      "HOUSEHOLD_2_225_WI_1_validation 0 20 48\n",
      "HOUSEHOLD_2_487_WI_1_validation 0 27 55\n",
      "FOODS_3_047_WI_1_validation 0 25 53\n",
      "FOODS_3_278_WI_1_validation 0 18 46\n",
      "FOODS_3_500_WI_1_validation 0 18 46\n",
      "FOODS_3_759_WI_1_validation 0 11 39\n",
      "HOUSEHOLD_1_060_WI_1_validation 0 25 53\n",
      "HOUSEHOLD_1_328_WI_1_validation 0 4 32\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 327s 654us/sample - loss: 6.6869 - root_mean_squared_error: 2.5859 - val_loss: 5.5274 - val_root_mean_squared_error: 2.3510\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 5.0712 - root_mean_squared_error: 2.2519 - val_loss: 4.7299 - val_root_mean_squared_error: 2.1748\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 321s 643us/sample - loss: 4.9544 - root_mean_squared_error: 2.2258 - val_loss: 4.6518 - val_root_mean_squared_error: 2.1568\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 4.9300 - root_mean_squared_error: 2.2204 - val_loss: 4.6464 - val_root_mean_squared_error: 2.1556\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 324s 647us/sample - loss: 4.9125 - root_mean_squared_error: 2.2164 - val_loss: 4.6223 - val_root_mean_squared_error: 2.1500\n",
      "Epoch 8/20\n",
      "500000/500000 [==============================] - 324s 649us/sample - loss: 4.8986 - root_mean_squared_error: 2.2133 - val_loss: 4.6122 - val_root_mean_squared_error: 2.1476\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 322s 644us/sample - loss: 4.8854 - root_mean_squared_error: 2.2103 - val_loss: 4.6380 - val_root_mean_squared_error: 2.1536\n",
      "Epoch 10/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 4.8758 - root_mean_squared_error: 2.2081 - val_loss: 4.5890 - val_root_mean_squared_error: 2.1422\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 323s 647us/sample - loss: 4.8674 - root_mean_squared_error: 2.2062 - val_loss: 4.5966 - val_root_mean_squared_error: 2.1440\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 323s 646us/sample - loss: 4.8603 - root_mean_squared_error: 2.2046 - val_loss: 4.6094 - val_root_mean_squared_error: 2.1470\n",
      "Epoch 13/20\n",
      "500000/500000 [==============================] - 324s 649us/sample - loss: 4.8540 - root_mean_squared_error: 2.2032 - val_loss: 4.5867 - val_root_mean_squared_error: 2.1416\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 326s 651us/sample - loss: 4.8474 - root_mean_squared_error: 2.2017 - val_loss: 4.5679 - val_root_mean_squared_error: 2.1373\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 327s 655us/sample - loss: 4.8372 - root_mean_squared_error: 2.1994 - val_loss: 4.5505 - val_root_mean_squared_error: 2.1332\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 328s 657us/sample - loss: 4.5316 - root_mean_squared_error: 2.1288 - val_loss: 4.3810 - val_root_mean_squared_error: 2.0931\n",
      "Epoch 18/20\n",
      "500000/500000 [==============================] - 327s 655us/sample - loss: 4.4658 - root_mean_squared_error: 2.1132 - val_loss: 4.2099 - val_root_mean_squared_error: 2.0518\n",
      "Epoch 19/20\n",
      "500000/500000 [==============================] - 327s 654us/sample - loss: 4.4545 - root_mean_squared_error: 2.1106 - val_loss: 4.2409 - val_root_mean_squared_error: 2.0593\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 323s 645us/sample - loss: 4.4468 - root_mean_squared_error: 2.1087 - val_loss: 4.2775 - val_root_mean_squared_error: 2.0682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:18<00:00, 220.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_2_007_WI_2_validation 0 27 55\n",
      "FOODS_2_035_WI_2_validation 0 13 41\n",
      "FOODS_2_132_WI_2_validation 0 27 55\n",
      "FOODS_2_259_WI_2_validation 0 27 55\n",
      "FOODS_2_273_WI_2_validation 0 27 55\n",
      "FOODS_3_044_WI_2_validation 0 20 48\n",
      "FOODS_3_084_WI_2_validation 0 27 55\n",
      "FOODS_3_105_WI_2_validation 0 20 48\n",
      "FOODS_3_205_WI_2_validation 0 6 34\n",
      "FOODS_3_270_WI_2_validation 0 27 55\n",
      "FOODS_3_275_WI_2_validation 0 20 48\n",
      "FOODS_3_429_WI_2_validation 0 6 34\n",
      "FOODS_3_482_WI_2_validation 0 13 41\n",
      "FOODS_3_662_WI_2_validation 0 27 55\n",
      "FOODS_3_707_WI_2_validation 0 6 34\n",
      "FOODS_3_733_WI_2_validation 0 6 34\n",
      "HOBBIES_1_019_WI_2_validation 0 6 34\n",
      "HOBBIES_1_190_WI_2_validation 0 6 34\n",
      "HOBBIES_1_219_WI_2_validation 0 27 55\n",
      "HOBBIES_1_241_WI_2_validation 0 6 34\n",
      "HOUSEHOLD_1_190_WI_2_validation 0 6 34\n",
      "HOUSEHOLD_1_283_WI_2_validation 0 13 41\n",
      "HOUSEHOLD_1_435_WI_2_validation 0 6 34\n",
      "HOUSEHOLD_2_060_WI_2_validation 0 6 34\n",
      "HOUSEHOLD_2_132_WI_2_validation 0 6 34\n",
      "HOUSEHOLD_2_177_WI_2_validation 0 6 34\n",
      "HOUSEHOLD_2_515_WI_2_validation 0 6 34\n",
      "FOODS_2_185_WI_2_validation 0 25 53\n",
      "FOODS_3_003_WI_2_validation 0 25 53\n",
      "FOODS_3_038_WI_2_validation 0 18 46\n",
      "FOODS_3_047_WI_2_validation 0 25 53\n",
      "FOODS_3_119_WI_2_validation 0 18 46\n",
      "FOODS_3_166_WI_2_validation 0 25 53\n",
      "FOODS_3_255_WI_2_validation 0 11 39\n",
      "FOODS_3_278_WI_2_validation 0 25 53\n",
      "FOODS_3_472_WI_2_validation 0 25 53\n",
      "FOODS_3_647_WI_2_validation 0 25 53\n",
      "FOODS_3_796_WI_2_validation 0 18 46\n",
      "HOBBIES_1_046_WI_2_validation 0 18 46\n",
      "HOBBIES_1_344_WI_2_validation 0 25 53\n",
      "HOUSEHOLD_1_245_WI_2_validation 0 4 32\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 327s 654us/sample - loss: 14.3302 - root_mean_squared_error: 3.7855 - val_loss: 10.6905 - val_root_mean_squared_error: 3.2696\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 327s 654us/sample - loss: 12.6337 - root_mean_squared_error: 3.5544 - val_loss: 10.4092 - val_root_mean_squared_error: 3.2263\n",
      "Epoch 3/20\n",
      "500000/500000 [==============================] - 325s 649us/sample - loss: 12.4571 - root_mean_squared_error: 3.5295 - val_loss: 10.3250 - val_root_mean_squared_error: 3.2133\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 325s 649us/sample - loss: 12.3231 - root_mean_squared_error: 3.5104 - val_loss: 10.2234 - val_root_mean_squared_error: 3.1974\n",
      "Epoch 6/20\n",
      "500000/500000 [==============================] - 325s 651us/sample - loss: 12.2816 - root_mean_squared_error: 3.5045 - val_loss: 10.2908 - val_root_mean_squared_error: 3.2079\n",
      "Epoch 7/20\n",
      "500000/500000 [==============================] - 329s 659us/sample - loss: 12.2073 - root_mean_squared_error: 3.4939 - val_loss: 10.1848 - val_root_mean_squared_error: 3.1914\n",
      "Epoch 10/20\n",
      "500000/500000 [==============================] - 325s 651us/sample - loss: 12.1887 - root_mean_squared_error: 3.4912 - val_loss: 10.1752 - val_root_mean_squared_error: 3.1899\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 325s 651us/sample - loss: 12.1762 - root_mean_squared_error: 3.4894 - val_loss: 10.1815 - val_root_mean_squared_error: 3.1909\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 326s 652us/sample - loss: 12.1490 - root_mean_squared_error: 3.4855 - val_loss: 10.2060 - val_root_mean_squared_error: 3.1947\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 12.1426 - root_mean_squared_error: 3.4846 - val_loss: 10.1102 - val_root_mean_squared_error: 3.1797\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 326s 652us/sample - loss: 12.1319 - root_mean_squared_error: 3.4831 - val_loss: 10.1433 - val_root_mean_squared_error: 3.1849\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 327s 654us/sample - loss: 12.1217 - root_mean_squared_error: 3.4816 - val_loss: 10.2388 - val_root_mean_squared_error: 3.1998\n",
      "Epoch 17/20\n",
      "500000/500000 [==============================] - 328s 655us/sample - loss: 12.1129 - root_mean_squared_error: 3.4804 - val_loss: 10.1242 - val_root_mean_squared_error: 3.1819\n",
      "Epoch 18/20\n",
      "500000/500000 [==============================] - 327s 653us/sample - loss: 12.1018 - root_mean_squared_error: 3.4788 - val_loss: 10.1429 - val_root_mean_squared_error: 3.1848\n",
      "Epoch 20/20\n",
      "500000/500000 [==============================] - 326s 651us/sample - loss: 12.0924 - root_mean_squared_error: 3.4774 - val_loss: 10.1265 - val_root_mean_squared_error: 3.1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:16<00:00, 223.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOODS_2_007_WI_3_validation 0 6 34\n",
      "FOODS_2_035_WI_3_validation 0 13 41\n",
      "FOODS_2_115_WI_3_validation 0 13 41\n",
      "FOODS_3_275_WI_3_validation 0 20 48\n",
      "FOODS_3_359_WI_3_validation 0 27 55\n",
      "FOODS_3_429_WI_3_validation 0 6 34\n",
      "FOODS_3_521_WI_3_validation 0 6 34\n",
      "FOODS_3_583_WI_3_validation 0 27 55\n",
      "FOODS_3_662_WI_3_validation 0 6 34\n",
      "FOODS_3_747_WI_3_validation 0 20 48\n",
      "HOBBIES_1_219_WI_3_validation 0 27 55\n",
      "HOBBIES_1_241_WI_3_validation 0 6 34\n",
      "HOUSEHOLD_1_190_WI_3_validation 0 6 34\n",
      "HOUSEHOLD_1_283_WI_3_validation 0 20 48\n",
      "HOUSEHOLD_1_332_WI_3_validation 0 20 48\n",
      "HOUSEHOLD_2_020_WI_3_validation 0 27 55\n",
      "HOUSEHOLD_2_060_WI_3_validation 0 13 41\n",
      "HOUSEHOLD_2_114_WI_3_validation 0 13 41\n",
      "HOUSEHOLD_2_132_WI_3_validation 0 6 34\n",
      "HOUSEHOLD_2_177_WI_3_validation 0 20 48\n",
      "HOUSEHOLD_2_360_WI_3_validation 0 13 41\n",
      "FOODS_2_390_WI_3_validation 0 11 39\n",
      "FOODS_3_003_WI_3_validation 0 18 46\n",
      "FOODS_3_038_WI_3_validation 0 25 53\n",
      "FOODS_3_047_WI_3_validation 0 25 53\n",
      "FOODS_3_119_WI_3_validation 0 18 46\n",
      "FOODS_3_166_WI_3_validation 0 18 46\n",
      "FOODS_3_278_WI_3_validation 0 25 53\n",
      "FOODS_3_366_WI_3_validation 0 25 53\n",
      "FOODS_3_466_WI_3_validation 0 11 39\n",
      "FOODS_3_500_WI_3_validation 0 18 46\n",
      "FOODS_3_517_WI_3_validation 0 25 53\n",
      "FOODS_3_563_WI_3_validation 0 11 39\n",
      "FOODS_3_735_WI_3_validation 0 18 46\n",
      "HOBBIES_1_125_WI_3_validation 0 4 32\n",
      "HOBBIES_1_269_WI_3_validation 0 4 32\n",
      "HOUSEHOLD_1_116_WI_3_validation 0 11 39\n",
      "HOUSEHOLD_2_396_WI_3_validation 0 11 39\n",
      "Train on 500000 samples, validate on 200000 samples\n",
      "Epoch 1/20\n",
      "500000/500000 [==============================] - 324s 648us/sample - loss: 10.4438 - root_mean_squared_error: 3.2317 - val_loss: 7.6071 - val_root_mean_squared_error: 2.7581\n",
      "Epoch 2/20\n",
      "500000/500000 [==============================] - 326s 652us/sample - loss: 8.6796 - root_mean_squared_error: 2.9461 - val_loss: 7.2513 - val_root_mean_squared_error: 2.6928\n",
      "Epoch 4/20\n",
      "500000/500000 [==============================] - 329s 658us/sample - loss: 8.1296 - root_mean_squared_error: 2.8512 - val_loss: 6.6950 - val_root_mean_squared_error: 2.5875\n",
      "Epoch 9/20\n",
      "500000/500000 [==============================] - 331s 662us/sample - loss: 7.7627 - root_mean_squared_error: 2.7862 - val_loss: 6.3988 - val_root_mean_squared_error: 2.5296\n",
      "Epoch 11/20\n",
      "500000/500000 [==============================] - 328s 656us/sample - loss: 7.7453 - root_mean_squared_error: 2.7830 - val_loss: 6.3702 - val_root_mean_squared_error: 2.5239\n",
      "Epoch 12/20\n",
      "500000/500000 [==============================] - 331s 661us/sample - loss: 7.7143 - root_mean_squared_error: 2.7775 - val_loss: 6.3529 - val_root_mean_squared_error: 2.5205\n",
      "Epoch 14/20\n",
      "500000/500000 [==============================] - 330s 660us/sample - loss: 7.7041 - root_mean_squared_error: 2.7756 - val_loss: 6.3155 - val_root_mean_squared_error: 2.5131\n",
      "Epoch 15/20\n",
      "500000/500000 [==============================] - 332s 663us/sample - loss: 7.6978 - root_mean_squared_error: 2.7745 - val_loss: 6.3427 - val_root_mean_squared_error: 2.5185\n",
      "Epoch 16/20\n",
      "500000/500000 [==============================] - 326s 653us/sample - loss: 7.7045 - root_mean_squared_error: 2.7757 - val_loss: 6.3189 - val_root_mean_squared_error: 2.5137\n",
      "Epoch 17/20\n",
      " 59140/500000 [==>...........................] - ETA: 3:55 - loss: 7.3491 - root_mean_squared_error: 2.7109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 325s 650us/sample - loss: 7.6808 - root_mean_squared_error: 2.7714 - val_loss: 6.3364 - val_root_mean_squared_error: 2.5172\n",
      "Epoch 18/20\n",
      "107350/500000 [=====>........................] - ETA: 3:27 - loss: 7.9251 - root_mean_squared_error: 2.8152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 325s 650us/sample - loss: 7.6717 - root_mean_squared_error: 2.7698 - val_loss: 6.3947 - val_root_mean_squared_error: 2.5288\n",
      "Epoch 19/20\n",
      "169070/500000 [=========>....................] - ETA: 2:55 - loss: 7.2058 - root_mean_squared_error: 2.6844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 327s 655us/sample - loss: 7.6675 - root_mean_squared_error: 2.7690 - val_loss: 6.3966 - val_root_mean_squared_error: 2.5291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:17<00:00, 221.05it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "for store_id in STORE_IDS:\n",
    "    BASE_GRID_DF = pd.read_pickle(f'{SAV_BASE_PATH}/BASE_FEATURES.pkl')\n",
    "    grid_df = BASE_GRID_DF[(BASE_GRID_DF['store_id']==store_id)]\n",
    "    del BASE_GRID_DF\n",
    "    part1 = (grid_df['d']>START_TRAIN)&(grid_df['d']<=END_TRAIN-2*part_len)\n",
    "    part2 = (grid_df['d']>START_TRAIN+part_len)&(grid_df['d']<=END_TRAIN-part_len)\n",
    "    part3 = (grid_df['d']>START_TRAIN+2*part_len)&(grid_df['d']<=END_TRAIN)\n",
    "\n",
    "    X_part1, y_part1, X2_part1 = get_train_valid(grid_df[part1])\n",
    "    X_part2, y_part2, X2_part2 = get_train_valid(grid_df[part2])\n",
    "    X_part3, y_part3, X2_part3 = get_train_valid(grid_df[part3])\n",
    "    \n",
    "    np.save(f'{SAV_BASE_PATH}/X_part1_{store_id}.npy', X_part1) # save\n",
    "    np.save(f'{SAV_BASE_PATH}/X2_part1_{store_id}.npy', X2_part1) # save\n",
    "    np.save(f'{SAV_BASE_PATH}/y_part1_{store_id}.npy', y_part1) # save\n",
    "    np.save(f'{SAV_BASE_PATH}/X_part2_{store_id}.npy', X_part2) # save\n",
    "    np.save(f'{SAV_BASE_PATH}/X2_part2_{store_id}.npy', X2_part2) # save\n",
    "    np.save(f'{SAV_BASE_PATH}/y_part2_{store_id}.npy', y_part2) # save\n",
    "    np.save(f'{SAV_BASE_PATH}/X_part3_{store_id}.npy', X_part3) # save\n",
    "    np.save(f'{SAV_BASE_PATH}/X2_part3_{store_id}.npy', X2_part3) # save\n",
    "    np.save(f'{SAV_BASE_PATH}/y_part3_{store_id}.npy', y_part3) # save\n",
    "    \n",
    "    # X_part1 = np.load(f'X_part1.npy') # load\n",
    "    # y_part1 = np.load(f'y_part1.npy') # load\n",
    "    # X_part2 = np.load(f'X_part2.npy') # load\n",
    "    # y_part2 = np.load(f'y_part2.npy') # load\n",
    "    # X_part3 = np.load(f'X_part3.npy') # load\n",
    "    # y_part3 = np.load(f'y_part3.npy') # load\n",
    "    \n",
    "    X_train = np.vstack([X_part1, X_part2])\n",
    "    X2_train = np.vstack([X2_part1, X2_part2])\n",
    "    y_train = np.vstack([y_part1, y_part2])\n",
    "    X_valid = X_part3\n",
    "    X2_valid = X2_part3\n",
    "    y_valid = y_part3\n",
    "    train_sample_index = np.random.choice(X_train.shape[0], 500_000)\n",
    "    valid_sample_index = np.random.choice(X_valid.shape[0], 200_000)\n",
    "    \n",
    "    model = train_model(X_train[train_sample_index][:,:], X2_train[train_sample_index], y_train[train_sample_index], \n",
    "                    X_valid[valid_sample_index][:,:], X2_valid[valid_sample_index], y_valid[valid_sample_index], \n",
    "                    store_id, SAV_BASE_PATH, 28, 39, epochs=20)\n",
    "    \n",
    "    pred_df_i = predict_samples(grid_df, model)\n",
    "    pred_df = pd.concat([pred_df, pred_df_i], axis=0)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 40586.18937710277\n",
      "F2 29395.143401602167\n",
      "F3 38120.38545977829\n",
      "F4 36982.47288805284\n",
      "F5 33591.79892578081\n",
      "F6 39587.439021511425\n",
      "F7 21188.550194994838\n",
      "F8 30484.770024415222\n",
      "F9 35838.44382213248\n",
      "F10 42286.74087745728\n",
      "F11 27302.81191282044\n",
      "F12 31864.939928364183\n",
      "F13 36296.47553243057\n",
      "F14 31806.939007062843\n",
      "F15 36411.397060816176\n",
      "F16 40450.16693109856\n",
      "F17 17131.708616930875\n",
      "F18 33480.58410119888\n",
      "F19 23496.48269185616\n",
      "F20 34811.43517611466\n",
      "F21 38752.0814780636\n",
      "F22 39937.21767022612\n",
      "F23 27844.90706532309\n",
      "F24 40845.706697984686\n",
      "F25 25612.66726968481\n",
      "F26 39288.13686922821\n",
      "F27 39248.542891609424\n",
      "F28 34933.17951326945\n"
     ]
    }
   ],
   "source": [
    "for col in [f'F{i}' for i in range(1,29)]:\n",
    "    print(col, pred_df[col].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928475</td>\n",
       "      <td>1.088036</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>1.026586</td>\n",
       "      <td>0.547378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.222985</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036828</td>\n",
       "      <td>0.810852</td>\n",
       "      <td>0.573717</td>\n",
       "      <td>0.759222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.016626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.601889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_002_CA_1_validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455638</td>\n",
       "      <td>0.636054</td>\n",
       "      <td>0.360710</td>\n",
       "      <td>0.294070</td>\n",
       "      <td>0.092625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361501</td>\n",
       "      <td>0.190376</td>\n",
       "      <td>0.128430</td>\n",
       "      <td>0.463296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_003_CA_1_validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.494741</td>\n",
       "      <td>0.323444</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>0.142067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676567</td>\n",
       "      <td>0.619101</td>\n",
       "      <td>0.481467</td>\n",
       "      <td>0.353034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_004_CA_1_validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.015525</td>\n",
       "      <td>2.188738</td>\n",
       "      <td>1.849086</td>\n",
       "      <td>2.785250</td>\n",
       "      <td>2.958735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.067468</td>\n",
       "      <td>...</td>\n",
       "      <td>4.352099</td>\n",
       "      <td>4.261330</td>\n",
       "      <td>5.083395</td>\n",
       "      <td>5.753962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.373944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.045892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.907110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_005_CA_1_validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.465038</td>\n",
       "      <td>1.265729</td>\n",
       "      <td>1.287864</td>\n",
       "      <td>1.192603</td>\n",
       "      <td>1.236912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.745727</td>\n",
       "      <td>...</td>\n",
       "      <td>1.239331</td>\n",
       "      <td>1.134817</td>\n",
       "      <td>1.429517</td>\n",
       "      <td>1.915966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.213023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.360599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60975</th>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60976</th>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60977</th>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60978</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60979</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60980 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id   F1        F2        F3        F4  \\\n",
       "0      FOODS_1_001_CA_1_validation  0.0  0.928475  1.088036  0.856354   \n",
       "1      FOODS_1_002_CA_1_validation  0.0  0.455638  0.636054  0.360710   \n",
       "2      FOODS_1_003_CA_1_validation  0.0  0.553006  0.494741  0.323444   \n",
       "3      FOODS_1_004_CA_1_validation  0.0  3.015525  2.188738  1.849086   \n",
       "4      FOODS_1_005_CA_1_validation  0.0  1.465038  1.265729  1.287864   \n",
       "...                            ...  ...       ...       ...       ...   \n",
       "60975  FOODS_3_823_WI_3_evaluation  0.0  0.000000  0.000000  0.000000   \n",
       "60976  FOODS_3_824_WI_3_evaluation  0.0  0.000000  0.000000  0.000000   \n",
       "60977  FOODS_3_825_WI_3_evaluation  0.0  0.000000  0.000000  0.000000   \n",
       "60978  FOODS_3_826_WI_3_evaluation  0.0  0.000000  0.000000  0.000000   \n",
       "60979  FOODS_3_827_WI_3_evaluation  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "             F5        F6   F7   F8        F9  ...       F19       F20  \\\n",
       "0      1.026586  0.547378  0.0  0.0  1.222985  ...  1.036828  0.810852   \n",
       "1      0.294070  0.092625  0.0  0.0  0.830625  ...  0.361501  0.190376   \n",
       "2      0.643956  0.142067  0.0  0.0  0.695731  ...  0.676567  0.619101   \n",
       "3      2.785250  2.958735  0.0  0.0  5.067468  ...  4.352099  4.261330   \n",
       "4      1.192603  1.236912  0.0  0.0  1.745727  ...  1.239331  1.134817   \n",
       "...         ...       ...  ...  ...       ...  ...       ...       ...   \n",
       "60975  0.000000  0.000000  0.0  0.0  0.000000  ...  0.000000  0.000000   \n",
       "60976  0.000000  0.000000  0.0  0.0  0.000000  ...  0.000000  0.000000   \n",
       "60977  0.000000  0.000000  0.0  0.0  0.000000  ...  0.000000  0.000000   \n",
       "60978  0.000000  0.000000  0.0  0.0  0.000000  ...  0.000000  0.000000   \n",
       "60979  0.000000  0.000000  0.0  0.0  0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "            F21       F22  F23       F24  F25       F26  F27       F28  \n",
       "0      0.573717  0.759222  0.0  1.016626  0.0  0.601889  0.0  0.689259  \n",
       "1      0.128430  0.463296  0.0  0.762140  0.0  0.177825  0.0  0.411012  \n",
       "2      0.481467  0.353034  0.0  0.724214  0.0  0.561560  0.0  0.398130  \n",
       "3      5.083395  5.753962  0.0  4.373944  0.0  3.045892  0.0  5.907110  \n",
       "4      1.429517  1.915966  0.0  1.489210  0.0  1.213023  0.0  1.360599  \n",
       "...         ...       ...  ...       ...  ...       ...  ...       ...  \n",
       "60975  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  \n",
       "60976  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  \n",
       "60977  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  \n",
       "60978  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  \n",
       "60979  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  \n",
       "\n",
       "[60980 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(f'{ORIGINAL}/sample_submission.csv')\n",
    "pred_df = pd.concat([pred_df, sample_submission[~sample_submission['id'].isin(pred_df.id.unique().tolist())]], axis=0)\n",
    "pred_df.to_csv('../cache/submission/lstm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
