{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from module.prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _make_lag_roll(base_test, target, shift_day, roll_wind):\n",
    "#     # target, shift_day, roll_wind = LAG_DAY[0],LAG_DAY[1],LAG_DAY[2]\n",
    "#     lag_df = base_test[['id','d',target]]\n",
    "#     col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n",
    "#     lag_df[col_name] = lag_df.groupby(['id'])[target].rolling(roll_wind).parallel_apply(np.mean).reset_index(0, drop=True)\n",
    "#     print(lag_df[col_name].shape, lag_df.groupby(['id'])[col_name].transform(lambda x: x.shift(shift_day)).shape)\n",
    "    \n",
    "#     lag_df[col_name] = lag_df.groupby(['id'])[col_name].transform(lambda x: x.shift(shift_day))\n",
    "\n",
    "#     # grid_df[f'rolling{i}_shift(shift_day)_fft_diff_amp_top{top_no}'] = grid_df.groupby([\"id\"])[\"sales_diff\"].rolling(\n",
    "#     #     i).parallel_apply(fft_peak).reset_index(0, drop=True)\n",
    "#     # grid_df[f'rolling{i}_shift(shift_day)_fft_diff_amp_top{top_no}'] = grid_df.groupby([\"id\"])[\n",
    "#     #     f'rolling{i}_shift(shift_day)_fft_diff_amp_top{top_no}'].transform(lambda x: x.shift(shift_day))\n",
    "#     return lag_df[[col_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "END_TRAIN =  1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory ../cache/ver620\n",
      "melt_train_df 47.10912537574768\n",
      "extract_price_features 37.248167991638184\n",
      "extract_calendar_features 71.56659507751465\n",
      "extract_rolling_features 757.5818192958832\n",
      "extract_encode_features 20.057915210723877\n",
      "extract_sliding_shift_features 536.9259903430939\n",
      "Mem. usage decreased to 7557.09 Mb (33.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(TEMP_FEATURE_PKL):\n",
    "    train_df = pd.read_csv(f'{ORI_CSV_PATH}/sales_train_evaluation.csv')\n",
    "#     train_df = train_df[train_df['id'].isin(IDS[:100])]\n",
    "    prices_df = pd.read_csv(f'{ORI_CSV_PATH}/sell_prices.csv')\n",
    "    calendar_df = pd.read_csv(f'{ORI_CSV_PATH}/calendar.csv')\n",
    "    try:\n",
    "        if not os.path.exists(BASE_PATH):\n",
    "            os.makedirs(BASE_PATH)\n",
    "    except OSError:\n",
    "        print(\"Creation of the directory %s failed\" % BASE_PATH)\n",
    "    else:\n",
    "        print(\"Successfully created the directory %s\" % BASE_PATH)\n",
    "\n",
    "    grid_df = extract_features(train_df, prices_df, calendar_df, target=TARGET, nan_mask_d=1913+28)\n",
    "    \n",
    "    grid_df['item_id'] = grid_df['item_id'].astype('category')\n",
    "    grid_df['dept_id'] = grid_df['dept_id'].astype('category')\n",
    "    grid_df['cat_id'] = grid_df['cat_id'].astype('category')\n",
    "#     grid_df['item_id'] = grid_df['item_id'].apply(lambda x: int(x.split('_')[-1])).astype('category')\n",
    "#     grid_df['dept_id'] = grid_df['dept_id'].apply(lambda x: int(x.split('_')[-1])).astype('category')\n",
    "#     grid_df['cat_id'] = grid_df['cat_id'].replace({'HOBBIES': 0, 'HOUSEHOLD': 1, 'FOODS': 2}).astype('category')\n",
    "#     for col in ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']:\n",
    "#         grid_df[col] = grid_df[col].replace(\n",
    "#             dict(zip(grid_df[col].unique(), np.arange(grid_df[col].unique().shape[0])))).astype('category')\n",
    "    grid_df = reduce_mem_usage(grid_df)\n",
    "    grid_df.to_pickle(TEMP_FEATURE_PKL)\n",
    "    del grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = pd.read_pickle(TEMP_FEATURE_PKL)\n",
    "grid_df['groups'] = grid_df['tm_y'].astype(str) + '_' + (grid_df['tm_m']//3).astype(str)\n",
    "grid_df.to_pickle(TEMP_FEATURE_PKL)\n",
    "del grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_cols = dict(zip(STORES_IDS, [M5_FEATURES]*len(STORES_IDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.lgbm_baseline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_1\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 2.55244\tvalid_1's rmse: 2.7168\n",
      "[200]\ttraining's rmse: 2.43996\tvalid_1's rmse: 2.63446\n",
      "[300]\ttraining's rmse: 2.40508\tvalid_1's rmse: 2.61255\n",
      "[400]\ttraining's rmse: 2.38333\tvalid_1's rmse: 2.60171\n",
      "[500]\ttraining's rmse: 2.36491\tvalid_1's rmse: 2.59293\n",
      "[600]\ttraining's rmse: 2.34944\tvalid_1's rmse: 2.5875\n",
      "[700]\ttraining's rmse: 2.33517\tvalid_1's rmse: 2.58384\n",
      "[800]\ttraining's rmse: 2.32239\tvalid_1's rmse: 2.57984\n",
      "[900]\ttraining's rmse: 2.31123\tvalid_1's rmse: 2.57748\n",
      "[1000]\ttraining's rmse: 2.30199\tvalid_1's rmse: 2.57539\n",
      "[1100]\ttraining's rmse: 2.29205\tvalid_1's rmse: 2.57405\n",
      "[1200]\ttraining's rmse: 2.2828\tvalid_1's rmse: 2.57351\n",
      "[1300]\ttraining's rmse: 2.274\tvalid_1's rmse: 2.57247\n",
      "[1400]\ttraining's rmse: 2.26552\tvalid_1's rmse: 2.57173\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 2.56737\tvalid_1's rmse: 2.64068\n",
      "[200]\ttraining's rmse: 2.46575\tvalid_1's rmse: 2.5373\n",
      "[300]\ttraining's rmse: 2.431\tvalid_1's rmse: 2.51164\n",
      "[400]\ttraining's rmse: 2.40823\tvalid_1's rmse: 2.50019\n",
      "[500]\ttraining's rmse: 2.39118\tvalid_1's rmse: 2.49218\n",
      "[600]\ttraining's rmse: 2.37469\tvalid_1's rmse: 2.48718\n",
      "[700]\ttraining's rmse: 2.36175\tvalid_1's rmse: 2.4828\n",
      "[800]\ttraining's rmse: 2.34953\tvalid_1's rmse: 2.48083\n",
      "[900]\ttraining's rmse: 2.33914\tvalid_1's rmse: 2.47891\n",
      "[1000]\ttraining's rmse: 2.32907\tvalid_1's rmse: 2.47764\n",
      "[1100]\ttraining's rmse: 2.3192\tvalid_1's rmse: 2.47588\n",
      "[1200]\ttraining's rmse: 2.31046\tvalid_1's rmse: 2.47486\n",
      "[1300]\ttraining's rmse: 2.30214\tvalid_1's rmse: 2.47288\n",
      "[1400]\ttraining's rmse: 2.29365\tvalid_1's rmse: 2.47228\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 2.64865\tvalid_1's rmse: 2.46073\n",
      "[200]\ttraining's rmse: 2.53731\tvalid_1's rmse: 2.37706\n",
      "[300]\ttraining's rmse: 2.49874\tvalid_1's rmse: 2.36029\n",
      "[400]\ttraining's rmse: 2.47411\tvalid_1's rmse: 2.35245\n",
      "[500]\ttraining's rmse: 2.45505\tvalid_1's rmse: 2.34779\n",
      "[600]\ttraining's rmse: 2.43814\tvalid_1's rmse: 2.34457\n",
      "[700]\ttraining's rmse: 2.42397\tvalid_1's rmse: 2.34257\n",
      "[800]\ttraining's rmse: 2.41031\tvalid_1's rmse: 2.34137\n",
      "[900]\ttraining's rmse: 2.39841\tvalid_1's rmse: 2.34041\n",
      "[1000]\ttraining's rmse: 2.38705\tvalid_1's rmse: 2.34015\n",
      "[1100]\ttraining's rmse: 2.37617\tvalid_1's rmse: 2.33983\n",
      "[1200]\ttraining's rmse: 2.36672\tvalid_1's rmse: 2.33957\n",
      "[1300]\ttraining's rmse: 2.35737\tvalid_1's rmse: 2.33981\n",
      "[1400]\ttraining's rmse: 2.34853\tvalid_1's rmse: 2.33939\n",
      "Train CA_2\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 2.0206\tvalid_1's rmse: 2.15767\n",
      "[200]\ttraining's rmse: 1.97497\tvalid_1's rmse: 2.12005\n",
      "[300]\ttraining's rmse: 1.95874\tvalid_1's rmse: 2.11326\n",
      "[400]\ttraining's rmse: 1.94819\tvalid_1's rmse: 2.11007\n",
      "[500]\ttraining's rmse: 1.93914\tvalid_1's rmse: 2.10871\n",
      "[600]\ttraining's rmse: 1.93169\tvalid_1's rmse: 2.10768\n",
      "[700]\ttraining's rmse: 1.92469\tvalid_1's rmse: 2.1073\n",
      "[800]\ttraining's rmse: 1.91804\tvalid_1's rmse: 2.10703\n",
      "[900]\ttraining's rmse: 1.91182\tvalid_1's rmse: 2.10678\n",
      "[1000]\ttraining's rmse: 1.90629\tvalid_1's rmse: 2.10717\n",
      "[1100]\ttraining's rmse: 1.90039\tvalid_1's rmse: 2.10728\n",
      "[1200]\ttraining's rmse: 1.89478\tvalid_1's rmse: 2.10752\n",
      "[1300]\ttraining's rmse: 1.88948\tvalid_1's rmse: 2.10788\n",
      "[1400]\ttraining's rmse: 1.88449\tvalid_1's rmse: 2.10817\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 2.04936\tvalid_1's rmse: 2.0816\n",
      "[200]\ttraining's rmse: 2.00784\tvalid_1's rmse: 2.04312\n",
      "[300]\ttraining's rmse: 1.99104\tvalid_1's rmse: 2.03507\n",
      "[400]\ttraining's rmse: 1.9791\tvalid_1's rmse: 2.03146\n",
      "[500]\ttraining's rmse: 1.96916\tvalid_1's rmse: 2.02958\n",
      "[600]\ttraining's rmse: 1.96077\tvalid_1's rmse: 2.02869\n",
      "[700]\ttraining's rmse: 1.95281\tvalid_1's rmse: 2.0279\n",
      "[800]\ttraining's rmse: 1.94513\tvalid_1's rmse: 2.02739\n",
      "[900]\ttraining's rmse: 1.93816\tvalid_1's rmse: 2.02694\n",
      "[1000]\ttraining's rmse: 1.93172\tvalid_1's rmse: 2.02723\n",
      "[1100]\ttraining's rmse: 1.92529\tvalid_1's rmse: 2.02712\n",
      "[1200]\ttraining's rmse: 1.91948\tvalid_1's rmse: 2.02739\n",
      "[1300]\ttraining's rmse: 1.91362\tvalid_1's rmse: 2.02747\n",
      "[1400]\ttraining's rmse: 1.90846\tvalid_1's rmse: 2.0277\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 2.09594\tvalid_1's rmse: 1.96826\n",
      "[200]\ttraining's rmse: 2.05191\tvalid_1's rmse: 1.94424\n",
      "[300]\ttraining's rmse: 2.0359\tvalid_1's rmse: 1.93898\n",
      "[400]\ttraining's rmse: 2.02562\tvalid_1's rmse: 1.93602\n",
      "[500]\ttraining's rmse: 2.01682\tvalid_1's rmse: 1.9346\n",
      "[600]\ttraining's rmse: 2.00861\tvalid_1's rmse: 1.9338\n",
      "[700]\ttraining's rmse: 2.00143\tvalid_1's rmse: 1.93311\n",
      "[800]\ttraining's rmse: 1.99437\tvalid_1's rmse: 1.93301\n",
      "[900]\ttraining's rmse: 1.98781\tvalid_1's rmse: 1.93328\n",
      "[1000]\ttraining's rmse: 1.98182\tvalid_1's rmse: 1.93344\n",
      "[1100]\ttraining's rmse: 1.97603\tvalid_1's rmse: 1.93361\n",
      "[1200]\ttraining's rmse: 1.97049\tvalid_1's rmse: 1.93399\n",
      "[1300]\ttraining's rmse: 1.96483\tvalid_1's rmse: 1.93443\n",
      "[1400]\ttraining's rmse: 1.95959\tvalid_1's rmse: 1.93479\n",
      "Train CA_3\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 3.65394\tvalid_1's rmse: 3.9277\n",
      "[200]\ttraining's rmse: 3.43693\tvalid_1's rmse: 3.70155\n",
      "[300]\ttraining's rmse: 3.35374\tvalid_1's rmse: 3.65084\n",
      "[400]\ttraining's rmse: 3.30521\tvalid_1's rmse: 3.63475\n",
      "[500]\ttraining's rmse: 3.26825\tvalid_1's rmse: 3.62357\n",
      "[600]\ttraining's rmse: 3.23588\tvalid_1's rmse: 3.61738\n",
      "[700]\ttraining's rmse: 3.21077\tvalid_1's rmse: 3.61625\n",
      "[800]\ttraining's rmse: 3.18955\tvalid_1's rmse: 3.61698\n",
      "[900]\ttraining's rmse: 3.17101\tvalid_1's rmse: 3.6168\n",
      "[1000]\ttraining's rmse: 3.15355\tvalid_1's rmse: 3.62\n",
      "[1100]\ttraining's rmse: 3.13624\tvalid_1's rmse: 3.62039\n",
      "[1200]\ttraining's rmse: 3.12169\tvalid_1's rmse: 3.62279\n",
      "[1300]\ttraining's rmse: 3.10846\tvalid_1's rmse: 3.6258\n",
      "[1400]\ttraining's rmse: 3.09589\tvalid_1's rmse: 3.62698\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 3.71034\tvalid_1's rmse: 3.76885\n",
      "[200]\ttraining's rmse: 3.47679\tvalid_1's rmse: 3.62489\n",
      "[300]\ttraining's rmse: 3.39071\tvalid_1's rmse: 3.57738\n",
      "[400]\ttraining's rmse: 3.35459\tvalid_1's rmse: 3.56266\n",
      "[500]\ttraining's rmse: 3.32709\tvalid_1's rmse: 3.55211\n",
      "[600]\ttraining's rmse: 3.30594\tvalid_1's rmse: 3.54359\n",
      "[700]\ttraining's rmse: 3.28666\tvalid_1's rmse: 3.54126\n",
      "[800]\ttraining's rmse: 3.26745\tvalid_1's rmse: 3.53336\n",
      "[900]\ttraining's rmse: 3.25033\tvalid_1's rmse: 3.53182\n",
      "[1000]\ttraining's rmse: 3.23273\tvalid_1's rmse: 3.5246\n",
      "[1100]\ttraining's rmse: 3.21726\tvalid_1's rmse: 3.52232\n",
      "[1200]\ttraining's rmse: 3.20408\tvalid_1's rmse: 3.52081\n",
      "[1300]\ttraining's rmse: 3.1902\tvalid_1's rmse: 3.5191\n",
      "[1400]\ttraining's rmse: 3.17762\tvalid_1's rmse: 3.51652\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 3.79611\tvalid_1's rmse: 3.5709\n",
      "[200]\ttraining's rmse: 3.54593\tvalid_1's rmse: 3.39301\n",
      "[300]\ttraining's rmse: 3.46477\tvalid_1's rmse: 3.35568\n",
      "[400]\ttraining's rmse: 3.41648\tvalid_1's rmse: 3.34111\n",
      "[500]\ttraining's rmse: 3.38022\tvalid_1's rmse: 3.33393\n",
      "[600]\ttraining's rmse: 3.34732\tvalid_1's rmse: 3.33034\n",
      "[700]\ttraining's rmse: 3.31995\tvalid_1's rmse: 3.3259\n",
      "[800]\ttraining's rmse: 3.29603\tvalid_1's rmse: 3.32298\n",
      "[900]\ttraining's rmse: 3.27436\tvalid_1's rmse: 3.32348\n",
      "[1000]\ttraining's rmse: 3.25532\tvalid_1's rmse: 3.32285\n",
      "[1100]\ttraining's rmse: 3.23724\tvalid_1's rmse: 3.32215\n",
      "[1200]\ttraining's rmse: 3.22116\tvalid_1's rmse: 3.32314\n",
      "[1300]\ttraining's rmse: 3.20647\tvalid_1's rmse: 3.32427\n",
      "[1400]\ttraining's rmse: 3.19268\tvalid_1's rmse: 3.32395\n",
      "Train CA_4\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 1.52504\tvalid_1's rmse: 1.5237\n",
      "[200]\ttraining's rmse: 1.49618\tvalid_1's rmse: 1.49633\n",
      "[300]\ttraining's rmse: 1.48487\tvalid_1's rmse: 1.48943\n",
      "[400]\ttraining's rmse: 1.4776\tvalid_1's rmse: 1.48643\n",
      "[500]\ttraining's rmse: 1.47148\tvalid_1's rmse: 1.48518\n",
      "[600]\ttraining's rmse: 1.46593\tvalid_1's rmse: 1.48419\n",
      "[700]\ttraining's rmse: 1.46068\tvalid_1's rmse: 1.48353\n",
      "[800]\ttraining's rmse: 1.4559\tvalid_1's rmse: 1.4829\n",
      "[900]\ttraining's rmse: 1.45139\tvalid_1's rmse: 1.4828\n",
      "[1000]\ttraining's rmse: 1.44711\tvalid_1's rmse: 1.4827\n",
      "[1100]\ttraining's rmse: 1.44302\tvalid_1's rmse: 1.48275\n",
      "[1200]\ttraining's rmse: 1.43873\tvalid_1's rmse: 1.48262\n",
      "[1300]\ttraining's rmse: 1.43487\tvalid_1's rmse: 1.48268\n",
      "[1400]\ttraining's rmse: 1.43099\tvalid_1's rmse: 1.48235\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 1.53279\tvalid_1's rmse: 1.50518\n",
      "[200]\ttraining's rmse: 1.50355\tvalid_1's rmse: 1.47838\n",
      "[300]\ttraining's rmse: 1.49195\tvalid_1's rmse: 1.47162\n",
      "[400]\ttraining's rmse: 1.48433\tvalid_1's rmse: 1.46834\n",
      "[500]\ttraining's rmse: 1.47814\tvalid_1's rmse: 1.46658\n",
      "[600]\ttraining's rmse: 1.47285\tvalid_1's rmse: 1.46546\n",
      "[700]\ttraining's rmse: 1.46762\tvalid_1's rmse: 1.46469\n",
      "[800]\ttraining's rmse: 1.46249\tvalid_1's rmse: 1.46379\n",
      "[900]\ttraining's rmse: 1.45798\tvalid_1's rmse: 1.46347\n",
      "[1000]\ttraining's rmse: 1.45362\tvalid_1's rmse: 1.46305\n",
      "[1100]\ttraining's rmse: 1.44954\tvalid_1's rmse: 1.46286\n",
      "[1200]\ttraining's rmse: 1.44554\tvalid_1's rmse: 1.46258\n",
      "[1300]\ttraining's rmse: 1.44175\tvalid_1's rmse: 1.46255\n",
      "[1400]\ttraining's rmse: 1.43786\tvalid_1's rmse: 1.46241\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 1.51152\tvalid_1's rmse: 1.56359\n",
      "[200]\ttraining's rmse: 1.47609\tvalid_1's rmse: 1.54222\n",
      "[300]\ttraining's rmse: 1.46473\tvalid_1's rmse: 1.53777\n",
      "[400]\ttraining's rmse: 1.45721\tvalid_1's rmse: 1.53534\n",
      "[500]\ttraining's rmse: 1.45123\tvalid_1's rmse: 1.53366\n",
      "[600]\ttraining's rmse: 1.44602\tvalid_1's rmse: 1.53239\n",
      "[700]\ttraining's rmse: 1.44088\tvalid_1's rmse: 1.53145\n",
      "[800]\ttraining's rmse: 1.43637\tvalid_1's rmse: 1.53103\n",
      "[900]\ttraining's rmse: 1.43216\tvalid_1's rmse: 1.53079\n",
      "[1000]\ttraining's rmse: 1.42813\tvalid_1's rmse: 1.53077\n",
      "[1100]\ttraining's rmse: 1.42431\tvalid_1's rmse: 1.53074\n",
      "[1200]\ttraining's rmse: 1.42058\tvalid_1's rmse: 1.53077\n",
      "[1300]\ttraining's rmse: 1.41722\tvalid_1's rmse: 1.53075\n",
      "[1400]\ttraining's rmse: 1.41349\tvalid_1's rmse: 1.53092\n",
      "Train TX_1\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 2.17589\tvalid_1's rmse: 2.14473\n",
      "[200]\ttraining's rmse: 2.09551\tvalid_1's rmse: 2.09594\n",
      "[300]\ttraining's rmse: 2.06497\tvalid_1's rmse: 2.08296\n",
      "[400]\ttraining's rmse: 2.04523\tvalid_1's rmse: 2.07778\n",
      "[500]\ttraining's rmse: 2.02839\tvalid_1's rmse: 2.0744\n",
      "[600]\ttraining's rmse: 2.01461\tvalid_1's rmse: 2.07222\n",
      "[700]\ttraining's rmse: 2.00279\tvalid_1's rmse: 2.07004\n",
      "[800]\ttraining's rmse: 1.99156\tvalid_1's rmse: 2.06902\n",
      "[900]\ttraining's rmse: 1.98246\tvalid_1's rmse: 2.06829\n",
      "[1000]\ttraining's rmse: 1.97245\tvalid_1's rmse: 2.06758\n",
      "[1100]\ttraining's rmse: 1.96318\tvalid_1's rmse: 2.0674\n",
      "[1200]\ttraining's rmse: 1.95459\tvalid_1's rmse: 2.06776\n",
      "[1300]\ttraining's rmse: 1.94577\tvalid_1's rmse: 2.06832\n",
      "[1400]\ttraining's rmse: 1.93698\tvalid_1's rmse: 2.06812\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 2.13452\tvalid_1's rmse: 2.2174\n",
      "[200]\ttraining's rmse: 2.06003\tvalid_1's rmse: 2.1395\n",
      "[300]\ttraining's rmse: 2.03459\tvalid_1's rmse: 2.12154\n",
      "[400]\ttraining's rmse: 2.018\tvalid_1's rmse: 2.1139\n",
      "[500]\ttraining's rmse: 2.00489\tvalid_1's rmse: 2.11007\n",
      "[600]\ttraining's rmse: 1.9929\tvalid_1's rmse: 2.10716\n",
      "[700]\ttraining's rmse: 1.98251\tvalid_1's rmse: 2.10543\n",
      "[800]\ttraining's rmse: 1.97249\tvalid_1's rmse: 2.10511\n",
      "[900]\ttraining's rmse: 1.96301\tvalid_1's rmse: 2.10346\n",
      "[1000]\ttraining's rmse: 1.95463\tvalid_1's rmse: 2.10351\n",
      "[1100]\ttraining's rmse: 1.94554\tvalid_1's rmse: 2.10305\n",
      "[1200]\ttraining's rmse: 1.93759\tvalid_1's rmse: 2.10289\n",
      "[1300]\ttraining's rmse: 1.92971\tvalid_1's rmse: 2.10314\n",
      "[1400]\ttraining's rmse: 1.92211\tvalid_1's rmse: 2.10355\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 2.15802\tvalid_1's rmse: 2.15276\n",
      "[200]\ttraining's rmse: 2.08456\tvalid_1's rmse: 2.08684\n",
      "[300]\ttraining's rmse: 2.05634\tvalid_1's rmse: 2.06836\n",
      "[400]\ttraining's rmse: 2.03989\tvalid_1's rmse: 2.06046\n",
      "[500]\ttraining's rmse: 2.0266\tvalid_1's rmse: 2.0569\n",
      "[600]\ttraining's rmse: 2.01528\tvalid_1's rmse: 2.05444\n",
      "[700]\ttraining's rmse: 2.00461\tvalid_1's rmse: 2.05195\n",
      "[800]\ttraining's rmse: 1.9956\tvalid_1's rmse: 2.05003\n",
      "[900]\ttraining's rmse: 1.98694\tvalid_1's rmse: 2.04883\n",
      "[1000]\ttraining's rmse: 1.9789\tvalid_1's rmse: 2.04783\n",
      "[1100]\ttraining's rmse: 1.97099\tvalid_1's rmse: 2.04718\n",
      "[1200]\ttraining's rmse: 1.96384\tvalid_1's rmse: 2.04728\n",
      "[1300]\ttraining's rmse: 1.95679\tvalid_1's rmse: 2.04676\n",
      "[1400]\ttraining's rmse: 1.9501\tvalid_1's rmse: 2.04622\n",
      "Train TX_2\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 2.67562\tvalid_1's rmse: 2.41784\n",
      "[200]\ttraining's rmse: 2.55129\tvalid_1's rmse: 2.35845\n",
      "[300]\ttraining's rmse: 2.50748\tvalid_1's rmse: 2.34096\n",
      "[400]\ttraining's rmse: 2.48248\tvalid_1's rmse: 2.33153\n",
      "[500]\ttraining's rmse: 2.46208\tvalid_1's rmse: 2.3252\n",
      "[600]\ttraining's rmse: 2.44571\tvalid_1's rmse: 2.32052\n",
      "[700]\ttraining's rmse: 2.43187\tvalid_1's rmse: 2.31803\n",
      "[800]\ttraining's rmse: 2.41787\tvalid_1's rmse: 2.31599\n",
      "[900]\ttraining's rmse: 2.4056\tvalid_1's rmse: 2.31488\n",
      "[1000]\ttraining's rmse: 2.39378\tvalid_1's rmse: 2.31362\n",
      "[1100]\ttraining's rmse: 2.38307\tvalid_1's rmse: 2.31274\n",
      "[1200]\ttraining's rmse: 2.37272\tvalid_1's rmse: 2.31251\n",
      "[1300]\ttraining's rmse: 2.36338\tvalid_1's rmse: 2.31254\n",
      "[1400]\ttraining's rmse: 2.35365\tvalid_1's rmse: 2.31195\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 2.45554\tvalid_1's rmse: 2.86401\n",
      "[200]\ttraining's rmse: 2.35218\tvalid_1's rmse: 2.7265\n",
      "[300]\ttraining's rmse: 2.31791\tvalid_1's rmse: 2.69347\n",
      "[400]\ttraining's rmse: 2.29713\tvalid_1's rmse: 2.68291\n",
      "[500]\ttraining's rmse: 2.28099\tvalid_1's rmse: 2.67714\n",
      "[600]\ttraining's rmse: 2.2673\tvalid_1's rmse: 2.67199\n",
      "[700]\ttraining's rmse: 2.2548\tvalid_1's rmse: 2.66924\n",
      "[800]\ttraining's rmse: 2.24319\tvalid_1's rmse: 2.66776\n",
      "[900]\ttraining's rmse: 2.23292\tvalid_1's rmse: 2.66542\n",
      "[1000]\ttraining's rmse: 2.22285\tvalid_1's rmse: 2.66435\n",
      "[1100]\ttraining's rmse: 2.21344\tvalid_1's rmse: 2.66283\n",
      "[1200]\ttraining's rmse: 2.20475\tvalid_1's rmse: 2.66203\n",
      "[1300]\ttraining's rmse: 2.19582\tvalid_1's rmse: 2.66128\n",
      "[1400]\ttraining's rmse: 2.18709\tvalid_1's rmse: 2.66108\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 2.60952\tvalid_1's rmse: 2.51922\n",
      "[200]\ttraining's rmse: 2.49498\tvalid_1's rmse: 2.4267\n",
      "[300]\ttraining's rmse: 2.45383\tvalid_1's rmse: 2.40736\n",
      "[400]\ttraining's rmse: 2.429\tvalid_1's rmse: 2.39802\n",
      "[500]\ttraining's rmse: 2.4074\tvalid_1's rmse: 2.39269\n",
      "[600]\ttraining's rmse: 2.39023\tvalid_1's rmse: 2.38946\n",
      "[700]\ttraining's rmse: 2.37542\tvalid_1's rmse: 2.38691\n",
      "[800]\ttraining's rmse: 2.36251\tvalid_1's rmse: 2.38568\n",
      "[900]\ttraining's rmse: 2.34964\tvalid_1's rmse: 2.38456\n",
      "[1000]\ttraining's rmse: 2.3384\tvalid_1's rmse: 2.3839\n",
      "[1100]\ttraining's rmse: 2.32814\tvalid_1's rmse: 2.38339\n",
      "[1200]\ttraining's rmse: 2.31783\tvalid_1's rmse: 2.38221\n",
      "[1300]\ttraining's rmse: 2.30823\tvalid_1's rmse: 2.38127\n",
      "[1400]\ttraining's rmse: 2.29893\tvalid_1's rmse: 2.38118\n",
      "Train TX_3\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 2.19103\tvalid_1's rmse: 2.33943\n",
      "[200]\ttraining's rmse: 2.09432\tvalid_1's rmse: 2.23265\n",
      "[300]\ttraining's rmse: 2.06092\tvalid_1's rmse: 2.2117\n",
      "[400]\ttraining's rmse: 2.03926\tvalid_1's rmse: 2.20407\n",
      "[500]\ttraining's rmse: 2.02345\tvalid_1's rmse: 2.20007\n",
      "[600]\ttraining's rmse: 2.00934\tvalid_1's rmse: 2.19795\n",
      "[700]\ttraining's rmse: 1.99662\tvalid_1's rmse: 2.19626\n",
      "[800]\ttraining's rmse: 1.98609\tvalid_1's rmse: 2.19481\n",
      "[900]\ttraining's rmse: 1.97624\tvalid_1's rmse: 2.19395\n",
      "[1000]\ttraining's rmse: 1.96699\tvalid_1's rmse: 2.1941\n",
      "[1100]\ttraining's rmse: 1.95796\tvalid_1's rmse: 2.19409\n",
      "[1200]\ttraining's rmse: 1.94889\tvalid_1's rmse: 2.19417\n",
      "[1300]\ttraining's rmse: 1.94053\tvalid_1's rmse: 2.19464\n",
      "[1400]\ttraining's rmse: 1.9329\tvalid_1's rmse: 2.19549\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 2.25453\tvalid_1's rmse: 2.23411\n",
      "[200]\ttraining's rmse: 2.15097\tvalid_1's rmse: 2.16642\n",
      "[300]\ttraining's rmse: 2.11399\tvalid_1's rmse: 2.14914\n",
      "[400]\ttraining's rmse: 2.09255\tvalid_1's rmse: 2.14106\n",
      "[500]\ttraining's rmse: 2.07521\tvalid_1's rmse: 2.13594\n",
      "[600]\ttraining's rmse: 2.06099\tvalid_1's rmse: 2.1341\n",
      "[700]\ttraining's rmse: 2.04791\tvalid_1's rmse: 2.13215\n",
      "[800]\ttraining's rmse: 2.0363\tvalid_1's rmse: 2.13089\n",
      "[900]\ttraining's rmse: 2.02587\tvalid_1's rmse: 2.12981\n",
      "[1000]\ttraining's rmse: 2.01688\tvalid_1's rmse: 2.12924\n",
      "[1100]\ttraining's rmse: 2.00842\tvalid_1's rmse: 2.12947\n",
      "[1200]\ttraining's rmse: 1.99951\tvalid_1's rmse: 2.12888\n",
      "[1300]\ttraining's rmse: 1.99117\tvalid_1's rmse: 2.12894\n",
      "[1400]\ttraining's rmse: 1.984\tvalid_1's rmse: 2.12936\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 2.25605\tvalid_1's rmse: 2.18445\n",
      "[200]\ttraining's rmse: 2.15886\tvalid_1's rmse: 2.10238\n",
      "[300]\ttraining's rmse: 2.12562\tvalid_1's rmse: 2.08507\n",
      "[400]\ttraining's rmse: 2.10388\tvalid_1's rmse: 2.07607\n",
      "[500]\ttraining's rmse: 2.08741\tvalid_1's rmse: 2.07041\n",
      "[600]\ttraining's rmse: 2.07307\tvalid_1's rmse: 2.0678\n",
      "[700]\ttraining's rmse: 2.05964\tvalid_1's rmse: 2.06473\n",
      "[800]\ttraining's rmse: 2.04787\tvalid_1's rmse: 2.06228\n",
      "[900]\ttraining's rmse: 2.03619\tvalid_1's rmse: 2.06068\n",
      "[1000]\ttraining's rmse: 2.02672\tvalid_1's rmse: 2.05999\n",
      "[1100]\ttraining's rmse: 2.01745\tvalid_1's rmse: 2.05924\n",
      "[1200]\ttraining's rmse: 2.00862\tvalid_1's rmse: 2.05792\n",
      "[1300]\ttraining's rmse: 2.00002\tvalid_1's rmse: 2.05737\n",
      "[1400]\ttraining's rmse: 1.99192\tvalid_1's rmse: 2.05742\n",
      "Train WI_1\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 1.73332\tvalid_1's rmse: 1.69496\n",
      "[200]\ttraining's rmse: 1.68312\tvalid_1's rmse: 1.67282\n",
      "[300]\ttraining's rmse: 1.66575\tvalid_1's rmse: 1.66906\n",
      "[400]\ttraining's rmse: 1.65433\tvalid_1's rmse: 1.66752\n",
      "[500]\ttraining's rmse: 1.64544\tvalid_1's rmse: 1.66644\n",
      "[600]\ttraining's rmse: 1.63731\tvalid_1's rmse: 1.66574\n",
      "[700]\ttraining's rmse: 1.63022\tvalid_1's rmse: 1.66502\n",
      "[800]\ttraining's rmse: 1.62335\tvalid_1's rmse: 1.66455\n",
      "[900]\ttraining's rmse: 1.6172\tvalid_1's rmse: 1.66413\n",
      "[1000]\ttraining's rmse: 1.61144\tvalid_1's rmse: 1.66389\n",
      "[1100]\ttraining's rmse: 1.60589\tvalid_1's rmse: 1.66373\n",
      "[1200]\ttraining's rmse: 1.60047\tvalid_1's rmse: 1.66359\n",
      "[1300]\ttraining's rmse: 1.59531\tvalid_1's rmse: 1.66377\n",
      "[1400]\ttraining's rmse: 1.59056\tvalid_1's rmse: 1.66394\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 1.70858\tvalid_1's rmse: 1.78991\n",
      "[200]\ttraining's rmse: 1.66255\tvalid_1's rmse: 1.74586\n",
      "[300]\ttraining's rmse: 1.64785\tvalid_1's rmse: 1.73517\n",
      "[400]\ttraining's rmse: 1.63852\tvalid_1's rmse: 1.73031\n",
      "[500]\ttraining's rmse: 1.63084\tvalid_1's rmse: 1.72715\n",
      "[600]\ttraining's rmse: 1.62399\tvalid_1's rmse: 1.72495\n",
      "[700]\ttraining's rmse: 1.61834\tvalid_1's rmse: 1.72344\n",
      "[800]\ttraining's rmse: 1.61281\tvalid_1's rmse: 1.72232\n",
      "[900]\ttraining's rmse: 1.60708\tvalid_1's rmse: 1.72136\n",
      "[1000]\ttraining's rmse: 1.60179\tvalid_1's rmse: 1.72083\n",
      "[1100]\ttraining's rmse: 1.59728\tvalid_1's rmse: 1.72044\n",
      "[1200]\ttraining's rmse: 1.59264\tvalid_1's rmse: 1.72022\n",
      "[1300]\ttraining's rmse: 1.58846\tvalid_1's rmse: 1.72001\n",
      "[1400]\ttraining's rmse: 1.58414\tvalid_1's rmse: 1.7201\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 1.72588\tvalid_1's rmse: 1.72636\n",
      "[200]\ttraining's rmse: 1.68226\tvalid_1's rmse: 1.68285\n",
      "[300]\ttraining's rmse: 1.66601\tvalid_1's rmse: 1.67549\n",
      "[400]\ttraining's rmse: 1.65502\tvalid_1's rmse: 1.67225\n",
      "[500]\ttraining's rmse: 1.64603\tvalid_1's rmse: 1.67018\n",
      "[600]\ttraining's rmse: 1.6384\tvalid_1's rmse: 1.66892\n",
      "[700]\ttraining's rmse: 1.63087\tvalid_1's rmse: 1.66792\n",
      "[800]\ttraining's rmse: 1.62438\tvalid_1's rmse: 1.66715\n",
      "[900]\ttraining's rmse: 1.61838\tvalid_1's rmse: 1.66632\n",
      "[1000]\ttraining's rmse: 1.61282\tvalid_1's rmse: 1.66582\n",
      "[1100]\ttraining's rmse: 1.60737\tvalid_1's rmse: 1.66582\n",
      "[1200]\ttraining's rmse: 1.60213\tvalid_1's rmse: 1.66527\n",
      "[1300]\ttraining's rmse: 1.59723\tvalid_1's rmse: 1.66539\n",
      "[1400]\ttraining's rmse: 1.59247\tvalid_1's rmse: 1.66533\n",
      "Train WI_2\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 2.64682\tvalid_1's rmse: 2.80421\n",
      "[200]\ttraining's rmse: 2.58453\tvalid_1's rmse: 2.73881\n",
      "[300]\ttraining's rmse: 2.55979\tvalid_1's rmse: 2.72537\n",
      "[400]\ttraining's rmse: 2.54095\tvalid_1's rmse: 2.71804\n",
      "[500]\ttraining's rmse: 2.52565\tvalid_1's rmse: 2.71479\n",
      "[600]\ttraining's rmse: 2.51033\tvalid_1's rmse: 2.71211\n",
      "[700]\ttraining's rmse: 2.49766\tvalid_1's rmse: 2.71038\n",
      "[800]\ttraining's rmse: 2.48542\tvalid_1's rmse: 2.70902\n",
      "[900]\ttraining's rmse: 2.47401\tvalid_1's rmse: 2.70844\n",
      "[1000]\ttraining's rmse: 2.46354\tvalid_1's rmse: 2.70783\n",
      "[1100]\ttraining's rmse: 2.45262\tvalid_1's rmse: 2.70734\n",
      "[1200]\ttraining's rmse: 2.44255\tvalid_1's rmse: 2.7071\n",
      "[1300]\ttraining's rmse: 2.43296\tvalid_1's rmse: 2.70712\n",
      "[1400]\ttraining's rmse: 2.42323\tvalid_1's rmse: 2.7081\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 2.74552\tvalid_1's rmse: 2.57582\n",
      "[200]\ttraining's rmse: 2.66954\tvalid_1's rmse: 2.54023\n",
      "[300]\ttraining's rmse: 2.63918\tvalid_1's rmse: 2.53402\n",
      "[400]\ttraining's rmse: 2.61995\tvalid_1's rmse: 2.52997\n",
      "[500]\ttraining's rmse: 2.60333\tvalid_1's rmse: 2.52728\n",
      "[600]\ttraining's rmse: 2.58876\tvalid_1's rmse: 2.5256\n",
      "[700]\ttraining's rmse: 2.57447\tvalid_1's rmse: 2.52421\n",
      "[800]\ttraining's rmse: 2.56029\tvalid_1's rmse: 2.52369\n",
      "[900]\ttraining's rmse: 2.54775\tvalid_1's rmse: 2.52418\n",
      "[1000]\ttraining's rmse: 2.53553\tvalid_1's rmse: 2.524\n",
      "[1100]\ttraining's rmse: 2.52314\tvalid_1's rmse: 2.52429\n",
      "[1200]\ttraining's rmse: 2.51287\tvalid_1's rmse: 2.52399\n",
      "[1300]\ttraining's rmse: 2.50217\tvalid_1's rmse: 2.52432\n",
      "[1400]\ttraining's rmse: 2.49119\tvalid_1's rmse: 2.52487\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 2.68062\tvalid_1's rmse: 2.73978\n",
      "[200]\ttraining's rmse: 2.61213\tvalid_1's rmse: 2.6901\n",
      "[300]\ttraining's rmse: 2.58584\tvalid_1's rmse: 2.67866\n",
      "[400]\ttraining's rmse: 2.56816\tvalid_1's rmse: 2.67256\n",
      "[500]\ttraining's rmse: 2.55225\tvalid_1's rmse: 2.66852\n",
      "[600]\ttraining's rmse: 2.5391\tvalid_1's rmse: 2.66734\n",
      "[700]\ttraining's rmse: 2.52623\tvalid_1's rmse: 2.6653\n",
      "[800]\ttraining's rmse: 2.51385\tvalid_1's rmse: 2.66427\n",
      "[900]\ttraining's rmse: 2.50162\tvalid_1's rmse: 2.66361\n",
      "[1000]\ttraining's rmse: 2.4905\tvalid_1's rmse: 2.66402\n",
      "[1100]\ttraining's rmse: 2.47968\tvalid_1's rmse: 2.66385\n",
      "[1200]\ttraining's rmse: 2.46965\tvalid_1's rmse: 2.66412\n",
      "[1300]\ttraining's rmse: 2.46017\tvalid_1's rmse: 2.66486\n",
      "[1400]\ttraining's rmse: 2.45023\tvalid_1's rmse: 2.66491\n",
      "Train WI_3\n",
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\.conda\\envs\\tf_gpu\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 2.39181\tvalid_1's rmse: 2.73527\n",
      "[200]\ttraining's rmse: 2.26869\tvalid_1's rmse: 2.6046\n",
      "[300]\ttraining's rmse: 2.22758\tvalid_1's rmse: 2.57201\n",
      "[400]\ttraining's rmse: 2.20436\tvalid_1's rmse: 2.55656\n",
      "[500]\ttraining's rmse: 2.1859\tvalid_1's rmse: 2.54889\n",
      "[600]\ttraining's rmse: 2.17065\tvalid_1's rmse: 2.54327\n",
      "[700]\ttraining's rmse: 2.15475\tvalid_1's rmse: 2.53877\n",
      "[800]\ttraining's rmse: 2.14143\tvalid_1's rmse: 2.53456\n",
      "[900]\ttraining's rmse: 2.12967\tvalid_1's rmse: 2.53381\n",
      "[1000]\ttraining's rmse: 2.1188\tvalid_1's rmse: 2.5325\n",
      "[1100]\ttraining's rmse: 2.10876\tvalid_1's rmse: 2.53308\n",
      "[1200]\ttraining's rmse: 2.09892\tvalid_1's rmse: 2.53306\n",
      "[1300]\ttraining's rmse: 2.08951\tvalid_1's rmse: 2.5332\n",
      "[1400]\ttraining's rmse: 2.07995\tvalid_1's rmse: 2.53317\n",
      "Fold: 1\n",
      "[100]\ttraining's rmse: 2.46279\tvalid_1's rmse: 2.45106\n",
      "[200]\ttraining's rmse: 2.34534\tvalid_1's rmse: 2.34759\n",
      "[300]\ttraining's rmse: 2.29859\tvalid_1's rmse: 2.32235\n",
      "[400]\ttraining's rmse: 2.26863\tvalid_1's rmse: 2.31127\n",
      "[500]\ttraining's rmse: 2.24584\tvalid_1's rmse: 2.30641\n",
      "[600]\ttraining's rmse: 2.22638\tvalid_1's rmse: 2.30383\n",
      "[700]\ttraining's rmse: 2.21019\tvalid_1's rmse: 2.30168\n",
      "[800]\ttraining's rmse: 2.19474\tvalid_1's rmse: 2.30071\n",
      "[900]\ttraining's rmse: 2.18036\tvalid_1's rmse: 2.29964\n",
      "[1000]\ttraining's rmse: 2.16907\tvalid_1's rmse: 2.29977\n",
      "[1100]\ttraining's rmse: 2.15769\tvalid_1's rmse: 2.30041\n",
      "[1200]\ttraining's rmse: 2.14813\tvalid_1's rmse: 2.29978\n",
      "[1300]\ttraining's rmse: 2.13868\tvalid_1's rmse: 2.29997\n",
      "[1400]\ttraining's rmse: 2.12976\tvalid_1's rmse: 2.29992\n",
      "Fold: 2\n",
      "[100]\ttraining's rmse: 2.52971\tvalid_1's rmse: 2.29742\n",
      "[200]\ttraining's rmse: 2.40375\tvalid_1's rmse: 2.22234\n",
      "[300]\ttraining's rmse: 2.35355\tvalid_1's rmse: 2.20175\n",
      "[400]\ttraining's rmse: 2.32252\tvalid_1's rmse: 2.19238\n",
      "[500]\ttraining's rmse: 2.29722\tvalid_1's rmse: 2.18673\n",
      "[600]\ttraining's rmse: 2.27614\tvalid_1's rmse: 2.18311\n",
      "[700]\ttraining's rmse: 2.25876\tvalid_1's rmse: 2.17931\n",
      "[800]\ttraining's rmse: 2.24258\tvalid_1's rmse: 2.17722\n",
      "[900]\ttraining's rmse: 2.22844\tvalid_1's rmse: 2.17584\n",
      "[1000]\ttraining's rmse: 2.21528\tvalid_1's rmse: 2.17462\n",
      "[1100]\ttraining's rmse: 2.20386\tvalid_1's rmse: 2.17421\n",
      "[1200]\ttraining's rmse: 2.19205\tvalid_1's rmse: 2.17327\n",
      "[1300]\ttraining's rmse: 2.1832\tvalid_1's rmse: 2.17312\n",
      "[1400]\ttraining's rmse: 2.17345\tvalid_1's rmse: 2.17285\n",
      "2.1160476243369826 2.276825780693446 0.1607781563564636\n"
     ]
    }
   ],
   "source": [
    "history_df = train_evaluate_model(useful_cols, TARGET, BASE_PATH)#stores_ids=['CA_1']\n",
    "print(history_df.rmse_trn.mean(), history_df.rmse_val.mean(), history_df.rmse_diff.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.to_pickle(f'{BASE_PATH}/lgbm_history_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD0 Predict | Day:1\n",
      "##########  3.32 min round |  3.32 min total |  36736.00 day sales |\n",
      "FOLD0 Predict | Day:2\n",
      "##########  3.32 min round |  6.64 min total |  34976.00 day sales |\n",
      "FOLD0 Predict | Day:3\n",
      "##########  3.32 min round |  9.96 min total |  34528.00 day sales |\n",
      "FOLD0 Predict | Day:4\n",
      "##########  3.31 min round |  13.27 min total |  35040.00 day sales |\n",
      "FOLD0 Predict | Day:5\n",
      "##########  3.34 min round |  16.61 min total |  41312.00 day sales |\n",
      "FOLD0 Predict | Day:6\n",
      "##########  3.34 min round |  19.95 min total |  50624.00 day sales |\n",
      "FOLD0 Predict | Day:7\n",
      "##########  3.35 min round |  23.30 min total |  55040.00 day sales |\n",
      "FOLD0 Predict | Day:8\n",
      "##########  5.36 min round |  28.66 min total |  44160.00 day sales |\n",
      "FOLD0 Predict | Day:9\n",
      "##########  5.39 min round |  34.06 min total |  44384.00 day sales |\n",
      "FOLD0 Predict | Day:10\n",
      "##########  5.41 min round |  39.46 min total |  39296.00 day sales |\n",
      "FOLD0 Predict | Day:11\n",
      "##########  5.38 min round |  44.84 min total |  40800.00 day sales |\n",
      "FOLD0 Predict | Day:12\n",
      "##########  5.34 min round |  50.18 min total |  45408.00 day sales |\n",
      "FOLD0 Predict | Day:13\n",
      "##########  5.32 min round |  55.49 min total |  54144.00 day sales |\n",
      "FOLD0 Predict | Day:14\n",
      "##########  5.34 min round |  60.83 min total |  46432.00 day sales |\n",
      "FOLD0 Predict | Day:15\n",
      "##########  5.37 min round |  66.20 min total |  44704.00 day sales |\n",
      "FOLD0 Predict | Day:16\n",
      "##########  4.78 min round |  70.98 min total |  39488.00 day sales |\n",
      "FOLD0 Predict | Day:17\n",
      "##########  5.54 min round |  76.52 min total |  40928.00 day sales |\n",
      "FOLD0 Predict | Day:18\n",
      "##########  5.79 min round |  82.31 min total |  41312.00 day sales |\n",
      "FOLD0 Predict | Day:19\n",
      "##########  5.85 min round |  88.16 min total |  44256.00 day sales |\n",
      "FOLD0 Predict | Day:20\n",
      "##########  5.82 min round |  93.98 min total |  54304.00 day sales |\n",
      "FOLD0 Predict | Day:21\n",
      "##########  5.86 min round |  99.85 min total |  56384.00 day sales |\n",
      "FOLD0 Predict | Day:22\n",
      "##########  5.84 min round |  105.69 min total |  41792.00 day sales |\n",
      "FOLD0 Predict | Day:23\n",
      "##########  5.85 min round |  111.54 min total |  37984.00 day sales |\n",
      "FOLD0 Predict | Day:24\n",
      "##########  5.81 min round |  117.35 min total |  37376.00 day sales |\n",
      "FOLD0 Predict | Day:25\n",
      "##########  4.92 min round |  122.27 min total |  37216.00 day sales |\n",
      "FOLD0 Predict | Day:26\n",
      "##########  5.57 min round |  127.84 min total |  41984.00 day sales |\n",
      "FOLD0 Predict | Day:27\n",
      "##########  5.51 min round |  133.35 min total |  51456.00 day sales |\n",
      "FOLD0 Predict | Day:28\n",
      "##########  5.53 min round |  138.88 min total |  51584.00 day sales |\n",
      "FOLD1 Predict | Day:1\n",
      "##########  5.69 min round |  5.69 min total |  37536.00 day sales |\n",
      "FOLD1 Predict | Day:2\n",
      "##########  5.81 min round |  11.50 min total |  35808.00 day sales |\n",
      "FOLD1 Predict | Day:3\n",
      "##########  5.85 min round |  17.35 min total |  35072.00 day sales |\n",
      "FOLD1 Predict | Day:4\n",
      "##########  5.80 min round |  23.15 min total |  35808.00 day sales |\n",
      "FOLD1 Predict | Day:5\n",
      "##########  5.33 min round |  28.47 min total |  42944.00 day sales |\n",
      "FOLD1 Predict | Day:6\n",
      "##########  4.73 min round |  33.20 min total |  52128.00 day sales |\n",
      "FOLD1 Predict | Day:7\n",
      "##########  5.71 min round |  38.91 min total |  55040.00 day sales |\n",
      "FOLD1 Predict | Day:8\n",
      "##########  5.79 min round |  44.70 min total |  44896.00 day sales |\n",
      "FOLD1 Predict | Day:9\n",
      "##########  5.80 min round |  50.49 min total |  45344.00 day sales |\n",
      "FOLD1 Predict | Day:10\n",
      "##########  5.78 min round |  56.27 min total |  39392.00 day sales |\n",
      "FOLD1 Predict | Day:11\n",
      "##########  5.62 min round |  61.89 min total |  41568.00 day sales |\n",
      "FOLD1 Predict | Day:12\n",
      "##########  5.49 min round |  67.39 min total |  46528.00 day sales |\n",
      "FOLD1 Predict | Day:13\n",
      "##########  5.57 min round |  72.96 min total |  54944.00 day sales |\n",
      "FOLD1 Predict | Day:14\n",
      "##########  4.83 min round |  77.79 min total |  46720.00 day sales |\n",
      "FOLD1 Predict | Day:15\n",
      "##########  5.50 min round |  83.30 min total |  46208.00 day sales |\n",
      "FOLD1 Predict | Day:16\n",
      "##########  5.54 min round |  88.84 min total |  40256.00 day sales |\n",
      "FOLD1 Predict | Day:17\n",
      "##########  5.57 min round |  94.40 min total |  41472.00 day sales |\n",
      "FOLD1 Predict | Day:18\n",
      "##########  5.61 min round |  100.01 min total |  41792.00 day sales |\n",
      "FOLD1 Predict | Day:19\n",
      "##########  5.55 min round |  105.56 min total |  44864.00 day sales |\n",
      "FOLD1 Predict | Day:20\n",
      "##########  5.52 min round |  111.08 min total |  55328.00 day sales |\n",
      "FOLD1 Predict | Day:21\n",
      "##########  5.50 min round |  116.58 min total |  58624.00 day sales |\n",
      "FOLD1 Predict | Day:22\n",
      "##########  4.78 min round |  121.36 min total |  42944.00 day sales |\n",
      "FOLD1 Predict | Day:23\n",
      "##########  5.36 min round |  126.72 min total |  38944.00 day sales |\n",
      "FOLD1 Predict | Day:24\n",
      "##########  5.34 min round |  132.07 min total |  37888.00 day sales |\n",
      "FOLD1 Predict | Day:25\n",
      "##########  5.33 min round |  137.40 min total |  37952.00 day sales |\n",
      "FOLD1 Predict | Day:26\n",
      "##########  5.35 min round |  142.75 min total |  42880.00 day sales |\n",
      "FOLD1 Predict | Day:27\n",
      "##########  5.37 min round |  148.12 min total |  52256.00 day sales |\n",
      "FOLD1 Predict | Day:28\n",
      "##########  5.37 min round |  153.49 min total |  53536.00 day sales |\n",
      "FOLD2 Predict | Day:1\n",
      "##########  5.38 min round |  5.38 min total |  37376.00 day sales |\n",
      "FOLD2 Predict | Day:2\n",
      "##########  4.41 min round |  9.79 min total |  35712.00 day sales |\n",
      "FOLD2 Predict | Day:3\n",
      "##########  5.36 min round |  15.15 min total |  35200.00 day sales |\n",
      "FOLD2 Predict | Day:4\n",
      "##########  5.37 min round |  20.52 min total |  35872.00 day sales |\n",
      "FOLD2 Predict | Day:5\n",
      "##########  5.35 min round |  25.87 min total |  42560.00 day sales |\n",
      "FOLD2 Predict | Day:6\n",
      "##########  5.36 min round |  31.23 min total |  51648.00 day sales |\n",
      "FOLD2 Predict | Day:7\n",
      "##########  5.36 min round |  36.58 min total |  54752.00 day sales |\n",
      "FOLD2 Predict | Day:8\n",
      "##########  5.37 min round |  41.96 min total |  44544.00 day sales |\n",
      "FOLD2 Predict | Day:9\n",
      "##########  5.35 min round |  47.31 min total |  45024.00 day sales |\n",
      "FOLD2 Predict | Day:10\n",
      "##########  4.74 min round |  52.04 min total |  39360.00 day sales |\n",
      "FOLD2 Predict | Day:11\n",
      "##########  5.70 min round |  57.75 min total |  41280.00 day sales |\n",
      "FOLD2 Predict | Day:12\n",
      "##########  5.70 min round |  63.44 min total |  46368.00 day sales |\n",
      "FOLD2 Predict | Day:13\n",
      "##########  5.70 min round |  69.14 min total |  54656.00 day sales |\n",
      "FOLD2 Predict | Day:14\n",
      "##########  5.73 min round |  74.87 min total |  47008.00 day sales |\n",
      "FOLD2 Predict | Day:15\n",
      "##########  5.69 min round |  80.56 min total |  45920.00 day sales |\n",
      "FOLD2 Predict | Day:16\n",
      "##########  5.72 min round |  86.29 min total |  40160.00 day sales |\n",
      "FOLD2 Predict | Day:17\n",
      "##########  5.69 min round |  91.98 min total |  41376.00 day sales |\n",
      "FOLD2 Predict | Day:18\n",
      "##########  5.71 min round |  97.68 min total |  41760.00 day sales |\n",
      "FOLD2 Predict | Day:19\n",
      "##########  4.93 min round |  102.62 min total |  44704.00 day sales |\n",
      "FOLD2 Predict | Day:20\n",
      "##########  5.73 min round |  108.35 min total |  54912.00 day sales |\n",
      "FOLD2 Predict | Day:21\n",
      "##########  5.65 min round |  114.00 min total |  58496.00 day sales |\n",
      "FOLD2 Predict | Day:22\n",
      "##########  5.68 min round |  119.68 min total |  42624.00 day sales |\n",
      "FOLD2 Predict | Day:23\n",
      "##########  5.72 min round |  125.40 min total |  38752.00 day sales |\n",
      "FOLD2 Predict | Day:24\n",
      "##########  5.72 min round |  131.12 min total |  37568.00 day sales |\n",
      "FOLD2 Predict | Day:25\n",
      "##########  5.70 min round |  136.82 min total |  37568.00 day sales |\n",
      "FOLD2 Predict | Day:26\n",
      "##########  5.75 min round |  142.57 min total |  42496.00 day sales |\n",
      "FOLD2 Predict | Day:27\n",
      "##########  5.72 min round |  148.29 min total |  51872.00 day sales |\n",
      "FOLD2 Predict | Day:28\n",
      "##########  4.79 min round |  153.08 min total |  52928.00 day sales |\n"
     ]
    }
   ],
   "source": [
    "final_all_preds = predict_test(useful_cols, TARGET, BASE_PATH, end_train=END_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_all_preds.to_pickle(f'{BASE_PATH}/lgbm_final_all_preds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_all_preds['id'] = final_all_preds['id'].apply(lambda x: x.replace('evaluation', 'validation'))\n",
    "smaple = pd.read_csv(f'{ORI_CSV_PATH}/sample_submission.csv')\n",
    "submission = pd.concat([final_all_preds ,smaple[30490:]], axis=0)\n",
    "submission.to_csv(f'{BASE_PATH}/lgbm_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_all_preds = pd.read_pickle(f'{BASE_PATH}/lgbm_final_all_preds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.823730</td>\n",
       "      <td>0.749023</td>\n",
       "      <td>0.741699</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.977539</td>\n",
       "      <td>1.131836</td>\n",
       "      <td>1.335938</td>\n",
       "      <td>0.891602</td>\n",
       "      <td>0.940918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859863</td>\n",
       "      <td>1.157227</td>\n",
       "      <td>1.088867</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.784180</td>\n",
       "      <td>0.760742</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.958984</td>\n",
       "      <td>1.183594</td>\n",
       "      <td>1.076172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.191895</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.189087</td>\n",
       "      <td>0.223511</td>\n",
       "      <td>0.290527</td>\n",
       "      <td>0.304443</td>\n",
       "      <td>0.237549</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.315430</td>\n",
       "      <td>0.320068</td>\n",
       "      <td>0.224976</td>\n",
       "      <td>0.208008</td>\n",
       "      <td>0.203491</td>\n",
       "      <td>0.221436</td>\n",
       "      <td>0.240967</td>\n",
       "      <td>0.306885</td>\n",
       "      <td>0.311523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.436035</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.419678</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.586914</td>\n",
       "      <td>0.741699</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623047</td>\n",
       "      <td>0.761230</td>\n",
       "      <td>0.776367</td>\n",
       "      <td>0.509277</td>\n",
       "      <td>0.470215</td>\n",
       "      <td>0.471436</td>\n",
       "      <td>0.488525</td>\n",
       "      <td>0.627930</td>\n",
       "      <td>0.727051</td>\n",
       "      <td>0.706055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1.653320</td>\n",
       "      <td>1.343750</td>\n",
       "      <td>1.386719</td>\n",
       "      <td>1.542969</td>\n",
       "      <td>2.009766</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>3.089844</td>\n",
       "      <td>1.714844</td>\n",
       "      <td>1.476562</td>\n",
       "      <td>...</td>\n",
       "      <td>1.892578</td>\n",
       "      <td>2.527344</td>\n",
       "      <td>3.083984</td>\n",
       "      <td>1.747070</td>\n",
       "      <td>1.501953</td>\n",
       "      <td>1.408203</td>\n",
       "      <td>1.413086</td>\n",
       "      <td>1.935547</td>\n",
       "      <td>2.921875</td>\n",
       "      <td>3.292969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.978516</td>\n",
       "      <td>0.872070</td>\n",
       "      <td>0.930176</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.554688</td>\n",
       "      <td>1.144531</td>\n",
       "      <td>1.127930</td>\n",
       "      <td>...</td>\n",
       "      <td>1.103516</td>\n",
       "      <td>1.537109</td>\n",
       "      <td>1.625977</td>\n",
       "      <td>1.021484</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.926758</td>\n",
       "      <td>0.930664</td>\n",
       "      <td>1.136719</td>\n",
       "      <td>1.529297</td>\n",
       "      <td>1.538086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.379395</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.344238</td>\n",
       "      <td>0.346680</td>\n",
       "      <td>0.390137</td>\n",
       "      <td>0.449463</td>\n",
       "      <td>0.517578</td>\n",
       "      <td>0.540039</td>\n",
       "      <td>0.594238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487061</td>\n",
       "      <td>0.655273</td>\n",
       "      <td>0.760254</td>\n",
       "      <td>0.510742</td>\n",
       "      <td>0.442139</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.375977</td>\n",
       "      <td>0.432617</td>\n",
       "      <td>0.499756</td>\n",
       "      <td>0.526367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.300049</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.274170</td>\n",
       "      <td>0.262451</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.348633</td>\n",
       "      <td>0.372314</td>\n",
       "      <td>0.372070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.405762</td>\n",
       "      <td>0.436523</td>\n",
       "      <td>0.300293</td>\n",
       "      <td>0.238159</td>\n",
       "      <td>0.224121</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.216309</td>\n",
       "      <td>0.281738</td>\n",
       "      <td>0.283447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.497070</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.777344</td>\n",
       "      <td>0.981445</td>\n",
       "      <td>1.088867</td>\n",
       "      <td>1.078125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939941</td>\n",
       "      <td>1.290039</td>\n",
       "      <td>1.474609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.706543</td>\n",
       "      <td>0.708008</td>\n",
       "      <td>0.596680</td>\n",
       "      <td>0.668945</td>\n",
       "      <td>0.819824</td>\n",
       "      <td>0.824707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>0.889648</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.946289</td>\n",
       "      <td>1.255859</td>\n",
       "      <td>1.191406</td>\n",
       "      <td>1.184570</td>\n",
       "      <td>1.240234</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076172</td>\n",
       "      <td>1.431641</td>\n",
       "      <td>1.473633</td>\n",
       "      <td>1.061523</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.888184</td>\n",
       "      <td>0.886230</td>\n",
       "      <td>1.029297</td>\n",
       "      <td>1.126953</td>\n",
       "      <td>1.242188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.182373</td>\n",
       "      <td>0.845215</td>\n",
       "      <td>0.902832</td>\n",
       "      <td>1.382812</td>\n",
       "      <td>1.898438</td>\n",
       "      <td>2.291016</td>\n",
       "      <td>2.095703</td>\n",
       "      <td>1.775391</td>\n",
       "      <td>1.882812</td>\n",
       "      <td>...</td>\n",
       "      <td>1.730469</td>\n",
       "      <td>2.412109</td>\n",
       "      <td>2.236328</td>\n",
       "      <td>1.706055</td>\n",
       "      <td>1.635742</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.563477</td>\n",
       "      <td>1.846680</td>\n",
       "      <td>2.277344</td>\n",
       "      <td>2.158203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        F1        F2        F3        F4  \\\n",
       "0      HOBBIES_1_001_CA_1_validation  0.823730  0.749023  0.741699  0.774902   \n",
       "1      HOBBIES_1_002_CA_1_validation  0.205200  0.191895  0.173828  0.189087   \n",
       "2      HOBBIES_1_003_CA_1_validation  0.436035  0.400635  0.419678  0.421875   \n",
       "3      HOBBIES_1_004_CA_1_validation  1.653320  1.343750  1.386719  1.542969   \n",
       "4      HOBBIES_1_005_CA_1_validation  0.978516  0.872070  0.930176  0.965820   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "30485    FOODS_3_823_WI_3_validation  0.379395  0.343750  0.344238  0.346680   \n",
       "30486    FOODS_3_824_WI_3_validation  0.300049  0.281250  0.274170  0.262451   \n",
       "30487    FOODS_3_825_WI_3_validation  0.601562  0.503906  0.497070  0.506836   \n",
       "30488    FOODS_3_826_WI_3_validation  0.938965  0.889648  0.800781  0.812500   \n",
       "30489    FOODS_3_827_WI_3_validation  0.182373  0.845215  0.902832  1.382812   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0      0.977539  1.131836  1.335938  0.891602  0.940918  ...  0.859863   \n",
       "1      0.223511  0.290527  0.304443  0.237549  0.232422  ...  0.257812   \n",
       "2      0.586914  0.741699  0.682617  0.496094  0.472656  ...  0.623047   \n",
       "3      2.009766  2.734375  3.089844  1.714844  1.476562  ...  1.892578   \n",
       "4      1.132812  1.375000  1.554688  1.144531  1.127930  ...  1.103516   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "30485  0.390137  0.449463  0.517578  0.540039  0.594238  ...  0.487061   \n",
       "30486  0.308838  0.328125  0.348633  0.372314  0.372070  ...  0.285645   \n",
       "30487  0.625000  0.777344  0.981445  1.088867  1.078125  ...  0.939941   \n",
       "30488  0.946289  1.255859  1.191406  1.184570  1.240234  ...  1.076172   \n",
       "30489  1.898438  2.291016  2.095703  1.775391  1.882812  ...  1.730469   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0      1.157227  1.088867  0.875488  0.784180  0.760742  0.819336  0.958984   \n",
       "1      0.315430  0.320068  0.224976  0.208008  0.203491  0.221436  0.240967   \n",
       "2      0.761230  0.776367  0.509277  0.470215  0.471436  0.488525  0.627930   \n",
       "3      2.527344  3.083984  1.747070  1.501953  1.408203  1.413086  1.935547   \n",
       "4      1.537109  1.625977  1.021484  0.917969  0.926758  0.930664  1.136719   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "30485  0.655273  0.760254  0.510742  0.442139  0.414062  0.375977  0.432617   \n",
       "30486  0.405762  0.436523  0.300293  0.238159  0.224121  0.212891  0.216309   \n",
       "30487  1.290039  1.474609  1.000000  0.706543  0.708008  0.596680  0.668945   \n",
       "30488  1.431641  1.473633  1.061523  0.968750  0.888184  0.886230  1.029297   \n",
       "30489  2.412109  2.236328  1.706055  1.635742  1.576172  1.563477  1.846680   \n",
       "\n",
       "            F27       F28  \n",
       "0      1.183594  1.076172  \n",
       "1      0.306885  0.311523  \n",
       "2      0.727051  0.706055  \n",
       "3      2.921875  3.292969  \n",
       "4      1.529297  1.538086  \n",
       "...         ...       ...  \n",
       "30485  0.499756  0.526367  \n",
       "30486  0.281738  0.283447  \n",
       "30487  0.819824  0.824707  \n",
       "30488  1.126953  1.242188  \n",
       "30489  2.277344  2.158203  \n",
       "\n",
       "[30490 rows x 29 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.823730</td>\n",
       "      <td>0.749023</td>\n",
       "      <td>0.741699</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.977539</td>\n",
       "      <td>1.131836</td>\n",
       "      <td>1.335938</td>\n",
       "      <td>0.891602</td>\n",
       "      <td>0.940918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859863</td>\n",
       "      <td>1.157227</td>\n",
       "      <td>1.088867</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.784180</td>\n",
       "      <td>0.760742</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.958984</td>\n",
       "      <td>1.183594</td>\n",
       "      <td>1.076172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.191895</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.189087</td>\n",
       "      <td>0.223511</td>\n",
       "      <td>0.290527</td>\n",
       "      <td>0.304443</td>\n",
       "      <td>0.237549</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.315430</td>\n",
       "      <td>0.320068</td>\n",
       "      <td>0.224976</td>\n",
       "      <td>0.208008</td>\n",
       "      <td>0.203491</td>\n",
       "      <td>0.221436</td>\n",
       "      <td>0.240967</td>\n",
       "      <td>0.306885</td>\n",
       "      <td>0.311523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.436035</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.419678</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.586914</td>\n",
       "      <td>0.741699</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623047</td>\n",
       "      <td>0.761230</td>\n",
       "      <td>0.776367</td>\n",
       "      <td>0.509277</td>\n",
       "      <td>0.470215</td>\n",
       "      <td>0.471436</td>\n",
       "      <td>0.488525</td>\n",
       "      <td>0.627930</td>\n",
       "      <td>0.727051</td>\n",
       "      <td>0.706055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1.653320</td>\n",
       "      <td>1.343750</td>\n",
       "      <td>1.386719</td>\n",
       "      <td>1.542969</td>\n",
       "      <td>2.009766</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>3.089844</td>\n",
       "      <td>1.714844</td>\n",
       "      <td>1.476562</td>\n",
       "      <td>...</td>\n",
       "      <td>1.892578</td>\n",
       "      <td>2.527344</td>\n",
       "      <td>3.083984</td>\n",
       "      <td>1.747070</td>\n",
       "      <td>1.501953</td>\n",
       "      <td>1.408203</td>\n",
       "      <td>1.413086</td>\n",
       "      <td>1.935547</td>\n",
       "      <td>2.921875</td>\n",
       "      <td>3.292969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.978516</td>\n",
       "      <td>0.872070</td>\n",
       "      <td>0.930176</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>1.132812</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.554688</td>\n",
       "      <td>1.144531</td>\n",
       "      <td>1.127930</td>\n",
       "      <td>...</td>\n",
       "      <td>1.103516</td>\n",
       "      <td>1.537109</td>\n",
       "      <td>1.625977</td>\n",
       "      <td>1.021484</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.926758</td>\n",
       "      <td>0.930664</td>\n",
       "      <td>1.136719</td>\n",
       "      <td>1.529297</td>\n",
       "      <td>1.538086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60975</th>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60976</th>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60977</th>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60978</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60979</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60980 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        F1        F2        F3        F4  \\\n",
       "0      HOBBIES_1_001_CA_1_validation  0.823730  0.749023  0.741699  0.774902   \n",
       "1      HOBBIES_1_002_CA_1_validation  0.205200  0.191895  0.173828  0.189087   \n",
       "2      HOBBIES_1_003_CA_1_validation  0.436035  0.400635  0.419678  0.421875   \n",
       "3      HOBBIES_1_004_CA_1_validation  1.653320  1.343750  1.386719  1.542969   \n",
       "4      HOBBIES_1_005_CA_1_validation  0.978516  0.872070  0.930176  0.965820   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "60975    FOODS_3_823_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60976    FOODS_3_824_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60977    FOODS_3_825_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60978    FOODS_3_826_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "60979    FOODS_3_827_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0      0.977539  1.131836  1.335938  0.891602  0.940918  ...  0.859863   \n",
       "1      0.223511  0.290527  0.304443  0.237549  0.232422  ...  0.257812   \n",
       "2      0.586914  0.741699  0.682617  0.496094  0.472656  ...  0.623047   \n",
       "3      2.009766  2.734375  3.089844  1.714844  1.476562  ...  1.892578   \n",
       "4      1.132812  1.375000  1.554688  1.144531  1.127930  ...  1.103516   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "60975  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60976  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60977  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60978  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "60979  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0      1.157227  1.088867  0.875488  0.784180  0.760742  0.819336  0.958984   \n",
       "1      0.315430  0.320068  0.224976  0.208008  0.203491  0.221436  0.240967   \n",
       "2      0.761230  0.776367  0.509277  0.470215  0.471436  0.488525  0.627930   \n",
       "3      2.527344  3.083984  1.747070  1.501953  1.408203  1.413086  1.935547   \n",
       "4      1.537109  1.625977  1.021484  0.917969  0.926758  0.930664  1.136719   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "60975  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60976  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60977  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60978  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "60979  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            F27       F28  \n",
       "0      1.183594  1.076172  \n",
       "1      0.306885  0.311523  \n",
       "2      0.727051  0.706055  \n",
       "3      2.921875  3.292969  \n",
       "4      1.529297  1.538086  \n",
       "...         ...       ...  \n",
       "60975  0.000000  0.000000  \n",
       "60976  0.000000  0.000000  \n",
       "60977  0.000000  0.000000  \n",
       "60978  0.000000  0.000000  \n",
       "60979  0.000000  0.000000  \n",
       "\n",
       "[60980 rows x 29 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(f'{BASE_PATH}/lgbm_baseline.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
