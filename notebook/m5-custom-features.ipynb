{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this kernel I would like to show: \n",
    "## 1. FE creation approaches\n",
    "## 2. Sequential fe validation\n",
    "## 3. Dimension reduction\n",
    "## 4. FE validation by Permutation importance\n",
    "## 5. Mean encodings\n",
    "## 6. Parallelization for FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os, sys, gc, warnings, psutil, random\n",
    "# from sklearn.metrics import rm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Baseline model\n",
    "#################################################################################\n",
    "\n",
    "# We will need some global VARS for future\n",
    "\n",
    "SEED = 42             # Our random seed for everything\n",
    "random.seed(SEED)     # to make all tests \"deterministic\"\n",
    "np.random.seed(SEED)\n",
    "N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "TARGET = 'sales'      # Our Target\n",
    "END_TRAIN = 1913      # And we will use last 28 days as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RMSE\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))\n",
    "\n",
    "def permutation_importance(model, validation_df, features_columns, target, metric=rmse, verbose=0):\n",
    "\n",
    "    list_ = []\n",
    "    # Make normal prediction with our model and save score\n",
    "    validation_df['preds'] = model.predict(validation_df[features_columns])\n",
    "    base_score = metric(validation_df[target], validation_df['preds'])\n",
    "    if verbose>0:\n",
    "        print('Standart RMSE', base_score)\n",
    "\n",
    "    # Now we are looping over all our numerical features\n",
    "    for col in features_columns:\n",
    "\n",
    "        # We will make validation set copy to restore\n",
    "        # features states on each run\n",
    "        temp_df = validation_df.copy()\n",
    "\n",
    "        # Error here appears if we have \"categorical\" features and can't \n",
    "        # do np.random.permutation without disrupt categories\n",
    "        # so we need to check if feature is numerical\n",
    "        if temp_df[col].dtypes.name != 'category':\n",
    "            temp_df[col] = np.random.permutation(temp_df[col].values)\n",
    "            temp_df['preds'] = model.predict(temp_df[features_columns])\n",
    "            cur_score = metric(temp_df[target], temp_df['preds'])\n",
    "            \n",
    "            list_.append({'feature':col, 'permutation_importance':np.round(cur_score - base_score, 4)})\n",
    "            # If our current rmse score is less than base score\n",
    "            # it means that feature most probably is a bad one\n",
    "            # and our model is learning on noise\n",
    "            if verbose>0:\n",
    "                print(col, np.round(cur_score - base_score, 4))\n",
    "            \n",
    "    return pd.DataFrame(list_).sort_values(by=['permutation_importance'], ascending=False)\n",
    "\n",
    "\n",
    "# permutation_importance_df = permutation_importance(estimator, valid_df, features_columns, TARGET, metric=rmse, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2960025 entries, 0 to 2960024\n",
      "Data columns (total 39 columns):\n",
      "id                  category\n",
      "item_id             category\n",
      "dept_id             category\n",
      "cat_id              category\n",
      "store_id            category\n",
      "state_id            category\n",
      "d                   int16\n",
      "sales               float64\n",
      "release             int16\n",
      "sell_price          float16\n",
      "price_max           float16\n",
      "price_min           float16\n",
      "price_std           float16\n",
      "price_mean          float16\n",
      "price_norm          float16\n",
      "price_nunique       float16\n",
      "item_nunique        int16\n",
      "price_momentum      float16\n",
      "price_momentum_m    float16\n",
      "price_momentum_y    float16\n",
      "event_name_1        category\n",
      "event_type_1        category\n",
      "event_name_2        category\n",
      "event_type_2        category\n",
      "snap_CA             category\n",
      "snap_TX             category\n",
      "snap_WI             category\n",
      "is_Halloween        category\n",
      "is_ValentinesDay    category\n",
      "is_Thanksgiving     category\n",
      "is_Christmas        category\n",
      "is_NewYear          category\n",
      "tm_d                int8\n",
      "tm_w                int8\n",
      "tm_m                int8\n",
      "tm_y                int8\n",
      "tm_wm               int8\n",
      "tm_dw               int8\n",
      "tm_w_end            int8\n",
      "dtypes: category(18), float16(10), float64(1), int16(3), int8(7)\n",
      "memory usage: 173.8 MB\n"
     ]
    }
   ],
   "source": [
    "########################### Load data\n",
    "########################### Basic features were created here:\n",
    "########################### https://www.kaggle.com/kyakovlev/m5-simple-fe\n",
    "#################################################################################\n",
    "\n",
    "# Read data\n",
    "grid_df = pd.concat([pd.read_pickle('./grid_part_1.pkl'),\n",
    "                     pd.read_pickle('./grid_part_2.pkl').iloc[:,2:],\n",
    "                     pd.read_pickle('./grid_part_3.pkl').iloc[:,2:]],\n",
    "                     axis=1)\n",
    "\n",
    "# Subsampling\n",
    "# to make all calculations faster.\n",
    "# Keep only 5% of original ids.\n",
    "keep_id = np.array_split(list(grid_df['id'].unique()), 20)[0]\n",
    "grid_df = grid_df[grid_df['id'].isin(keep_id)].reset_index(drop=True)\n",
    "\n",
    "# Let's \"inspect\" our grid DataFrame\n",
    "grid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[302]\ttraining's rmse: 2.83927\tvalid_1's rmse: 2.39352\n"
     ]
    }
   ],
   "source": [
    "########################### Baseline model\n",
    "#################################################################################\n",
    "\n",
    "# We will need some global VARS for future\n",
    "\n",
    "SEED = 42             # Our random seed for everything\n",
    "random.seed(SEED)     # to make all tests \"deterministic\"\n",
    "np.random.seed(SEED)\n",
    "N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "TARGET = 'sales'      # Our Target\n",
    "END_TRAIN = 1913      # And we will use last 28 days as validation\n",
    "\n",
    "# Drop some items from \"TEST\" set part (1914...)\n",
    "grid_df = grid_df[grid_df['d']<=END_TRAIN].reset_index(drop=True)\n",
    "\n",
    "# Features that we want to exclude from training\n",
    "remove_features = ['id','d',TARGET]\n",
    "\n",
    "# Our baseline model serves\n",
    "# to do fast checks of\n",
    "# new features performance \n",
    "\n",
    "# We will use LightGBM for our tests\n",
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',         # Standart boosting type\n",
    "                    'objective': 'regression',       # Standart loss for RMSE\n",
    "                    'metric': ['rmse'],              # as we will use rmse as metric \"proxy\"\n",
    "                    'subsample': 0.8,                \n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.05,           # 0.5 is \"fast enough\" for us\n",
    "                    'num_leaves': 2**7-1,            # We will need model only for fast check\n",
    "                    'min_data_in_leaf': 2**8-1,      # So we want it to train faster even with drop in generalization \n",
    "                    'feature_fraction': 0.8,\n",
    "                    'n_estimators': 5000,            # We don't want to limit training (you can change 5000 to any big enough number)\n",
    "                    'early_stopping_rounds': 30,     # We will stop training almost immediately (if it stops improving) \n",
    "                    'seed': SEED,\n",
    "                    'verbose': -1,\n",
    "                } \n",
    "\n",
    "## RMSE\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))\n",
    "\n",
    "# Small function to make fast features tests\n",
    "# estimator = make_fast_test(grid_df)\n",
    "# it will return lgb booster for future analisys\n",
    "def make_fast_test(df, permutate=False):\n",
    "\n",
    "    features_columns = [col for col in list(df) if col not in remove_features]\n",
    "\n",
    "    tr_x, tr_y = df[df['d']<=(END_TRAIN-28)][features_columns], df[df['d']<=(END_TRAIN-28)][TARGET]              \n",
    "    vl_x, v_y = df[df['d']>(END_TRAIN-28)][features_columns], df[df['d']>(END_TRAIN-28)][TARGET]\n",
    "    \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    valid_data = lgb.Dataset(vl_x, label=v_y)\n",
    "    \n",
    "    estimator = lgb.train(\n",
    "                            lgb_params,\n",
    "                            train_data,\n",
    "                            valid_sets = [train_data,valid_data],\n",
    "                            verbose_eval = 500,\n",
    "                        )\n",
    "    if permutate:\n",
    "        permutation_importance_df = permutation_importance(estimator, df[df['d']>(END_TRAIN-28)], features_columns, TARGET, metric=rmse, verbose=0)\n",
    "    else:\n",
    "        permutation_importance_df = None\n",
    "    \n",
    "    return estimator, permutation_importance_df\n",
    "\n",
    "# Make baseline model\n",
    "baseline_model,permutation_importance_df = make_fast_test(grid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Lets test our normal Lags (7 days)\n",
    "########################### Some more info about lags here:\n",
    "########################### https://www.kaggle.com/kyakovlev/m5-lags-features\n",
    "#################################################################################\n",
    "\n",
    "# Small helper to make lags creation faster\n",
    "from multiprocessing import Pool                # Multiprocess Runs\n",
    "\n",
    "## Multiprocessing Run.\n",
    "# :t_split - int of lags days                   # type: int\n",
    "# :func - Function to apply on each split       # type: python function\n",
    "# This function is NOT 'bulletproof', be carefull and pass only correct types of variables.\n",
    "## Multiprocess Runs\n",
    "def df_parallelize_run(func, t_split):\n",
    "    num_cores = np.min([N_CORES,len(t_split)])\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def make_normal_lag(lag_day):\n",
    "    lag_df = grid_df[['id','d',TARGET]] # not good to use df from \"global space\"\n",
    "    col_name = 'sales_lag_'+str(lag_day)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(lag_day)).astype(np.float16)\n",
    "    return lag_df[[col_name]]\n",
    "\n",
    "# Launch parallel lag creation\n",
    "# and \"append\" to our grid\n",
    "LAGS_SPLIT = [col for col in range(1,1+7)]\n",
    "grid_df = pd.concat([grid_df, df_parallelize_run(make_normal_lag,LAGS_SPLIT)], axis=1)\n",
    "\n",
    "# Make features test\n",
    "test_model,permutation_importance_df  = make_fast_test(grid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standart RMSE 2.2671115304002565\n",
      "release 0.0\n",
      "sell_price 0.003\n",
      "price_max -0.0005\n",
      "price_min 0.0002\n",
      "price_std 0.0063\n",
      "price_mean 0.003\n",
      "price_norm 0.0083\n",
      "price_nunique -0.0022\n",
      "item_nunique 0.0012\n",
      "price_momentum 0.0002\n",
      "price_momentum_m 0.0085\n",
      "price_momentum_y 0.001\n",
      "tm_d 0.0034\n",
      "tm_w -0.0\n",
      "tm_m 0.0\n",
      "tm_y 0.0\n",
      "tm_wm 0.0001\n",
      "tm_dw 0.0951\n",
      "tm_w_end 0.0139\n",
      "sales_lag_1 0.4595\n",
      "sales_lag_2 0.021\n",
      "sales_lag_3 0.0037\n",
      "sales_lag_4 0.0121\n",
      "sales_lag_5 0.0119\n",
      "sales_lag_6 0.0122\n",
      "sales_lag_7 0.0278\n"
     ]
    }
   ],
   "source": [
    "########################### Permutation importance Test\n",
    "########################### https://www.kaggle.com/dansbecker/permutation-importance @dansbecker\n",
    "#################################################################################\n",
    "\n",
    "# Let's creat validation dataset and features\n",
    "features_columns = [col for col in list(grid_df) if col not in remove_features]\n",
    "validation_df = grid_df[grid_df['d']>(END_TRAIN-28)].reset_index(drop=True)\n",
    "\n",
    "# Make normal prediction with our model and save score\n",
    "validation_df['preds'] = test_model.predict(validation_df[features_columns])\n",
    "base_score = rmse(validation_df[TARGET], validation_df['preds'])\n",
    "print('Standart RMSE', base_score)\n",
    "\n",
    "\n",
    "# Now we are looping over all our numerical features\n",
    "for col in features_columns:\n",
    "    \n",
    "    # We will make validation set copy to restore\n",
    "    # features states on each run\n",
    "    temp_df = validation_df.copy()\n",
    "    \n",
    "    # Error here appears if we have \"categorical\" features and can't \n",
    "    # do np.random.permutation without disrupt categories\n",
    "    # so we need to check if feature is numerical\n",
    "    if temp_df[col].dtypes.name != 'category':\n",
    "        temp_df[col] = np.random.permutation(temp_df[col].values)\n",
    "        temp_df['preds'] = test_model.predict(temp_df[features_columns])\n",
    "        cur_score = rmse(temp_df[TARGET], temp_df['preds'])\n",
    "        \n",
    "        # If our current rmse score is less than base score\n",
    "        # it means that feature most probably is a bad one\n",
    "        # and our model is learning on noise\n",
    "        print(col, np.round(cur_score - base_score, 4))\n",
    "\n",
    "# Remove Temp data\n",
    "del temp_df, validation_df\n",
    "\n",
    "# Remove test features\n",
    "# As we will compare performance with baseline model for now\n",
    "keep_cols = [col for col in list(grid_df) if 'sales_lag_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "\n",
    "\n",
    "# Results:\n",
    "## Lags with 1 days shift (nearest past) are important\n",
    "## Some other features are not important and probably just noise\n",
    "## Better make several Permutation runs to confirm useless of the feature\n",
    "## link again https://www.kaggle.com/dansbecker/permutation-importance @dansbecker\n",
    "\n",
    "## price_nunique -0.002 : strong negative values are most probably noise\n",
    "## price_max -0.0002 : values close to 0 need deeper investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[500]\ttraining's rmse: 2.74855\tvalid_1's rmse: 2.37852\n",
      "Early stopping, best iteration is:\n",
      "[517]\ttraining's rmse: 2.74172\tvalid_1's rmse: 2.37664\n",
      "Standart RMSE 2.376639096408089\n",
      "release 0.0\n",
      "sell_price 0.0064\n",
      "price_max 0.0075\n",
      "price_min 0.0043\n",
      "price_std 0.0021\n",
      "price_mean 0.0018\n",
      "price_norm 0.0111\n",
      "price_nunique 0.0188\n",
      "item_nunique 0.0076\n",
      "price_momentum 0.0006\n",
      "price_momentum_m 0.0364\n",
      "price_momentum_y 0.0088\n",
      "tm_d 0.0042\n",
      "tm_w 0.0042\n",
      "tm_m 0.0015\n",
      "tm_y 0.0\n",
      "tm_wm -0.0007\n",
      "tm_dw 0.1074\n",
      "tm_w_end 0.0153\n",
      "sales_lag_56 0.0148\n",
      "sales_lag_57 -0.0022\n",
      "sales_lag_58 0.0182\n",
      "sales_lag_59 0.0033\n",
      "sales_lag_60 0.0036\n",
      "sales_lag_61 -0.0031\n",
      "sales_lag_62 0.0019\n"
     ]
    }
   ],
   "source": [
    "########################### Lets test far away Lags (7 days with 56 days shift)\n",
    "########################### and check permutation importance\n",
    "#################################################################################\n",
    "\n",
    "LAGS_SPLIT = [col for col in range(56,56+7)]\n",
    "grid_df = pd.concat([grid_df, df_parallelize_run(make_normal_lag,LAGS_SPLIT)], axis=1)\n",
    "test_model = make_fast_test(grid_df)\n",
    "\n",
    "features_columns = [col for col in list(grid_df) if col not in remove_features]\n",
    "validation_df = grid_df[grid_df['d']>(END_TRAIN-28)].reset_index(drop=True)\n",
    "validation_df['preds'] = test_model.predict(validation_df[features_columns])\n",
    "base_score = rmse(validation_df[TARGET], validation_df['preds'])\n",
    "print('Standart RMSE', base_score)\n",
    "\n",
    "for col in features_columns:\n",
    "    temp_df = validation_df.copy()\n",
    "    if temp_df[col].dtypes.name != 'category':\n",
    "        temp_df[col] = np.random.permutation(temp_df[col].values)\n",
    "        temp_df['preds'] = test_model.predict(temp_df[features_columns])\n",
    "        cur_score = rmse(temp_df[TARGET], temp_df['preds'])\n",
    "        print(col, np.round(cur_score - base_score, 4))\n",
    "\n",
    "del temp_df, validation_df\n",
    "        \n",
    "# Remove test features\n",
    "# As we will compare performance with baseline model for now\n",
    "keep_cols = [col for col in list(grid_df) if 'sales_lag_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "\n",
    "\n",
    "# Results:\n",
    "## Lags with 56 days shift (far away past) are not as important\n",
    "## as nearest past lags\n",
    "## and at some point will be just noise for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA: id 7\n",
      "[0.72243389 0.06622603 0.05933126 0.04200092 0.0388851  0.03610057\n",
      " 0.03502223]\n",
      "Columns to keep: ['sales_pca_id7_1', 'sales_pca_id7_2', 'sales_pca_id7_3']\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[424]\ttraining's rmse: 2.60036\tvalid_1's rmse: 2.27278\n",
      "Standart RMSE 2.2727815880775624\n",
      "release 0.0\n",
      "sell_price 0.0097\n",
      "price_max 0.0008\n",
      "price_min -0.0005\n",
      "price_std 0.002\n",
      "price_mean 0.0021\n",
      "price_norm 0.0049\n",
      "price_nunique -0.0063\n",
      "item_nunique -0.0011\n",
      "price_momentum 0.0\n",
      "price_momentum_m 0.0165\n",
      "price_momentum_y 0.0009\n",
      "tm_d 0.0103\n",
      "tm_w -0.0001\n",
      "tm_m 0.0016\n",
      "tm_y 0.0\n",
      "tm_wm 0.0005\n",
      "tm_dw 0.208\n",
      "tm_w_end 0.0073\n",
      "sales_pca_id7_1 1.4509\n",
      "sales_pca_id7_2 0.016\n",
      "sales_pca_id7_3 0.007\n"
     ]
    }
   ],
   "source": [
    "########################### PCA\n",
    "#################################################################################\n",
    "\n",
    "# The main question here - can we have \n",
    "# almost same rmse boost with less features\n",
    "# less dimensionality?\n",
    "\n",
    "# Lets try PCA and make 7->3 dimensionality reduction\n",
    "\n",
    "# PCA is \"unsupervised\" learning\n",
    "# and with shifted target we can be sure\n",
    "# that we have no Target leakage\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def make_pca(df, pca_col, n_days):\n",
    "    print('PCA:', pca_col, n_days)\n",
    "    \n",
    "    # We don't need any other columns to make pca\n",
    "    pca_df = df[[pca_col,'d',TARGET]]\n",
    "    \n",
    "    # If we are doing pca for other series \"levels\" \n",
    "    # we need to agg first\n",
    "    if pca_col != 'id':\n",
    "        merge_base = pca_df[[pca_col,'d']]\n",
    "        pca_df = pca_df.groupby([pca_col,'d'])[TARGET].agg(['sum']).reset_index()\n",
    "        pca_df[TARGET] = pca_df['sum']\n",
    "        del pca_df['sum']\n",
    "    \n",
    "    # Min/Max scaling\n",
    "    pca_df[TARGET] = pca_df[TARGET]/pca_df[TARGET].max()\n",
    "    \n",
    "    # Making \"lag\" in old way (not parallel)\n",
    "    LAG_DAYS = [col for col in range(1,n_days+1)]\n",
    "    format_s = '{}_pca_'+pca_col+str(n_days)+'_{}'\n",
    "    pca_df = pca_df.assign(**{\n",
    "            format_s.format(col, l): pca_df.groupby([pca_col])[col].transform(lambda x: x.shift(l))\n",
    "            for l in LAG_DAYS\n",
    "            for col in [TARGET]\n",
    "        })\n",
    "    \n",
    "    pca_columns = list(pca_df)[3:]\n",
    "    pca_df[pca_columns] = pca_df[pca_columns].fillna(0)\n",
    "    pca = PCA(random_state=SEED)\n",
    "    \n",
    "    # You can use fit_transform here\n",
    "    pca.fit(pca_df[pca_columns])\n",
    "    pca_df[pca_columns] = pca.transform(pca_df[pca_columns])\n",
    "    \n",
    "    print(pca.explained_variance_ratio_)\n",
    "    \n",
    "    # we will keep only 3 most \"valuable\" columns/dimensions \n",
    "    keep_cols = pca_columns[:3]\n",
    "    print('Columns to keep:', keep_cols)\n",
    "    \n",
    "    # If we are doing pca for other series \"levels\"\n",
    "    # we need merge back our results to merge_base df\n",
    "    # and only than return resulted df\n",
    "    # I'll skip that step here\n",
    "    \n",
    "    return pca_df[keep_cols]\n",
    "\n",
    "\n",
    "# Make PCA\n",
    "grid_df = pd.concat([grid_df, make_pca(grid_df,'id',7)], axis=1)\n",
    "\n",
    "# Make features test\n",
    "test_model = make_fast_test(grid_df)\n",
    "\n",
    "features_columns = [col for col in list(grid_df) if col not in remove_features]\n",
    "validation_df = grid_df[grid_df['d']>(END_TRAIN-28)].reset_index(drop=True)\n",
    "validation_df['preds'] = test_model.predict(validation_df[features_columns])\n",
    "base_score = rmse(validation_df[TARGET], validation_df['preds'])\n",
    "print('Standart RMSE', base_score)\n",
    "\n",
    "for col in features_columns:\n",
    "    temp_df = validation_df.copy()\n",
    "    if temp_df[col].dtypes.name != 'category':\n",
    "        temp_df[col] = np.random.permutation(temp_df[col].values)\n",
    "        temp_df['preds'] = test_model.predict(temp_df[features_columns])\n",
    "        cur_score = rmse(temp_df[TARGET], temp_df['preds'])\n",
    "        print(col, np.round(cur_score - base_score, 4))\n",
    "\n",
    "# Remove test features\n",
    "# As we will compare performance with baseline model for now\n",
    "keep_cols = [col for col in list(grid_df) if '_pca_' not in col]\n",
    "grid_df = grid_df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding item_id\n",
      "Encoding cat_id\n",
      "Encoding dept_id\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[500]\ttraining's rmse: 2.74303\tvalid_1's rmse: 2.37972\n",
      "Early stopping, best iteration is:\n",
      "[490]\ttraining's rmse: 2.74583\tvalid_1's rmse: 2.37905\n",
      "Standart RMSE 2.3790545391991853\n",
      "release 0.0\n",
      "sell_price 0.0254\n",
      "price_max 0.0095\n",
      "price_min 0.0001\n",
      "price_std 0.0081\n",
      "price_mean 0.0004\n",
      "price_norm 0.0117\n",
      "price_nunique -0.0045\n",
      "item_nunique -0.0026\n",
      "price_momentum -0.0\n",
      "price_momentum_m 0.0345\n",
      "price_momentum_y 0.0109\n",
      "tm_d 0.0068\n",
      "tm_w 0.007\n",
      "tm_m 0.0011\n",
      "tm_y 0.0\n",
      "tm_wm 0.0011\n",
      "tm_dw 0.1773\n",
      "tm_w_end 0.0124\n",
      "sales_item_id_encoding_std 0.0116\n",
      "sales_item_id_encoding_mean 1.9479\n",
      "sales_cat_id_encoding_std 0.0008\n",
      "sales_cat_id_encoding_mean 0.0012\n",
      "sales_dept_id_encoding_std 0.0029\n",
      "sales_dept_id_encoding_mean -0.0\n"
     ]
    }
   ],
   "source": [
    "########################### Mean/std target encoding\n",
    "#################################################################################\n",
    "\n",
    "# We will use these three columns for test\n",
    "# (in combination with store_id)\n",
    "icols = ['item_id','cat_id','dept_id']\n",
    "\n",
    "# But we can use any other column or even multiple groups\n",
    "# like these ones\n",
    "#            'state_id',\n",
    "#            'store_id',\n",
    "#            'cat_id',\n",
    "#            'dept_id',\n",
    "#            ['state_id', 'cat_id'],\n",
    "#            ['state_id', 'dept_id'],\n",
    "#            ['store_id', 'cat_id'],\n",
    "#            ['store_id', 'dept_id'],\n",
    "#            'item_id',\n",
    "#            ['item_id', 'state_id'],\n",
    "#            ['item_id', 'store_id']\n",
    "\n",
    "# There are several ways to do \"mean\" encoding\n",
    "## K-fold scheme\n",
    "## LOO (leave one out)\n",
    "## Smoothed/regularized \n",
    "## Expanding mean\n",
    "## etc \n",
    "\n",
    "# You can test as many options as you want\n",
    "# and decide what to use\n",
    "# Because of memory issues you can't \n",
    "# use many features.\n",
    "\n",
    "# We will use simple target encoding\n",
    "# by std and mean agg\n",
    "for col in icols:\n",
    "    print('Encoding', col)\n",
    "    temp_df = grid_df[grid_df['d']<=(1913-28)] # to be sure we don't have leakage in our validation set\n",
    "    \n",
    "    temp_df = temp_df.groupby([col,'store_id']).agg({TARGET: ['std','mean']})\n",
    "    joiner = '_'+col+'_encoding_'\n",
    "    temp_df.columns = [joiner.join(col).strip() for col in temp_df.columns.values]\n",
    "    temp_df = temp_df.reset_index()\n",
    "    grid_df = grid_df.merge(temp_df, on=[col,'store_id'], how='left')\n",
    "    del temp_df\n",
    "\n",
    "# Make features test\n",
    "test_model = make_fast_test(grid_df)\n",
    "\n",
    "features_columns = [col for col in list(grid_df) if col not in remove_features]\n",
    "validation_df = grid_df[grid_df['d']>(END_TRAIN-28)].reset_index(drop=True)\n",
    "validation_df['preds'] = test_model.predict(validation_df[features_columns])\n",
    "base_score = rmse(validation_df[TARGET], validation_df['preds'])\n",
    "print('Standart RMSE', base_score)\n",
    "\n",
    "for col in features_columns:\n",
    "    temp_df = validation_df.copy()\n",
    "    if temp_df[col].dtypes.name != 'category':\n",
    "        temp_df[col] = np.random.permutation(temp_df[col].values)\n",
    "        temp_df['preds'] = test_model.predict(temp_df[features_columns])\n",
    "        cur_score = rmse(temp_df[TARGET], temp_df['preds'])\n",
    "        print(col, np.round(cur_score - base_score, 4))\n",
    "        \n",
    "\n",
    "# Remove test features\n",
    "keep_cols = [col for col in list(grid_df) if '_encoding_' not in col]\n",
    "grid_df = grid_df[keep_cols]\n",
    "\n",
    "# Bad thing that for some items  \n",
    "# we are using past and future values.\n",
    "# But we are looking for \"categorical\" similiarity\n",
    "# on a \"long run\". So future here is not a big problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[500]\ttraining's rmse: 2.63222\tvalid_1's rmse: 2.28391\n",
      "Early stopping, best iteration is:\n",
      "[840]\ttraining's rmse: 2.56826\tvalid_1's rmse: 2.27466\n",
      "Standart RMSE 2.2746555036589906\n",
      "release 0.0\n",
      "sell_price 0.0314\n",
      "price_max 0.0207\n",
      "price_min 0.0127\n",
      "price_std 0.0384\n",
      "price_mean 0.0073\n",
      "price_norm 0.0223\n",
      "price_nunique 0.0169\n",
      "item_nunique 0.006\n",
      "price_momentum 0.0001\n",
      "price_momentum_m 0.0174\n",
      "price_momentum_y -0.0001\n",
      "tm_d 0.0072\n",
      "tm_w 0.0016\n",
      "tm_m 0.0009\n",
      "tm_y 0.0\n",
      "tm_wm 0.0005\n",
      "tm_dw 0.2029\n",
      "tm_w_end 0.0061\n",
      "last_sale 0.6512\n"
     ]
    }
   ],
   "source": [
    "########################### Last non O sale\n",
    "#################################################################################\n",
    "\n",
    "def find_last_sale(df,n_day):\n",
    "    \n",
    "    # Limit initial df\n",
    "    ls_df = df[['id','d',TARGET]]\n",
    "    \n",
    "    # Convert target to binary\n",
    "    ls_df['non_zero'] = (ls_df[TARGET]>0).astype(np.int8)\n",
    "    \n",
    "    # Make lags to prevent any leakage\n",
    "    ls_df['non_zero_lag'] = ls_df.groupby(['id'])['non_zero'].transform(lambda x: x.shift(n_day).rolling(2000,1).sum()).fillna(-1)\n",
    "\n",
    "    temp_df = ls_df[['id','d','non_zero_lag']].drop_duplicates(subset=['id','non_zero_lag'])\n",
    "    temp_df.columns = ['id','d_min','non_zero_lag']\n",
    "\n",
    "    ls_df = ls_df.merge(temp_df, on=['id','non_zero_lag'], how='left')\n",
    "    ls_df['last_sale'] = ls_df['d'] - ls_df['d_min']\n",
    "\n",
    "    return ls_df[['last_sale']]\n",
    "\n",
    "\n",
    "# Find last non zero\n",
    "# Need some \"dances\" to fit in memory limit with groupers\n",
    "grid_df = pd.concat([grid_df, find_last_sale(grid_df,1)], axis=1)\n",
    "\n",
    "# Make features test\n",
    "test_model = make_fast_test(grid_df)\n",
    "\n",
    "features_columns = [col for col in list(grid_df) if col not in remove_features]\n",
    "validation_df = grid_df[grid_df['d']>(END_TRAIN-28)].reset_index(drop=True)\n",
    "validation_df['preds'] = test_model.predict(validation_df[features_columns])\n",
    "base_score = rmse(validation_df[TARGET], validation_df['preds'])\n",
    "print('Standart RMSE', base_score)\n",
    "\n",
    "for col in features_columns:\n",
    "    temp_df = validation_df.copy()\n",
    "    if temp_df[col].dtypes.name != 'category':\n",
    "        temp_df[col] = np.random.permutation(temp_df[col].values)\n",
    "        temp_df['preds'] = test_model.predict(temp_df[features_columns])\n",
    "        cur_score = rmse(temp_df[TARGET], temp_df['preds'])\n",
    "        print(col, np.round(cur_score - base_score, 4))\n",
    "\n",
    "# Remove test features\n",
    "keep_cols = [col for col in list(grid_df) if 'last_sale' not in col]\n",
    "grid_df = grid_df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "grid_df = pd.concat([pd.read_pickle('../cache/grid_part_1.pkl'),\n",
    "                     pd.read_pickle('../cache/grid_part_2.pkl').iloc[:,2:],\n",
    "                     pd.read_pickle('../cache/grid_part_3.pkl').iloc[:,2:]],\n",
    "                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 30, 31,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,\n",
       "       15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], dtype=int8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df.tm_d.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>release</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_std</th>\n",
       "      <th>price_mean</th>\n",
       "      <th>price_norm</th>\n",
       "      <th>price_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>price_momentum</th>\n",
       "      <th>price_momentum_m</th>\n",
       "      <th>price_momentum_y</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>is_Halloween</th>\n",
       "      <th>is_ValentinesDay</th>\n",
       "      <th>is_Thanksgiving</th>\n",
       "      <th>is_Christmas</th>\n",
       "      <th>is_NewYear</th>\n",
       "      <th>tm_d</th>\n",
       "      <th>tm_w</th>\n",
       "      <th>tm_m</th>\n",
       "      <th>tm_y</th>\n",
       "      <th>tm_wm</th>\n",
       "      <th>tm_dw</th>\n",
       "      <th>tm_w_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>0.019760</td>\n",
       "      <td>0.476318</td>\n",
       "      <td>0.919922</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.949219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.559570</td>\n",
       "      <td>1.769531</td>\n",
       "      <td>1.559570</td>\n",
       "      <td>0.032745</td>\n",
       "      <td>1.764648</td>\n",
       "      <td>0.881348</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885742</td>\n",
       "      <td>0.896484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_010_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.169922</td>\n",
       "      <td>3.169922</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>0.046356</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.064453</td>\n",
       "      <td>1.043945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_012_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_012</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.980469</td>\n",
       "      <td>6.519531</td>\n",
       "      <td>5.980469</td>\n",
       "      <td>0.115967</td>\n",
       "      <td>6.468750</td>\n",
       "      <td>0.916992</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.958984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_015_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_015</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.720215</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.011337</td>\n",
       "      <td>0.706543</td>\n",
       "      <td>0.972168</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990234</td>\n",
       "      <td>1.001953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_009_CA_1_validation  HOBBIES_1_009  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_010_CA_1_validation  HOBBIES_1_010  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_012_CA_1_validation  HOBBIES_1_012  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_015_CA_1_validation  HOBBIES_1_015  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d  sales  release  sell_price  price_max  price_min  price_std  \\\n",
       "0       CA  1   12.0        0    0.459961   0.500000   0.419922   0.019760   \n",
       "1       CA  1    2.0        0    1.559570   1.769531   1.559570   0.032745   \n",
       "2       CA  1    0.0        0    3.169922   3.169922   2.970703   0.046356   \n",
       "3       CA  1    0.0        0    5.980469   6.519531   5.980469   0.115967   \n",
       "4       CA  1    4.0        0    0.700195   0.720215   0.680176   0.011337   \n",
       "\n",
       "   price_mean  price_norm  price_nunique  item_nunique  price_momentum  \\\n",
       "0    0.476318    0.919922            4.0            16             NaN   \n",
       "1    1.764648    0.881348            2.0             9             NaN   \n",
       "2    2.980469    1.000000            2.0            20             NaN   \n",
       "3    6.468750    0.916992            3.0            71             NaN   \n",
       "4    0.706543    0.972168            3.0            16             NaN   \n",
       "\n",
       "   price_momentum_m  price_momentum_y event_name_1 event_type_1 event_name_2  \\\n",
       "0          0.968750          0.949219          NaN          NaN          NaN   \n",
       "1          0.885742          0.896484          NaN          NaN          NaN   \n",
       "2          1.064453          1.043945          NaN          NaN          NaN   \n",
       "3          0.921875          0.958984          NaN          NaN          NaN   \n",
       "4          0.990234          1.001953          NaN          NaN          NaN   \n",
       "\n",
       "  event_type_2 snap_CA snap_TX snap_WI is_Halloween is_ValentinesDay  \\\n",
       "0          NaN       0       0       0            0                0   \n",
       "1          NaN       0       0       0            0                0   \n",
       "2          NaN       0       0       0            0                0   \n",
       "3          NaN       0       0       0            0                0   \n",
       "4          NaN       0       0       0            0                0   \n",
       "\n",
       "  is_Thanksgiving is_Christmas is_NewYear  tm_d  tm_w  tm_m  tm_y  tm_wm  \\\n",
       "0               0            0          0    29     4     1     0      5   \n",
       "1               0            0          0    29     4     1     0      5   \n",
       "2               0            0          0    29     4     1     0      5   \n",
       "3               0            0          0    29     4     1     0      5   \n",
       "4               0            0          0    29     4     1     0      5   \n",
       "\n",
       "   tm_dw  tm_w_end  \n",
       "0      5         1  \n",
       "1      5         1  \n",
       "2      5         1  \n",
       "3      5         1  \n",
       "4      5         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding ['state_id']\n",
      "Encoding ['store_id']\n",
      "Encoding ['cat_id']\n",
      "Encoding ['dept_id']\n",
      "Encoding ['state_id', 'cat_id']\n",
      "Encoding ['state_id', 'dept_id']\n",
      "Encoding ['store_id', 'cat_id']\n",
      "Encoding ['store_id', 'dept_id']\n",
      "Encoding ['item_id']\n",
      "Encoding ['item_id', 'state_id']\n",
      "Encoding ['item_id', 'store_id']\n",
      "Encoding ['tm_dw', 'item_id']\n",
      "Encoding ['tm_dw']\n"
     ]
    }
   ],
   "source": [
    "########################### Apply on grid_df\n",
    "#################################################################################\n",
    "# lets read grid from \n",
    "# https://www.kaggle.com/kyakovlev/m5-simple-fe\n",
    "# to be sure that our grids are aligned by index\n",
    "grid_df = pd.concat([pd.read_pickle('../cache/grid_part_1.pkl'),\n",
    "                     pd.read_pickle('../cache/grid_part_2.pkl').iloc[:,2:],\n",
    "                     pd.read_pickle('../cache/grid_part_3.pkl').iloc[:,2:]],\n",
    "                     axis=1)\n",
    "TARGET = 'sales'\n",
    "grid_df[TARGET][grid_df['d']>(1913-28)] = np.nan\n",
    "base_cols = list(grid_df)\n",
    "\n",
    "icols =  [\n",
    "            ['state_id'],\n",
    "            ['store_id'],\n",
    "            ['cat_id'],\n",
    "            ['dept_id'],\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            ['item_id'],\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id'],\n",
    "            ['tm_dw','item_id'],\n",
    "            ['tm_dw'],\n",
    "#             ['tm_m'],\n",
    "            ]\n",
    "\n",
    "for col in icols:\n",
    "    print('Encoding', col)\n",
    "    col_name = '_'+'_'.join(col)+'_'\n",
    "    grid_df['enc'+col_name+'mean'] = grid_df.groupby(col)[TARGET].transform('mean').astype(np.float16)\n",
    "    grid_df['enc'+col_name+'std'] = grid_df.groupby(col)[TARGET].transform('std').astype(np.float16)\n",
    "\n",
    "keep_cols = [col for col in list(grid_df) if col not in base_cols]\n",
    "grid_df = grid_df[['id','d',TARGET]+keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA: id 7\n",
      "[0.9577294  0.02673342 0.00694716 0.00340516 0.00216168 0.00163071\n",
      " 0.00139247]\n",
      "Columns to keep: ['sales_pca_id7_1', 'sales_pca_id7_2', 'sales_pca_id7_3']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def make_pca(df, pca_col, n_days):\n",
    "    print('PCA:', pca_col, n_days)\n",
    "    \n",
    "    # We don't need any other columns to make pca\n",
    "    pca_df = df[[pca_col,'d',TARGET]]\n",
    "    \n",
    "    # If we are doing pca for other series \"levels\" \n",
    "    # we need to agg first\n",
    "    if pca_col != 'id':\n",
    "        merge_base = pca_df[[pca_col,'d']]\n",
    "        pca_df = pca_df.groupby([pca_col,'d'])[TARGET].agg(['sum']).reset_index()\n",
    "        pca_df[TARGET] = pca_df['sum']\n",
    "        del pca_df['sum']\n",
    "    \n",
    "    # Min/Max scaling\n",
    "    pca_df[TARGET] = pca_df[TARGET]/pca_df[TARGET].max()\n",
    "    \n",
    "    # Making \"lag\" in old way (not parallel)\n",
    "    LAG_DAYS = [col for col in range(1,n_days+1)]\n",
    "    format_s = '{}_pca_'+pca_col+str(n_days)+'_{}'\n",
    "    pca_df = pca_df.assign(**{\n",
    "            format_s.format(col, l): pca_df.groupby([pca_col])[col].transform(lambda x: x.shift(l))\n",
    "            for l in LAG_DAYS\n",
    "            for col in [TARGET]\n",
    "        })\n",
    "    \n",
    "    pca_columns = list(pca_df)[3:]\n",
    "    \n",
    "    pca_df[pca_columns] = pca_df[pca_columns].fillna(-999999)\n",
    "    pca = PCA(random_state=SEED)\n",
    "    \n",
    "    # You can use fit_transform here\n",
    "    \n",
    "    pca.fit(pca_df[pca_columns])\n",
    "    pca_df[pca_columns] = pca.transform(pca_df[pca_columns])\n",
    "    \n",
    "    print(pca.explained_variance_ratio_)\n",
    "    \n",
    "    # we will keep only 3 most \"valuable\" columns/dimensions \n",
    "    keep_cols = pca_columns[:3]\n",
    "    print('Columns to keep:', keep_cols)\n",
    "    \n",
    "    # If we are doing pca for other series \"levels\"\n",
    "    # we need merge back our results to merge_base df\n",
    "    # and only than return resulted df\n",
    "    # I'll skip that step here\n",
    "    \n",
    "    return pca_df[keep_cols]\n",
    "\n",
    "\n",
    "# Make PCA\n",
    "grid_df = pd.concat([grid_df, make_pca(grid_df,'id',7)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>enc_state_id_mean</th>\n",
       "      <th>enc_state_id_std</th>\n",
       "      <th>enc_store_id_mean</th>\n",
       "      <th>enc_store_id_std</th>\n",
       "      <th>enc_cat_id_mean</th>\n",
       "      <th>enc_cat_id_std</th>\n",
       "      <th>enc_dept_id_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_item_id_state_id_std</th>\n",
       "      <th>enc_item_id_store_id_mean</th>\n",
       "      <th>enc_item_id_store_id_std</th>\n",
       "      <th>enc_tm_dw_item_id_mean</th>\n",
       "      <th>enc_tm_dw_item_id_std</th>\n",
       "      <th>enc_tm_dw_mean</th>\n",
       "      <th>enc_tm_dw_std</th>\n",
       "      <th>sales_pca_id7_1</th>\n",
       "      <th>sales_pca_id7_2</th>\n",
       "      <th>sales_pca_id7_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>45145359</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>5.027344</td>\n",
       "      <td>-9.635421e+04</td>\n",
       "      <td>-7.432287e-04</td>\n",
       "      <td>-907.273008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45175849</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>1.197266</td>\n",
       "      <td>1.367188</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>-9.635421e+04</td>\n",
       "      <td>-8.517103e-04</td>\n",
       "      <td>-907.272396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45206339</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.563477</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.262695</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>2.763336e+05</td>\n",
       "      <td>-5.211204e+05</td>\n",
       "      <td>482872.773364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45236829</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.553711</td>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.249023</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>6.542743e+05</td>\n",
       "      <td>-9.390265e+05</td>\n",
       "      <td>607426.064240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45267319</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>1.153320</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>3.828125</td>\n",
       "      <td>1.035378e+06</td>\n",
       "      <td>-1.170947e+06</td>\n",
       "      <td>277822.496733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45297809</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.422852</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>1.417539e+06</td>\n",
       "      <td>-1.170947e+06</td>\n",
       "      <td>-254725.778064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45328299</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>1.726562</td>\n",
       "      <td>5.121094</td>\n",
       "      <td>1.798643e+06</td>\n",
       "      <td>-9.390265e+05</td>\n",
       "      <td>-584329.345817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45358789</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>5.027344</td>\n",
       "      <td>2.176584e+06</td>\n",
       "      <td>-5.211204e+05</td>\n",
       "      <td>-459776.054631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45389279</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>1.197266</td>\n",
       "      <td>1.367188</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45419769</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.563477</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.262695</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45450259</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.553711</td>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.249023</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45480749</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>1.153320</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>3.828125</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45511239</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.422852</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45541729</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>1.726562</td>\n",
       "      <td>5.121094</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45572219</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>5.027344</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45602709</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>1.197266</td>\n",
       "      <td>1.367188</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45633199</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.563477</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.262695</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45663689</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.553711</td>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.249023</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45694179</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>1.153320</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>3.828125</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45724669</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.422852</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45755159</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>1.726562</td>\n",
       "      <td>5.121094</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45785649</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>5.027344</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45816139</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>1.197266</td>\n",
       "      <td>1.367188</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45846629</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.563477</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.262695</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45877119</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.553711</td>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.249023</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45907609</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>1.153320</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>3.828125</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45938099</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.422852</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45968589</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>1.726562</td>\n",
       "      <td>5.121094</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45999079</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>5.027344</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46029569</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>1.197266</td>\n",
       "      <td>1.367188</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46060059</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.563477</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.262695</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46090549</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.553711</td>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.249023</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46121039</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>1.153320</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>3.828125</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46151529</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.422852</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46182019</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>1.726562</td>\n",
       "      <td>5.121094</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46212509</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>5.027344</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46242999</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>1.197266</td>\n",
       "      <td>1.367188</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46273489</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.563477</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.262695</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46303979</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.553711</td>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.249023</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46334469</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>1.153320</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>3.828125</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46364959</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.422852</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46395449</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>1.726562</td>\n",
       "      <td>5.121094</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46425939</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>5.027344</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46456429</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>1.197266</td>\n",
       "      <td>1.367188</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46486919</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.563477</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.262695</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46517409</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.553711</td>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.249023</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46547899</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>1.153320</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>3.828125</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46578389</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.422852</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46608879</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>1.726562</td>\n",
       "      <td>5.121094</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46639369</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>5.027344</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46669859</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.562988</td>\n",
       "      <td>1.197266</td>\n",
       "      <td>1.367188</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46700349</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.563477</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>1.262695</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46730839</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.553711</td>\n",
       "      <td>1.121094</td>\n",
       "      <td>1.249023</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46761329</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>1.153320</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>3.828125</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46791819</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.422852</td>\n",
       "      <td>4.332031</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46822309</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>1.726562</td>\n",
       "      <td>5.121094</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46852799</td>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>1.639648</td>\n",
       "      <td>4.476562</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>5.769531</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>1.576172</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>5.027344</td>\n",
       "      <td>2.549271e+06</td>\n",
       "      <td>9.663192e-07</td>\n",
       "      <td>24003.992398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id     d  sales  enc_state_id_mean  \\\n",
       "45145359  FOODS_1_001_CA_1_validation  1885    0.0           1.576172   \n",
       "45175849  FOODS_1_001_CA_1_validation  1886    NaN           1.576172   \n",
       "45206339  FOODS_1_001_CA_1_validation  1887    NaN           1.576172   \n",
       "45236829  FOODS_1_001_CA_1_validation  1888    NaN           1.576172   \n",
       "45267319  FOODS_1_001_CA_1_validation  1889    NaN           1.576172   \n",
       "45297809  FOODS_1_001_CA_1_validation  1890    NaN           1.576172   \n",
       "45328299  FOODS_1_001_CA_1_validation  1891    NaN           1.576172   \n",
       "45358789  FOODS_1_001_CA_1_validation  1892    NaN           1.576172   \n",
       "45389279  FOODS_1_001_CA_1_validation  1893    NaN           1.576172   \n",
       "45419769  FOODS_1_001_CA_1_validation  1894    NaN           1.576172   \n",
       "45450259  FOODS_1_001_CA_1_validation  1895    NaN           1.576172   \n",
       "45480749  FOODS_1_001_CA_1_validation  1896    NaN           1.576172   \n",
       "45511239  FOODS_1_001_CA_1_validation  1897    NaN           1.576172   \n",
       "45541729  FOODS_1_001_CA_1_validation  1898    NaN           1.576172   \n",
       "45572219  FOODS_1_001_CA_1_validation  1899    NaN           1.576172   \n",
       "45602709  FOODS_1_001_CA_1_validation  1900    NaN           1.576172   \n",
       "45633199  FOODS_1_001_CA_1_validation  1901    NaN           1.576172   \n",
       "45663689  FOODS_1_001_CA_1_validation  1902    NaN           1.576172   \n",
       "45694179  FOODS_1_001_CA_1_validation  1903    NaN           1.576172   \n",
       "45724669  FOODS_1_001_CA_1_validation  1904    NaN           1.576172   \n",
       "45755159  FOODS_1_001_CA_1_validation  1905    NaN           1.576172   \n",
       "45785649  FOODS_1_001_CA_1_validation  1906    NaN           1.576172   \n",
       "45816139  FOODS_1_001_CA_1_validation  1907    NaN           1.576172   \n",
       "45846629  FOODS_1_001_CA_1_validation  1908    NaN           1.576172   \n",
       "45877119  FOODS_1_001_CA_1_validation  1909    NaN           1.576172   \n",
       "45907609  FOODS_1_001_CA_1_validation  1910    NaN           1.576172   \n",
       "45938099  FOODS_1_001_CA_1_validation  1911    NaN           1.576172   \n",
       "45968589  FOODS_1_001_CA_1_validation  1912    NaN           1.576172   \n",
       "45999079  FOODS_1_001_CA_1_validation  1913    NaN           1.576172   \n",
       "46029569  FOODS_1_001_CA_1_validation  1914    NaN           1.576172   \n",
       "46060059  FOODS_1_001_CA_1_validation  1915    NaN           1.576172   \n",
       "46090549  FOODS_1_001_CA_1_validation  1916    NaN           1.576172   \n",
       "46121039  FOODS_1_001_CA_1_validation  1917    NaN           1.576172   \n",
       "46151529  FOODS_1_001_CA_1_validation  1918    NaN           1.576172   \n",
       "46182019  FOODS_1_001_CA_1_validation  1919    NaN           1.576172   \n",
       "46212509  FOODS_1_001_CA_1_validation  1920    NaN           1.576172   \n",
       "46242999  FOODS_1_001_CA_1_validation  1921    NaN           1.576172   \n",
       "46273489  FOODS_1_001_CA_1_validation  1922    NaN           1.576172   \n",
       "46303979  FOODS_1_001_CA_1_validation  1923    NaN           1.576172   \n",
       "46334469  FOODS_1_001_CA_1_validation  1924    NaN           1.576172   \n",
       "46364959  FOODS_1_001_CA_1_validation  1925    NaN           1.576172   \n",
       "46395449  FOODS_1_001_CA_1_validation  1926    NaN           1.576172   \n",
       "46425939  FOODS_1_001_CA_1_validation  1927    NaN           1.576172   \n",
       "46456429  FOODS_1_001_CA_1_validation  1928    NaN           1.576172   \n",
       "46486919  FOODS_1_001_CA_1_validation  1929    NaN           1.576172   \n",
       "46517409  FOODS_1_001_CA_1_validation  1930    NaN           1.576172   \n",
       "46547899  FOODS_1_001_CA_1_validation  1931    NaN           1.576172   \n",
       "46578389  FOODS_1_001_CA_1_validation  1932    NaN           1.576172   \n",
       "46608879  FOODS_1_001_CA_1_validation  1933    NaN           1.576172   \n",
       "46639369  FOODS_1_001_CA_1_validation  1934    NaN           1.576172   \n",
       "46669859  FOODS_1_001_CA_1_validation  1935    NaN           1.576172   \n",
       "46700349  FOODS_1_001_CA_1_validation  1936    NaN           1.576172   \n",
       "46730839  FOODS_1_001_CA_1_validation  1937    NaN           1.576172   \n",
       "46761329  FOODS_1_001_CA_1_validation  1938    NaN           1.576172   \n",
       "46791819  FOODS_1_001_CA_1_validation  1939    NaN           1.576172   \n",
       "46822309  FOODS_1_001_CA_1_validation  1940    NaN           1.576172   \n",
       "46852799  FOODS_1_001_CA_1_validation  1941    NaN           1.576172   \n",
       "\n",
       "          enc_state_id_std  enc_store_id_mean  enc_store_id_std  \\\n",
       "45145359          4.605469           1.639648          4.476562   \n",
       "45175849          4.605469           1.639648          4.476562   \n",
       "45206339          4.605469           1.639648          4.476562   \n",
       "45236829          4.605469           1.639648          4.476562   \n",
       "45267319          4.605469           1.639648          4.476562   \n",
       "45297809          4.605469           1.639648          4.476562   \n",
       "45328299          4.605469           1.639648          4.476562   \n",
       "45358789          4.605469           1.639648          4.476562   \n",
       "45389279          4.605469           1.639648          4.476562   \n",
       "45419769          4.605469           1.639648          4.476562   \n",
       "45450259          4.605469           1.639648          4.476562   \n",
       "45480749          4.605469           1.639648          4.476562   \n",
       "45511239          4.605469           1.639648          4.476562   \n",
       "45541729          4.605469           1.639648          4.476562   \n",
       "45572219          4.605469           1.639648          4.476562   \n",
       "45602709          4.605469           1.639648          4.476562   \n",
       "45633199          4.605469           1.639648          4.476562   \n",
       "45663689          4.605469           1.639648          4.476562   \n",
       "45694179          4.605469           1.639648          4.476562   \n",
       "45724669          4.605469           1.639648          4.476562   \n",
       "45755159          4.605469           1.639648          4.476562   \n",
       "45785649          4.605469           1.639648          4.476562   \n",
       "45816139          4.605469           1.639648          4.476562   \n",
       "45846629          4.605469           1.639648          4.476562   \n",
       "45877119          4.605469           1.639648          4.476562   \n",
       "45907609          4.605469           1.639648          4.476562   \n",
       "45938099          4.605469           1.639648          4.476562   \n",
       "45968589          4.605469           1.639648          4.476562   \n",
       "45999079          4.605469           1.639648          4.476562   \n",
       "46029569          4.605469           1.639648          4.476562   \n",
       "46060059          4.605469           1.639648          4.476562   \n",
       "46090549          4.605469           1.639648          4.476562   \n",
       "46121039          4.605469           1.639648          4.476562   \n",
       "46151529          4.605469           1.639648          4.476562   \n",
       "46182019          4.605469           1.639648          4.476562   \n",
       "46212509          4.605469           1.639648          4.476562   \n",
       "46242999          4.605469           1.639648          4.476562   \n",
       "46273489          4.605469           1.639648          4.476562   \n",
       "46303979          4.605469           1.639648          4.476562   \n",
       "46334469          4.605469           1.639648          4.476562   \n",
       "46364959          4.605469           1.639648          4.476562   \n",
       "46395449          4.605469           1.639648          4.476562   \n",
       "46425939          4.605469           1.639648          4.476562   \n",
       "46456429          4.605469           1.639648          4.476562   \n",
       "46486919          4.605469           1.639648          4.476562   \n",
       "46517409          4.605469           1.639648          4.476562   \n",
       "46547899          4.605469           1.639648          4.476562   \n",
       "46578389          4.605469           1.639648          4.476562   \n",
       "46608879          4.605469           1.639648          4.476562   \n",
       "46639369          4.605469           1.639648          4.476562   \n",
       "46669859          4.605469           1.639648          4.476562   \n",
       "46700349          4.605469           1.639648          4.476562   \n",
       "46730839          4.605469           1.639648          4.476562   \n",
       "46761329          4.605469           1.639648          4.476562   \n",
       "46791819          4.605469           1.639648          4.476562   \n",
       "46822309          4.605469           1.639648          4.476562   \n",
       "46852799          4.605469           1.639648          4.476562   \n",
       "\n",
       "          enc_cat_id_mean  enc_cat_id_std  enc_dept_id_mean  ...  \\\n",
       "45145359         2.109375        5.769531          1.442383  ...   \n",
       "45175849         2.109375        5.769531          1.442383  ...   \n",
       "45206339         2.109375        5.769531          1.442383  ...   \n",
       "45236829         2.109375        5.769531          1.442383  ...   \n",
       "45267319         2.109375        5.769531          1.442383  ...   \n",
       "45297809         2.109375        5.769531          1.442383  ...   \n",
       "45328299         2.109375        5.769531          1.442383  ...   \n",
       "45358789         2.109375        5.769531          1.442383  ...   \n",
       "45389279         2.109375        5.769531          1.442383  ...   \n",
       "45419769         2.109375        5.769531          1.442383  ...   \n",
       "45450259         2.109375        5.769531          1.442383  ...   \n",
       "45480749         2.109375        5.769531          1.442383  ...   \n",
       "45511239         2.109375        5.769531          1.442383  ...   \n",
       "45541729         2.109375        5.769531          1.442383  ...   \n",
       "45572219         2.109375        5.769531          1.442383  ...   \n",
       "45602709         2.109375        5.769531          1.442383  ...   \n",
       "45633199         2.109375        5.769531          1.442383  ...   \n",
       "45663689         2.109375        5.769531          1.442383  ...   \n",
       "45694179         2.109375        5.769531          1.442383  ...   \n",
       "45724669         2.109375        5.769531          1.442383  ...   \n",
       "45755159         2.109375        5.769531          1.442383  ...   \n",
       "45785649         2.109375        5.769531          1.442383  ...   \n",
       "45816139         2.109375        5.769531          1.442383  ...   \n",
       "45846629         2.109375        5.769531          1.442383  ...   \n",
       "45877119         2.109375        5.769531          1.442383  ...   \n",
       "45907609         2.109375        5.769531          1.442383  ...   \n",
       "45938099         2.109375        5.769531          1.442383  ...   \n",
       "45968589         2.109375        5.769531          1.442383  ...   \n",
       "45999079         2.109375        5.769531          1.442383  ...   \n",
       "46029569         2.109375        5.769531          1.442383  ...   \n",
       "46060059         2.109375        5.769531          1.442383  ...   \n",
       "46090549         2.109375        5.769531          1.442383  ...   \n",
       "46121039         2.109375        5.769531          1.442383  ...   \n",
       "46151529         2.109375        5.769531          1.442383  ...   \n",
       "46182019         2.109375        5.769531          1.442383  ...   \n",
       "46212509         2.109375        5.769531          1.442383  ...   \n",
       "46242999         2.109375        5.769531          1.442383  ...   \n",
       "46273489         2.109375        5.769531          1.442383  ...   \n",
       "46303979         2.109375        5.769531          1.442383  ...   \n",
       "46334469         2.109375        5.769531          1.442383  ...   \n",
       "46364959         2.109375        5.769531          1.442383  ...   \n",
       "46395449         2.109375        5.769531          1.442383  ...   \n",
       "46425939         2.109375        5.769531          1.442383  ...   \n",
       "46456429         2.109375        5.769531          1.442383  ...   \n",
       "46486919         2.109375        5.769531          1.442383  ...   \n",
       "46517409         2.109375        5.769531          1.442383  ...   \n",
       "46547899         2.109375        5.769531          1.442383  ...   \n",
       "46578389         2.109375        5.769531          1.442383  ...   \n",
       "46608879         2.109375        5.769531          1.442383  ...   \n",
       "46639369         2.109375        5.769531          1.442383  ...   \n",
       "46669859         2.109375        5.769531          1.442383  ...   \n",
       "46700349         2.109375        5.769531          1.442383  ...   \n",
       "46730839         2.109375        5.769531          1.442383  ...   \n",
       "46761329         2.109375        5.769531          1.442383  ...   \n",
       "46791819         2.109375        5.769531          1.442383  ...   \n",
       "46822309         2.109375        5.769531          1.442383  ...   \n",
       "46852799         2.109375        5.769531          1.442383  ...   \n",
       "\n",
       "          enc_item_id_state_id_std  enc_item_id_store_id_mean  \\\n",
       "45145359                  1.666016                   0.779785   \n",
       "45175849                  1.666016                   0.779785   \n",
       "45206339                  1.666016                   0.779785   \n",
       "45236829                  1.666016                   0.779785   \n",
       "45267319                  1.666016                   0.779785   \n",
       "45297809                  1.666016                   0.779785   \n",
       "45328299                  1.666016                   0.779785   \n",
       "45358789                  1.666016                   0.779785   \n",
       "45389279                  1.666016                   0.779785   \n",
       "45419769                  1.666016                   0.779785   \n",
       "45450259                  1.666016                   0.779785   \n",
       "45480749                  1.666016                   0.779785   \n",
       "45511239                  1.666016                   0.779785   \n",
       "45541729                  1.666016                   0.779785   \n",
       "45572219                  1.666016                   0.779785   \n",
       "45602709                  1.666016                   0.779785   \n",
       "45633199                  1.666016                   0.779785   \n",
       "45663689                  1.666016                   0.779785   \n",
       "45694179                  1.666016                   0.779785   \n",
       "45724669                  1.666016                   0.779785   \n",
       "45755159                  1.666016                   0.779785   \n",
       "45785649                  1.666016                   0.779785   \n",
       "45816139                  1.666016                   0.779785   \n",
       "45846629                  1.666016                   0.779785   \n",
       "45877119                  1.666016                   0.779785   \n",
       "45907609                  1.666016                   0.779785   \n",
       "45938099                  1.666016                   0.779785   \n",
       "45968589                  1.666016                   0.779785   \n",
       "45999079                  1.666016                   0.779785   \n",
       "46029569                  1.666016                   0.779785   \n",
       "46060059                  1.666016                   0.779785   \n",
       "46090549                  1.666016                   0.779785   \n",
       "46121039                  1.666016                   0.779785   \n",
       "46151529                  1.666016                   0.779785   \n",
       "46182019                  1.666016                   0.779785   \n",
       "46212509                  1.666016                   0.779785   \n",
       "46242999                  1.666016                   0.779785   \n",
       "46273489                  1.666016                   0.779785   \n",
       "46303979                  1.666016                   0.779785   \n",
       "46334469                  1.666016                   0.779785   \n",
       "46364959                  1.666016                   0.779785   \n",
       "46395449                  1.666016                   0.779785   \n",
       "46425939                  1.666016                   0.779785   \n",
       "46456429                  1.666016                   0.779785   \n",
       "46486919                  1.666016                   0.779785   \n",
       "46517409                  1.666016                   0.779785   \n",
       "46547899                  1.666016                   0.779785   \n",
       "46578389                  1.666016                   0.779785   \n",
       "46608879                  1.666016                   0.779785   \n",
       "46639369                  1.666016                   0.779785   \n",
       "46669859                  1.666016                   0.779785   \n",
       "46700349                  1.666016                   0.779785   \n",
       "46730839                  1.666016                   0.779785   \n",
       "46761329                  1.666016                   0.779785   \n",
       "46791819                  1.666016                   0.779785   \n",
       "46822309                  1.666016                   0.779785   \n",
       "46852799                  1.666016                   0.779785   \n",
       "\n",
       "          enc_item_id_store_id_std  enc_tm_dw_item_id_mean  \\\n",
       "45145359                  1.256836                0.744141   \n",
       "45175849                  1.256836                0.562988   \n",
       "45206339                  1.256836                0.563477   \n",
       "45236829                  1.256836                0.553711   \n",
       "45267319                  1.256836                0.593750   \n",
       "45297809                  1.256836                0.688965   \n",
       "45328299                  1.256836                0.781738   \n",
       "45358789                  1.256836                0.744141   \n",
       "45389279                  1.256836                0.562988   \n",
       "45419769                  1.256836                0.563477   \n",
       "45450259                  1.256836                0.553711   \n",
       "45480749                  1.256836                0.593750   \n",
       "45511239                  1.256836                0.688965   \n",
       "45541729                  1.256836                0.781738   \n",
       "45572219                  1.256836                0.744141   \n",
       "45602709                  1.256836                0.562988   \n",
       "45633199                  1.256836                0.563477   \n",
       "45663689                  1.256836                0.553711   \n",
       "45694179                  1.256836                0.593750   \n",
       "45724669                  1.256836                0.688965   \n",
       "45755159                  1.256836                0.781738   \n",
       "45785649                  1.256836                0.744141   \n",
       "45816139                  1.256836                0.562988   \n",
       "45846629                  1.256836                0.563477   \n",
       "45877119                  1.256836                0.553711   \n",
       "45907609                  1.256836                0.593750   \n",
       "45938099                  1.256836                0.688965   \n",
       "45968589                  1.256836                0.781738   \n",
       "45999079                  1.256836                0.744141   \n",
       "46029569                  1.256836                0.562988   \n",
       "46060059                  1.256836                0.563477   \n",
       "46090549                  1.256836                0.553711   \n",
       "46121039                  1.256836                0.593750   \n",
       "46151529                  1.256836                0.688965   \n",
       "46182019                  1.256836                0.781738   \n",
       "46212509                  1.256836                0.744141   \n",
       "46242999                  1.256836                0.562988   \n",
       "46273489                  1.256836                0.563477   \n",
       "46303979                  1.256836                0.553711   \n",
       "46334469                  1.256836                0.593750   \n",
       "46364959                  1.256836                0.688965   \n",
       "46395449                  1.256836                0.781738   \n",
       "46425939                  1.256836                0.744141   \n",
       "46456429                  1.256836                0.562988   \n",
       "46486919                  1.256836                0.563477   \n",
       "46517409                  1.256836                0.553711   \n",
       "46547899                  1.256836                0.593750   \n",
       "46578389                  1.256836                0.688965   \n",
       "46608879                  1.256836                0.781738   \n",
       "46639369                  1.256836                0.744141   \n",
       "46669859                  1.256836                0.562988   \n",
       "46700349                  1.256836                0.563477   \n",
       "46730839                  1.256836                0.553711   \n",
       "46761329                  1.256836                0.593750   \n",
       "46791819                  1.256836                0.688965   \n",
       "46822309                  1.256836                0.781738   \n",
       "46852799                  1.256836                0.744141   \n",
       "\n",
       "          enc_tm_dw_item_id_std  enc_tm_dw_mean  enc_tm_dw_std  \\\n",
       "45145359               1.576172        1.708008       5.027344   \n",
       "45175849               1.197266        1.367188       4.082031   \n",
       "45206339               1.207031        1.262695       3.804688   \n",
       "45236829               1.121094        1.249023       3.796875   \n",
       "45267319               1.153320        1.256836       3.828125   \n",
       "45297809               1.378906        1.422852       4.332031   \n",
       "45328299               1.494141        1.726562       5.121094   \n",
       "45358789               1.576172        1.708008       5.027344   \n",
       "45389279               1.197266        1.367188       4.082031   \n",
       "45419769               1.207031        1.262695       3.804688   \n",
       "45450259               1.121094        1.249023       3.796875   \n",
       "45480749               1.153320        1.256836       3.828125   \n",
       "45511239               1.378906        1.422852       4.332031   \n",
       "45541729               1.494141        1.726562       5.121094   \n",
       "45572219               1.576172        1.708008       5.027344   \n",
       "45602709               1.197266        1.367188       4.082031   \n",
       "45633199               1.207031        1.262695       3.804688   \n",
       "45663689               1.121094        1.249023       3.796875   \n",
       "45694179               1.153320        1.256836       3.828125   \n",
       "45724669               1.378906        1.422852       4.332031   \n",
       "45755159               1.494141        1.726562       5.121094   \n",
       "45785649               1.576172        1.708008       5.027344   \n",
       "45816139               1.197266        1.367188       4.082031   \n",
       "45846629               1.207031        1.262695       3.804688   \n",
       "45877119               1.121094        1.249023       3.796875   \n",
       "45907609               1.153320        1.256836       3.828125   \n",
       "45938099               1.378906        1.422852       4.332031   \n",
       "45968589               1.494141        1.726562       5.121094   \n",
       "45999079               1.576172        1.708008       5.027344   \n",
       "46029569               1.197266        1.367188       4.082031   \n",
       "46060059               1.207031        1.262695       3.804688   \n",
       "46090549               1.121094        1.249023       3.796875   \n",
       "46121039               1.153320        1.256836       3.828125   \n",
       "46151529               1.378906        1.422852       4.332031   \n",
       "46182019               1.494141        1.726562       5.121094   \n",
       "46212509               1.576172        1.708008       5.027344   \n",
       "46242999               1.197266        1.367188       4.082031   \n",
       "46273489               1.207031        1.262695       3.804688   \n",
       "46303979               1.121094        1.249023       3.796875   \n",
       "46334469               1.153320        1.256836       3.828125   \n",
       "46364959               1.378906        1.422852       4.332031   \n",
       "46395449               1.494141        1.726562       5.121094   \n",
       "46425939               1.576172        1.708008       5.027344   \n",
       "46456429               1.197266        1.367188       4.082031   \n",
       "46486919               1.207031        1.262695       3.804688   \n",
       "46517409               1.121094        1.249023       3.796875   \n",
       "46547899               1.153320        1.256836       3.828125   \n",
       "46578389               1.378906        1.422852       4.332031   \n",
       "46608879               1.494141        1.726562       5.121094   \n",
       "46639369               1.576172        1.708008       5.027344   \n",
       "46669859               1.197266        1.367188       4.082031   \n",
       "46700349               1.207031        1.262695       3.804688   \n",
       "46730839               1.121094        1.249023       3.796875   \n",
       "46761329               1.153320        1.256836       3.828125   \n",
       "46791819               1.378906        1.422852       4.332031   \n",
       "46822309               1.494141        1.726562       5.121094   \n",
       "46852799               1.576172        1.708008       5.027344   \n",
       "\n",
       "          sales_pca_id7_1  sales_pca_id7_2  sales_pca_id7_3  \n",
       "45145359    -9.635421e+04    -7.432287e-04      -907.273008  \n",
       "45175849    -9.635421e+04    -8.517103e-04      -907.272396  \n",
       "45206339     2.763336e+05    -5.211204e+05    482872.773364  \n",
       "45236829     6.542743e+05    -9.390265e+05    607426.064240  \n",
       "45267319     1.035378e+06    -1.170947e+06    277822.496733  \n",
       "45297809     1.417539e+06    -1.170947e+06   -254725.778064  \n",
       "45328299     1.798643e+06    -9.390265e+05   -584329.345817  \n",
       "45358789     2.176584e+06    -5.211204e+05   -459776.054631  \n",
       "45389279     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45419769     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45450259     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45480749     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45511239     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45541729     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45572219     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45602709     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45633199     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45663689     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45694179     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45724669     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45755159     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45785649     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45816139     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45846629     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45877119     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45907609     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45938099     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45968589     2.549271e+06     9.663192e-07     24003.992398  \n",
       "45999079     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46029569     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46060059     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46090549     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46121039     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46151529     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46182019     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46212509     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46242999     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46273489     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46303979     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46334469     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46364959     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46395449     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46425939     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46456429     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46486919     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46517409     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46547899     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46578389     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46608879     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46639369     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46669859     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46700349     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46730839     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46761329     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46791819     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46822309     2.549271e+06     9.663192e-07     24003.992398  \n",
       "46852799     2.549271e+06     9.663192e-07     24003.992398  \n",
       "\n",
       "[57 rows x 32 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for id_, group in grid_df[grid_df['d']>=1913-28].groupby('id'):\n",
    "    break\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Mean/Std encoding\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "print('Save Mean/Std encoding')\n",
    "grid_df.to_pickle('../cache/mean_encoding_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46881677 entries, 0 to 46881676\n",
      "Data columns (total 32 columns):\n",
      "id                           category\n",
      "d                            int16\n",
      "sales                        float64\n",
      "enc_state_id_mean            float16\n",
      "enc_state_id_std             float16\n",
      "enc_store_id_mean            float16\n",
      "enc_store_id_std             float16\n",
      "enc_cat_id_mean              float16\n",
      "enc_cat_id_std               float16\n",
      "enc_dept_id_mean             float16\n",
      "enc_dept_id_std              float16\n",
      "enc_state_id_cat_id_mean     float16\n",
      "enc_state_id_cat_id_std      float16\n",
      "enc_state_id_dept_id_mean    float16\n",
      "enc_state_id_dept_id_std     float16\n",
      "enc_store_id_cat_id_mean     float16\n",
      "enc_store_id_cat_id_std      float16\n",
      "enc_store_id_dept_id_mean    float16\n",
      "enc_store_id_dept_id_std     float16\n",
      "enc_item_id_mean             float16\n",
      "enc_item_id_std              float16\n",
      "enc_item_id_state_id_mean    float16\n",
      "enc_item_id_state_id_std     float16\n",
      "enc_item_id_store_id_mean    float16\n",
      "enc_item_id_store_id_std     float16\n",
      "enc_tm_dw_item_id_mean       float16\n",
      "enc_tm_dw_item_id_std        float16\n",
      "enc_tm_dw_mean               float16\n",
      "enc_tm_dw_std                float16\n",
      "sales_pca_id7_1              float64\n",
      "sales_pca_id7_2              float64\n",
      "sales_pca_id7_3              float64\n",
      "dtypes: category(1), float16(26), float64(4), int16(1)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "########################### Final list of new features\n",
    "#################################################################################\n",
    "grid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
