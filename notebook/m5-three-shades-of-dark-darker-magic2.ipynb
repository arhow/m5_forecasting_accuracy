{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    \n",
    "## Multiprocess Runs\n",
    "def df_parallelize_run(func, t_split):\n",
    "    num_cores = np.min([N_CORES,len(t_split)])\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helper to load data by store ID\n",
    "#################################################################################\n",
    "# Read data\n",
    "def gen_data_by_store(store):\n",
    "    \n",
    "    # Read and contact basic feature\n",
    "    df = pd.concat([pd.read_pickle(BASE),\n",
    "                    pd.read_pickle(PRICE).iloc[:,2:],\n",
    "                    pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
    "                    axis=1)\n",
    "    \n",
    "    # Leave only relevant store\n",
    "    df = df[df['store_id']==store]\n",
    "\n",
    "    # With memory limits we have to read \n",
    "    # lags and mean encoding features\n",
    "    # separately and drop items that we don't need.\n",
    "    # As our Features Grids are aligned \n",
    "    # we can use index to keep only necessary rows\n",
    "    # Alignment is good for us as concat uses less memory than merge.\n",
    "    df2 = pd.read_pickle(MEAN_ENC)[mean_features]\n",
    "    df2 = df2[df2.index.isin(df.index)]\n",
    "    \n",
    "    df3 = pd.read_pickle(LAGS).iloc[:,3:]\n",
    "    df3 = df3[df3.index.isin(df.index)]\n",
    "    \n",
    "    df = pd.concat([df, df2], axis=1)\n",
    "    del df2 # to not reach memory limit \n",
    "    \n",
    "    df = pd.concat([df, df3], axis=1)\n",
    "    del df3 # to not reach memory limit \n",
    "    \n",
    "    # Create features list\n",
    "    features = [col for col in list(df) if col not in remove_features]\n",
    "    df = df[['id','d',TARGET]+features]\n",
    "    \n",
    "    df.to_pickle(f'../cache/notebook_{store}.pkl', compression='gzip')\n",
    "    return\n",
    "\n",
    "def get_data_by_store(store, base_path='./', compression=None):\n",
    "    \n",
    "    df = pd.read_pickle(f'{base_path}notebook_{store}.pkl', compression=compression)\n",
    "    \n",
    "    # Skipping first n rows\n",
    "    df = df[df['d']>=START_TRAIN].reset_index(drop=True)\n",
    "    \n",
    "    features = df.columns.drop(['id','d',TARGET]).tolist()\n",
    "    \n",
    "    return df, features\n",
    "\n",
    "# Recombine Test set after training\n",
    "def get_base_test(base_path='.'):\n",
    "    base_test = pd.DataFrame()\n",
    "\n",
    "    for store_id in STORES_IDS:\n",
    "        temp_df = pd.read_pickle(f'{base_path}/test_'+store_id+'.pkl')\n",
    "        temp_df['store_id'] = store_id\n",
    "        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "    \n",
    "    return base_test\n",
    "\n",
    "\n",
    "########################### Helper to make dynamic rolling lags\n",
    "#################################################################################\n",
    "def make_lag(LAG_DAY):\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'sales_lag_'+str(LAG_DAY)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
    "    return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "def make_lag_roll(LAG_DAY):\n",
    "    shift_day = LAG_DAY[0]\n",
    "    roll_wind = LAG_DAY[1]\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "    return lag_df[[col_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model params\n",
    "#################################################################################\n",
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'regression',#'tweedie','regression',\n",
    "#                     'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.5,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 2**11-1,\n",
    "                    'min_data_in_leaf': 2**12-1,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'max_bin': 100,\n",
    "                    'n_estimators': 1400,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                } \n",
    "\n",
    "# Let's look closer on params\n",
    "\n",
    "## 'boosting_type': 'gbdt'\n",
    "# we have 'goss' option for faster training\n",
    "# but it normally leads to underfit.\n",
    "# Also there is good 'dart' mode\n",
    "# but it takes forever to train\n",
    "# and model performance depends \n",
    "# a lot on random factor \n",
    "# https://www.kaggle.com/c/home-credit-default-risk/discussion/60921\n",
    "\n",
    "## 'objective': 'tweedie'\n",
    "# Tweedie Gradient Boosting for Extremely\n",
    "# Unbalanced Zero-inflated Data\n",
    "# https://arxiv.org/pdf/1811.10192.pdf\n",
    "# and many more articles about tweediie\n",
    "#\n",
    "# Strange (for me) but Tweedie is close in results\n",
    "# to my own ugly loss.\n",
    "# My advice here - make OWN LOSS function\n",
    "# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/140564\n",
    "# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/143070\n",
    "# I think many of you already using it (after poisson kernel appeared) \n",
    "# (kagglers are very good with \"params\" testing and tuning).\n",
    "# Try to figure out why Tweedie works.\n",
    "# probably it will show you new features options\n",
    "# or data transformation (Target transformation?).\n",
    "\n",
    "## 'tweedie_variance_power': 1.1\n",
    "# default = 1.5\n",
    "# set this closer to 2 to shift towards a Gamma distribution\n",
    "# set this closer to 1 to shift towards a Poisson distribution\n",
    "# my CV shows 1.1 is optimal \n",
    "# but you can make your own choice\n",
    "\n",
    "## 'metric': 'rmse'\n",
    "# Doesn't mean anything to us\n",
    "# as competition metric is different\n",
    "# and we don't use early stoppings here.\n",
    "# So rmse serves just for general \n",
    "# model performance overview.\n",
    "# Also we use \"fake\" validation set\n",
    "# (as it makes part of the training set)\n",
    "# so even general rmse score doesn't mean anything))\n",
    "# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834\n",
    "\n",
    "## 'subsample': 0.5\n",
    "# Serves to fight with overfit\n",
    "# this will randomly select part of data without resampling\n",
    "# Chosen by CV (my CV can be wrong!)\n",
    "# Next kernel will be about CV\n",
    "\n",
    "##'subsample_freq': 1\n",
    "# frequency for bagging\n",
    "# default value - seems ok\n",
    "\n",
    "## 'learning_rate': 0.03\n",
    "# Chosen by CV\n",
    "# Smaller - longer training\n",
    "# but there is an option to stop \n",
    "# in \"local minimum\"\n",
    "# Bigger - faster training\n",
    "# but there is a chance to\n",
    "# not find \"global minimum\" minimum\n",
    "\n",
    "## 'num_leaves': 2**11-1\n",
    "## 'min_data_in_leaf': 2**12-1\n",
    "# Force model to use more features\n",
    "# We need it to reduce \"recursive\"\n",
    "# error impact.\n",
    "# Also it leads to overfit\n",
    "# that's why we use small \n",
    "# 'max_bin': 100\n",
    "\n",
    "## l1, l2 regularizations\n",
    "# https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c\n",
    "# Good tiny explanation\n",
    "# l2 can work with bigger num_leaves\n",
    "# but my CV doesn't show boost\n",
    "                    \n",
    "## 'n_estimators': 1400\n",
    "# CV shows that there should be\n",
    "# different values for each state/store.\n",
    "# Current value was chosen \n",
    "# for general purpose.\n",
    "# As we don't use any early stopings\n",
    "# careful to not overfit Public LB.\n",
    "\n",
    "##'feature_fraction': 0.5\n",
    "# LightGBM will randomly select \n",
    "# part of features on each iteration (tree).\n",
    "# We have maaaany features\n",
    "# and many of them are \"duplicates\"\n",
    "# and many just \"noise\"\n",
    "# good values here - 0.5-0.7 (by CV)\n",
    "\n",
    "## 'boost_from_average': False\n",
    "# There is some \"problem\"\n",
    "# to code boost_from_average for \n",
    "# custom loss\n",
    "# 'True' makes training faster\n",
    "# BUT carefull use it\n",
    "# https://github.com/microsoft/LightGBM/issues/1514\n",
    "# not our case but good to know cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "VER = 1                          # Our model version\n",
    "SEED = 42                        # We want all things\n",
    "seed_everything(SEED)            # to be as deterministic \n",
    "lgb_params['seed'] = SEED        # as possible\n",
    "N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "\n",
    "#LIMITS and const\n",
    "TARGET      = 'sales'            # Our target\n",
    "START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "END_TRAIN   = 1913               # End day of our train set\n",
    "P_HORIZON   = 28                 # Prediction horizon\n",
    "USE_AUX     = False               # Use or not pretrained models\n",
    "\n",
    "#FEATURES to remove\n",
    "## These features lead to overfit\n",
    "## or values not present in test set\n",
    "ROLLING_TEMP_FEATURES= ['rolling_mean_tmp_1_7', 'rolling_mean_tmp_1_30', 'rolling_mean_tmp_14_30', 'rolling_mean_tmp_14_7', 'rolling_mean_tmp_7_30', 'rolling_mean_tmp_7_14', 'rolling_mean_tmp_7_60', 'rolling_mean_tmp_1_14', 'rolling_mean_tmp_14_60', 'rolling_mean_tmp_7_7', 'rolling_mean_tmp_14_14', 'rolling_mean_tmp_1_60']\n",
    "\n",
    "remove_features = ['id','state_id','store_id',\n",
    "                   'date','wm_yr_wk','d',TARGET, 'sales_diff', 'no_sales']\n",
    "\n",
    "mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
    "                   'enc_dept_id_mean','enc_dept_id_std',\n",
    "                   'enc_item_id_mean','enc_item_id_std',\n",
    "                  'enc_tm_dw_mean', 'enc_tm_dw_std',\n",
    "                  'enc_tm_dw_item_id_mean','enc_tm_dw_item_id_std']+['enc_tm_y_mean_sell',\n",
    " 'enc_tm_y_std_sell',\n",
    " 'enc_state_id_tm_y_mean_sell',\n",
    " 'enc_state_id_tm_y_std_sell',\n",
    " 'enc_store_id_tm_y_mean_sell',\n",
    " 'enc_store_id_tm_y_std_sell',\n",
    " 'enc_cat_id_tm_y_mean_sell',\n",
    " 'enc_cat_id_tm_y_std_sell',\n",
    " 'enc_dept_id_tm_y_mean_sell',\n",
    " 'enc_dept_id_tm_y_std_sell',\n",
    " 'enc_item_id_tm_y_mean_sell',\n",
    " 'enc_item_id_tm_y_std_sell',\n",
    " 'enc_item_id_state_id_tm_y_mean_sell',\n",
    " 'enc_item_id_state_id_tm_y_std_sell',\n",
    " 'enc_item_id_store_id_tm_y_mean_sell',\n",
    " 'enc_item_id_store_id_tm_y_std_sell',\n",
    " 'sales_pca_id7_1',\n",
    " 'sales_pca_id7_2',\n",
    " 'sales_pca_id7_3']\n",
    "\n",
    "\n",
    "#PATHS for Features\n",
    "ORIGINAL = '../input/m5-forecasting-accuracy/'\n",
    "BASE     = '../cache/grid_part_1.pkl'\n",
    "PRICE    = '../cache/grid_part_2.pkl'\n",
    "CALENDAR = '../cache/grid_part_3.pkl'\n",
    "LAGS     = '../cache/lags_df_28.pkl'\n",
    "MEAN_ENC = '../cache/mean_encoding_df.pkl'\n",
    "\n",
    "\n",
    "# AUX(pretrained) Models paths\n",
    "# AUX_MODELS = '../input/m5-aux-models/'\n",
    "\n",
    "\n",
    "#STORES ids\n",
    "STORES_IDS = pd.read_csv(ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "STORES_IDS = list(STORES_IDS.unique())\n",
    "\n",
    "\n",
    "#SPLITS for lags creation\n",
    "SHIFT_DAY  = 28\n",
    "N_LAGS     = 15\n",
    "LAGS_SPLIT = [col for col in range(SHIFT_DAY,SHIFT_DAY+N_LAGS)]\n",
    "ROLS_SPLIT = []\n",
    "for i in [1,7,14]:\n",
    "    for j in [7,14,30,60]:\n",
    "        ROLS_SPLIT.append([i,j])\n",
    "        \n",
    "#features\n",
    "for i in STORES_IDS:\n",
    "    gen_data_by_store(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))\n",
    "\n",
    "def permutation_importance(model, validation_df, features_columns, target, metric=rmse, verbose=1):\n",
    "\n",
    "    list_ = []\n",
    "    # Make normal prediction with our model and save score\n",
    "    validation_df['preds'] = model.predict(validation_df[features_columns])\n",
    "    base_score = metric(validation_df[target], validation_df['preds'])\n",
    "    if verbose>0:\n",
    "        print('Standart RMSE', base_score)\n",
    "\n",
    "    # Now we are looping over all our numerical features\n",
    "    for col in features_columns:\n",
    "\n",
    "        # We will make validation set copy to restore\n",
    "        # features states on each run\n",
    "        temp_df = validation_df.copy()\n",
    "\n",
    "        # Error here appears if we have \"categorical\" features and can't \n",
    "        # do np.random.permutation without disrupt categories\n",
    "        # so we need to check if feature is numerical\n",
    "        if temp_df[col].dtypes.name != 'category':\n",
    "            temp_df[col] = np.random.permutation(temp_df[col].values)\n",
    "            temp_df['preds'] = model.predict(temp_df[features_columns])\n",
    "            cur_score = metric(temp_df[target], temp_df['preds'])\n",
    "            \n",
    "            list_.append({'feature':col, 'permutation_importance':np.round(cur_score - base_score, 4)})\n",
    "            # If our current rmse score is less than base score\n",
    "            # it means that feature most probably is a bad one\n",
    "            # and our model is learning on noise\n",
    "            if verbose>0:\n",
    "                print(col, np.round(cur_score - base_score, 4))\n",
    "            \n",
    "    return pd.DataFrame(list_).sort_values(by=['permutation_importance'], ascending=False)\n",
    "\n",
    "\n",
    "# permutation_importance_df = permutation_importance(estimator, valid_df, features_columns, TARGET, metric=rmse, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Aux Models\n",
    "# If you don't want to wait hours and hours\n",
    "# to have result you can train each store \n",
    "# in separate kernel and then just join result.\n",
    "\n",
    "# If we want to use pretrained models we can \n",
    "## skip training \n",
    "## (in our case do dummy training\n",
    "##  to show that we are good with memory\n",
    "##  and you can safely use this (all kernel) code)\n",
    "if USE_AUX:\n",
    "    lgb_params['n_estimators'] = 2\n",
    "    \n",
    "# Here is some 'logs' that can compare\n",
    "#Train CA_1\n",
    "#[100]\tvalid_0's rmse: 2.02289\n",
    "#[200]\tvalid_0's rmse: 2.0017\n",
    "#[300]\tvalid_0's rmse: 1.99239\n",
    "#[400]\tvalid_0's rmse: 1.98471\n",
    "#[500]\tvalid_0's rmse: 1.97923\n",
    "#[600]\tvalid_0's rmse: 1.97284\n",
    "#[700]\tvalid_0's rmse: 1.96763\n",
    "#[800]\tvalid_0's rmse: 1.9624\n",
    "#[900]\tvalid_0's rmse: 1.95673\n",
    "#[1000]\tvalid_0's rmse: 1.95201\n",
    "#[1100]\tvalid_0's rmse: 1.9476\n",
    "#[1200]\tvalid_0's rmse: 1.9434\n",
    "#[1300]\tvalid_0's rmse: 1.9392\n",
    "#[1400]\tvalid_0's rmse: 1.93446\n",
    "\n",
    "#Train CA_2\n",
    "#[100]\tvalid_0's rmse: 1.88949\n",
    "#[200]\tvalid_0's rmse: 1.84767\n",
    "#[300]\tvalid_0's rmse: 1.83653\n",
    "#[400]\tvalid_0's rmse: 1.82909\n",
    "#[500]\tvalid_0's rmse: 1.82265\n",
    "#[600]\tvalid_0's rmse: 1.81725\n",
    "#[700]\tvalid_0's rmse: 1.81252\n",
    "#[800]\tvalid_0's rmse: 1.80736\n",
    "#[900]\tvalid_0's rmse: 1.80242\n",
    "#[1000]\tvalid_0's rmse: 1.79821\n",
    "#[1100]\tvalid_0's rmse: 1.794\n",
    "#[1200]\tvalid_0's rmse: 1.78973\n",
    "#[1300]\tvalid_0's rmse: 1.78552\n",
    "#[1400]\tvalid_0's rmse: 1.78158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_1\n",
      "[100]\tvalid_0's rmse: 1.38797\n",
      "[200]\tvalid_0's rmse: 1.29097\n",
      "[300]\tvalid_0's rmse: 1.29047\n",
      "[400]\tvalid_0's rmse: 1.29367\n",
      "[500]\tvalid_0's rmse: 1.29527\n",
      "[600]\tvalid_0's rmse: 1.29226\n",
      "[700]\tvalid_0's rmse: 1.28961\n",
      "[800]\tvalid_0's rmse: 1.28808\n",
      "[900]\tvalid_0's rmse: 1.28369\n",
      "[1000]\tvalid_0's rmse: 1.2812\n",
      "[1100]\tvalid_0's rmse: 1.2778\n",
      "[1200]\tvalid_0's rmse: 1.27536\n",
      "[1300]\tvalid_0's rmse: 1.27197\n",
      "[1400]\tvalid_0's rmse: 1.26662\n"
     ]
    }
   ],
   "source": [
    "########################### Train Models\n",
    "#################################################################################\n",
    "his = []\n",
    "do_permutation = True\n",
    "try_1_store = True\n",
    "if not USE_AUX:\n",
    "    for store_id in STORES_IDS:\n",
    "        print('Train', store_id)\n",
    "\n",
    "        # Get grid for current store\n",
    "        grid_df, features_columns = get_data_by_store(store_id, base_path='../cache/')\n",
    "\n",
    "        # Masks for \n",
    "        # Train (All data less than 1913)\n",
    "        # \"Validation\" (Last 28 days - not real validatio set)\n",
    "        # Test (All data greater than 1913 day, \n",
    "        #       with some gap for recursive features)\n",
    "        train_mask = grid_df['d']<=(END_TRAIN)\n",
    "        valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "        preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "\n",
    "        # Apply masks and save lgb dataset as bin\n",
    "        # to reduce memory spikes during dtype convertations\n",
    "        # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "        # \"To avoid any conversions, you should always use np.float32\"\n",
    "        # or save to bin before start training\n",
    "        # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "        train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
    "                           label=grid_df[train_mask][TARGET])\n",
    "#         train_data.save_binary('train_data.bin')\n",
    "#         train_data = lgb.Dataset('train_data.bin')\n",
    "\n",
    "        valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
    "                           label=grid_df[valid_mask][TARGET])\n",
    "\n",
    "        # Launch seeder again to make lgb training 100% deterministic\n",
    "        # with each \"code line\" np.random \"evolves\" \n",
    "        # so we need (may want) to \"reset\" it\n",
    "        seed_everything(SEED)\n",
    "        estimator = lgb.train(lgb_params,\n",
    "                              train_data,\n",
    "                              valid_sets = [valid_data],\n",
    "                              verbose_eval = 100,\n",
    "                              )\n",
    "        if do_permutation:\n",
    "            permutation_importance_df = permutation_importance(estimator, grid_df[valid_mask], features_columns, TARGET, metric=rmse, verbose=0)\n",
    "        else:\n",
    "            permutation_importance_df = None\n",
    "        \n",
    "        \n",
    "        \n",
    "        his.append({'store_id':store_id, 'permutation_importance_df':permutation_importance_df,})\n",
    "        if try_1_store:\n",
    "            break\n",
    "        \n",
    "        # Saving part of the dataset for later predictions\n",
    "        # Removing features that we need to calculate recursively \n",
    "        grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "        keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "        grid_df = grid_df[keep_cols]\n",
    "        grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "\n",
    "        # Save model - it's not real '.bin' but a pickle file\n",
    "        # estimator = lgb.Booster(model_file='model.txt')\n",
    "        # can only predict with the best iteration (or the saving iteration)\n",
    "        # pickle.dump gives us more flexibility\n",
    "        # like estimator.predict(TEST, num_iteration=100)\n",
    "        # num_iteration - number of iteration want to predict with, \n",
    "        # NULL or <= 0 means use best iteration\n",
    "        model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "        pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "        # Remove temporary files and objects \n",
    "        # to free some hdd space and ram memory\n",
    "        # !rm train_data.bin\n",
    "        del train_data, valid_data, estimator, grid_df\n",
    "        gc.collect()\n",
    "\n",
    "        # \"Keep\" models features for predictions\n",
    "        MODEL_FEATURES = features_columns\n",
    "        \n",
    "else:\n",
    "    _, MODEL_FEATURES = get_data_by_store(STORES_IDS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>permutation_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sales_diff</td>\n",
       "      <td>1.3694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>rolling_mean_tmp_1_7</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>no_sales</td>\n",
       "      <td>0.5089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sales_pca_id7_3</td>\n",
       "      <td>0.3134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sales_pca_id7_2</td>\n",
       "      <td>0.3091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>rolling_mean_tmp_1_14</td>\n",
       "      <td>0.1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>rolling_mean_tmp_1_30</td>\n",
       "      <td>0.0716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>rolling_mean_tmp_1_60</td>\n",
       "      <td>0.0217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>sum_latest7_sales</td>\n",
       "      <td>0.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tm_dw</td>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sum_latest14_sales</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>sales_diff_fft_amp1</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>sum_latest60_sales</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tm_w_end</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>rolling_mean_tmp_7_7</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sales_lag_29</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>sales_lag_36</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>sum_latest30_sales</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>sales_lag_42</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>enc_tm_dw_mean</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  permutation_importance\n",
       "49              sales_diff                  1.3694\n",
       "91    rolling_mean_tmp_1_7                  0.8580\n",
       "50                no_sales                  0.5089\n",
       "48         sales_pca_id7_3                  0.3134\n",
       "47         sales_pca_id7_2                  0.3091\n",
       "92   rolling_mean_tmp_1_14                  0.1684\n",
       "93   rolling_mean_tmp_1_30                  0.0716\n",
       "94   rolling_mean_tmp_1_60                  0.0217\n",
       "68       sum_latest7_sales                  0.0135\n",
       "18                   tm_dw                  0.0134\n",
       "73      sum_latest14_sales                  0.0074\n",
       "103    sales_diff_fft_amp1                  0.0063\n",
       "83      sum_latest60_sales                  0.0048\n",
       "19                tm_w_end                  0.0048\n",
       "95    rolling_mean_tmp_7_7                  0.0046\n",
       "52            sales_lag_29                  0.0040\n",
       "59            sales_lag_36                  0.0040\n",
       "78      sum_latest30_sales                  0.0036\n",
       "65            sales_lag_42                  0.0035\n",
       "26          enc_tm_dw_mean                  0.0034"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['feature'] = estimator.feature_name()\n",
    "feature_importance_df['importance'] = estimator.feature_importance()\n",
    "feature_importance_df.sort_values(by=['importance'], ascending=False, inplace=True)\n",
    "feature_importance_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# feature_importance_df = pd.DataFrame()\n",
    "# for store_id in STORES_IDS:\n",
    "#     model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "#     estimator = pickle.load(open(model_name, 'rb'))\n",
    "#     feature_importance_df[store_id] = estimator.feature_importance()\n",
    "# feature_importance_df['feature'] = estimator.feature_name()\n",
    "# feature_importance_df['importance_mean'] = feature_importance_df.drop(columns=['feature']).mean(axis=1)\n",
    "# feature_importance_df.sort_values(by=['importance_mean'], ascending=False, inplace=True)\n",
    "# feature_importance_df.reset_index(drop=True, inplace=True)\n",
    "# # lgb.plot_importance(estimator, max_num_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0ce3ff02b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Train CA_1\n",
    "[100]\tvalid_0's rmse: 2.05355\n",
    "[200]\tvalid_0's rmse: 2.05005\n",
    "[300]\tvalid_0's rmse: 2.05159\n",
    "[400]\tvalid_0's rmse: 2.05153\n",
    "[500]\tvalid_0's rmse: 2.05033\n",
    "[600]\tvalid_0's rmse: 2.04557\n",
    "[700]\tvalid_0's rmse: 2.03879\n",
    "[800]\tvalid_0's rmse: 2.03395\n",
    "[900]\tvalid_0's rmse: 2.02572\n",
    "[1000]\tvalid_0's rmse: 2.01963\n",
    "[1100]\tvalid_0's rmse: 2.01417\n",
    "[1200]\tvalid_0's rmse: 2.00851\n",
    "[1300]\tvalid_0's rmse: 2.00469\n",
    "[1400]\tvalid_0's rmse: 1.99971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_importance_df = his[0]['permutation_importance_df'].rename(columns={'permutation_importance':'permutation_importance1'})\n",
    "for idx, item in enumerate(his[1:]):\n",
    "    permutation_importance_df = pd.merge(permutation_importance_df, item['permutation_importance_df'].rename(columns={'permutation_importance':f'permutation_importance{idx+2}'}), on='feature', how='left',)\n",
    "permutation_importance_df['permutation_importance'] = permutation_importance_df.drop(columns=['feature']).mean(axis=1)\n",
    "permutation_importance_df.sort_values(by=['permutation_importance'], ascending=False, inplace=True)\n",
    "permutation_importance_df = permutation_importance_df[['feature','permutation_importance']+[f'permutation_importance{i}' for i in range(1, 11)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>permutation_importance</th>\n",
       "      <th>permutation_importance1</th>\n",
       "      <th>permutation_importance2</th>\n",
       "      <th>permutation_importance3</th>\n",
       "      <th>permutation_importance4</th>\n",
       "      <th>permutation_importance5</th>\n",
       "      <th>permutation_importance6</th>\n",
       "      <th>permutation_importance7</th>\n",
       "      <th>permutation_importance8</th>\n",
       "      <th>permutation_importance9</th>\n",
       "      <th>permutation_importance10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rolling_mean_tmp_1_7</td>\n",
       "      <td>0.91387</td>\n",
       "      <td>0.8179</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>1.4656</td>\n",
       "      <td>0.2022</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>1.4629</td>\n",
       "      <td>1.3514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rolling_mean_tmp_1_14</td>\n",
       "      <td>0.38904</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3393</td>\n",
       "      <td>0.3260</td>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.2815</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>0.4158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rolling_mean_tmp_7_7</td>\n",
       "      <td>0.06319</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.1336</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tm_dw</td>\n",
       "      <td>0.02659</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rolling_mean_tmp_1_30</td>\n",
       "      <td>0.01717</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enc_tm_dw_item_id_mean</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rolling_mean_tmp_7_14</td>\n",
       "      <td>0.01405</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>enc_tm_dw_mean</td>\n",
       "      <td>0.00798</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rolling_mean_tmp_7_30</td>\n",
       "      <td>0.00684</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tm_d</td>\n",
       "      <td>0.00553</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>enc_tm_dw_std</td>\n",
       "      <td>0.00393</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>enc_tm_dw_item_id_std</td>\n",
       "      <td>0.00392</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sum_latest60_sales</td>\n",
       "      <td>0.00345</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>rolling_mean_tmp_1_60</td>\n",
       "      <td>0.00337</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rolling_mean_14</td>\n",
       "      <td>0.00320</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tm_w_end</td>\n",
       "      <td>0.00315</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sum_latest180_sales</td>\n",
       "      <td>0.00312</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rolling_mean_7</td>\n",
       "      <td>0.00282</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rolling_mean_tmp_14_14</td>\n",
       "      <td>0.00275</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sales_diff_rolling_std_180</td>\n",
       "      <td>0.00264</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rolling_mean_tmp_7_60</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rolling_mean_180</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>enc_item_id_mean</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sales_diff_fft_amp3</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>sum_latest14_sales</td>\n",
       "      <td>0.00217</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rolling_std_180</td>\n",
       "      <td>0.00212</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sales_diff_rolling_std_60</td>\n",
       "      <td>0.00207</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sales_diff_rolling_std_7</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rolling_mean_30</td>\n",
       "      <td>0.00199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rolling_std_7</td>\n",
       "      <td>0.00199</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sum_latest30_sales</td>\n",
       "      <td>0.00194</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>rolling_mean_60</td>\n",
       "      <td>0.00194</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>price_norm</td>\n",
       "      <td>0.00193</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sales_diff_rolling_std_14</td>\n",
       "      <td>0.00187</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>enc_item_id_std</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rolling_mean_tmp_14_60</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rolling_std_14</td>\n",
       "      <td>0.00185</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rolling_mean_tmp_14_7</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sales_diff_rolling_std_30</td>\n",
       "      <td>0.00178</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>price_momentum_m</td>\n",
       "      <td>0.00177</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>sales_lag_38</td>\n",
       "      <td>0.00164</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>rolling_mean_tmp_14_30</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rolling_std_60</td>\n",
       "      <td>0.00153</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rolling_std_30</td>\n",
       "      <td>0.00149</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>sales_lag_33</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sales_lag_31</td>\n",
       "      <td>0.00135</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sales_lag_40</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sales_lag_32</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sales_lag_39</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sales_diff_fft_amp1</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>sum_latest7_sales</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>sales_diff_rolling_mean_180</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sell_price</td>\n",
       "      <td>0.00103</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sales_diff_fft_amp2</td>\n",
       "      <td>0.00095</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sales_lag_30</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sales_lag_37</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>item_nunique</td>\n",
       "      <td>0.00086</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>sales_diff_rolling_mean_30</td>\n",
       "      <td>0.00085</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sales_lag_28</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>price_min</td>\n",
       "      <td>0.00069</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>price_max</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tm_wm</td>\n",
       "      <td>0.00056</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>-0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>sales_diff_rolling_mean_14</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>sales_diff_fft_freq2</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>price_mean</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>price_std</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>release</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sales_lag_35</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0053</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>sales_diff_rolling_mean_7</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>price_momentum</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>price_momentum_y</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tm_w</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>sales_diff_fft_freq1</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>enc_cat_id_mean</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>enc_dept_id_mean</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tm_m</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>sales_diff_fft_freq3</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>enc_cat_id_std</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>enc_dept_id_std</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tm_y</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>price_nunique</td>\n",
       "      <td>-0.00010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>sales_lag_41</td>\n",
       "      <td>-0.00048</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sales_lag_34</td>\n",
       "      <td>-0.00051</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>sales_lag_36</td>\n",
       "      <td>-0.00053</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>sales_diff_rolling_mean_60</td>\n",
       "      <td>-0.00080</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>-0.0085</td>\n",
       "      <td>-0.0021</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>sales_lag_42</td>\n",
       "      <td>-0.00094</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0178</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>sales_lag_29</td>\n",
       "      <td>-0.00097</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0056</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>-0.0056</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  permutation_importance  \\\n",
       "0          rolling_mean_tmp_1_7                 0.91387   \n",
       "1         rolling_mean_tmp_1_14                 0.38904   \n",
       "2          rolling_mean_tmp_7_7                 0.06319   \n",
       "3                         tm_dw                 0.02659   \n",
       "7         rolling_mean_tmp_1_30                 0.01717   \n",
       "4        enc_tm_dw_item_id_mean                 0.01472   \n",
       "5         rolling_mean_tmp_7_14                 0.01405   \n",
       "6                enc_tm_dw_mean                 0.00798   \n",
       "9         rolling_mean_tmp_7_30                 0.00684   \n",
       "11                         tm_d                 0.00553   \n",
       "8                 enc_tm_dw_std                 0.00393   \n",
       "13        enc_tm_dw_item_id_std                 0.00392   \n",
       "23           sum_latest60_sales                 0.00345   \n",
       "83        rolling_mean_tmp_1_60                 0.00337   \n",
       "22              rolling_mean_14                 0.00320   \n",
       "24                     tm_w_end                 0.00315   \n",
       "47          sum_latest180_sales                 0.00312   \n",
       "10               rolling_mean_7                 0.00282   \n",
       "15       rolling_mean_tmp_14_14                 0.00275   \n",
       "17   sales_diff_rolling_std_180                 0.00264   \n",
       "26        rolling_mean_tmp_7_60                 0.00261   \n",
       "12             rolling_mean_180                 0.00250   \n",
       "18             enc_item_id_mean                 0.00249   \n",
       "27          sales_diff_fft_amp3                 0.00244   \n",
       "67           sum_latest14_sales                 0.00217   \n",
       "16              rolling_std_180                 0.00212   \n",
       "33    sales_diff_rolling_std_60                 0.00207   \n",
       "31     sales_diff_rolling_std_7                 0.00200   \n",
       "14              rolling_mean_30                 0.00199   \n",
       "29                rolling_std_7                 0.00199   \n",
       "28           sum_latest30_sales                 0.00194   \n",
       "41              rolling_mean_60                 0.00194   \n",
       "39                   price_norm                 0.00193   \n",
       "19    sales_diff_rolling_std_14                 0.00187   \n",
       "20              enc_item_id_std                 0.00186   \n",
       "34       rolling_mean_tmp_14_60                 0.00186   \n",
       "30               rolling_std_14                 0.00185   \n",
       "32        rolling_mean_tmp_14_7                 0.00182   \n",
       "25    sales_diff_rolling_std_30                 0.00178   \n",
       "35             price_momentum_m                 0.00177   \n",
       "45                 sales_lag_38                 0.00164   \n",
       "37       rolling_mean_tmp_14_30                 0.00162   \n",
       "42               rolling_std_60                 0.00153   \n",
       "36               rolling_std_30                 0.00149   \n",
       "46                 sales_lag_33                 0.00141   \n",
       "56                 sales_lag_31                 0.00135   \n",
       "21                 sales_lag_40                 0.00133   \n",
       "53                 sales_lag_32                 0.00132   \n",
       "48                 sales_lag_39                 0.00130   \n",
       "38          sales_diff_fft_amp1                 0.00125   \n",
       "81            sum_latest7_sales                 0.00123   \n",
       "68  sales_diff_rolling_mean_180                 0.00115   \n",
       "44                   sell_price                 0.00103   \n",
       "49          sales_diff_fft_amp2                 0.00095   \n",
       "43                 sales_lag_30                 0.00092   \n",
       "40                 sales_lag_37                 0.00092   \n",
       "57                 item_nunique                 0.00086   \n",
       "79   sales_diff_rolling_mean_30                 0.00085   \n",
       "85                 sales_lag_28                 0.00074   \n",
       "54                    price_min                 0.00069   \n",
       "58                    price_max                 0.00067   \n",
       "63                        tm_wm                 0.00056   \n",
       "59   sales_diff_rolling_mean_14                 0.00053   \n",
       "65         sales_diff_fft_freq2                 0.00053   \n",
       "66                   price_mean                 0.00050   \n",
       "64                    price_std                 0.00042   \n",
       "77                      release                 0.00040   \n",
       "52                 sales_lag_35                 0.00039   \n",
       "55    sales_diff_rolling_mean_7                 0.00039   \n",
       "75               price_momentum                 0.00028   \n",
       "71             price_momentum_y                 0.00028   \n",
       "72                         tm_w                 0.00027   \n",
       "61         sales_diff_fft_freq1                 0.00026   \n",
       "73              enc_cat_id_mean                 0.00017   \n",
       "82             enc_dept_id_mean                 0.00012   \n",
       "76                         tm_m                 0.00011   \n",
       "60         sales_diff_fft_freq3                 0.00008   \n",
       "78               enc_cat_id_std                 0.00004   \n",
       "80              enc_dept_id_std                 0.00001   \n",
       "74                         tm_y                 0.00000   \n",
       "70                price_nunique                -0.00010   \n",
       "51                 sales_lag_41                -0.00048   \n",
       "50                 sales_lag_34                -0.00051   \n",
       "69                 sales_lag_36                -0.00053   \n",
       "86   sales_diff_rolling_mean_60                -0.00080   \n",
       "62                 sales_lag_42                -0.00094   \n",
       "84                 sales_lag_29                -0.00097   \n",
       "\n",
       "    permutation_importance1  permutation_importance2  permutation_importance3  \\\n",
       "0                    0.8179                   0.6102                   1.4656   \n",
       "1                    0.3695                   0.3854                   0.6054   \n",
       "2                    0.0643                   0.0340                   0.1336   \n",
       "3                    0.0283                   0.0366                   0.0350   \n",
       "7                    0.0069                   0.0214                   0.0160   \n",
       "4                    0.0151                   0.0132                   0.0211   \n",
       "5                    0.0139                   0.0129                   0.0267   \n",
       "6                    0.0070                   0.0109                   0.0073   \n",
       "9                    0.0061                   0.0060                   0.0066   \n",
       "11                   0.0043                   0.0023                   0.0039   \n",
       "8                    0.0064                   0.0041                   0.0030   \n",
       "13                   0.0034                   0.0074                   0.0060   \n",
       "23                   0.0027                   0.0092                  -0.0027   \n",
       "83                  -0.0019                   0.0058                  -0.0013   \n",
       "22                   0.0027                   0.0019                   0.0039   \n",
       "24                   0.0027                   0.0042                   0.0070   \n",
       "47                   0.0015                   0.0046                   0.0021   \n",
       "10                   0.0045                   0.0021                   0.0017   \n",
       "15                   0.0032                   0.0031                   0.0024   \n",
       "17                   0.0031                   0.0022                   0.0034   \n",
       "26                   0.0025                   0.0054                   0.0029   \n",
       "12                   0.0037                   0.0022                   0.0036   \n",
       "18                   0.0030                   0.0013                   0.0069   \n",
       "27                   0.0025                   0.0030                   0.0013   \n",
       "67                   0.0002                   0.0046                  -0.0006   \n",
       "16                   0.0031                   0.0017                   0.0022   \n",
       "33                   0.0021                   0.0019                   0.0037   \n",
       "31                   0.0023                   0.0016                   0.0034   \n",
       "14                   0.0033                   0.0030                   0.0028   \n",
       "29                   0.0024                   0.0014                   0.0019   \n",
       "28                   0.0024                   0.0066                   0.0002   \n",
       "41                   0.0017                   0.0025                   0.0025   \n",
       "39                   0.0017                   0.0005                   0.0100   \n",
       "19                   0.0028                   0.0014                   0.0030   \n",
       "20                   0.0028                   0.0011                   0.0031   \n",
       "34                   0.0019                   0.0024                   0.0028   \n",
       "30                   0.0023                   0.0018                   0.0027   \n",
       "32                   0.0022                   0.0037                  -0.0022   \n",
       "25                   0.0026                   0.0020                   0.0022   \n",
       "35                   0.0018                   0.0009                   0.0022   \n",
       "45                   0.0015                   0.0006                   0.0021   \n",
       "37                   0.0018                   0.0057                  -0.0047   \n",
       "42                   0.0017                   0.0015                   0.0020   \n",
       "36                   0.0018                   0.0021                   0.0016   \n",
       "46                   0.0015                   0.0007                   0.0049   \n",
       "56                   0.0006                   0.0005                  -0.0001   \n",
       "21                   0.0028                   0.0007                   0.0014   \n",
       "53                   0.0008                   0.0006                   0.0004   \n",
       "48                   0.0014                   0.0004                   0.0024   \n",
       "38                   0.0017                   0.0018                  -0.0002   \n",
       "81                  -0.0002                   0.0046                  -0.0028   \n",
       "68                   0.0002                   0.0037                   0.0047   \n",
       "44                   0.0016                   0.0014                   0.0021   \n",
       "49                   0.0012                   0.0028                  -0.0011   \n",
       "43                   0.0016                   0.0007                  -0.0026   \n",
       "40                   0.0017                   0.0011                  -0.0011   \n",
       "57                   0.0006                   0.0007                   0.0036   \n",
       "79                  -0.0002                   0.0012                   0.0011   \n",
       "85                  -0.0022                   0.0034                  -0.0067   \n",
       "54                   0.0008                   0.0005                   0.0009   \n",
       "58                   0.0006                   0.0010                   0.0014   \n",
       "63                   0.0004                   0.0003                   0.0005   \n",
       "59                   0.0005                   0.0007                  -0.0002   \n",
       "65                   0.0003                   0.0006                   0.0026   \n",
       "66                   0.0003                   0.0009                   0.0016   \n",
       "64                   0.0003                   0.0005                   0.0008   \n",
       "77                  -0.0000                   0.0020                   0.0013   \n",
       "52                   0.0008                   0.0055                  -0.0059   \n",
       "55                   0.0006                   0.0009                   0.0007   \n",
       "75                   0.0000                  -0.0001                   0.0025   \n",
       "71                   0.0001                   0.0002                   0.0014   \n",
       "72                   0.0001                   0.0003                   0.0002   \n",
       "61                   0.0004                   0.0006                  -0.0004   \n",
       "73                   0.0000                   0.0001                   0.0001   \n",
       "82                  -0.0010                   0.0001                   0.0001   \n",
       "76                   0.0000                   0.0002                   0.0001   \n",
       "60                   0.0005                   0.0004                  -0.0017   \n",
       "78                  -0.0001                   0.0001                  -0.0001   \n",
       "80                  -0.0002                   0.0002                  -0.0001   \n",
       "74                   0.0000                   0.0000                   0.0000   \n",
       "70                   0.0001                   0.0001                  -0.0017   \n",
       "51                   0.0009                   0.0017                  -0.0072   \n",
       "50                   0.0011                   0.0011                  -0.0047   \n",
       "69                   0.0002                   0.0017                  -0.0060   \n",
       "86                  -0.0043                   0.0025                  -0.0004   \n",
       "62                   0.0004                   0.0046                  -0.0178   \n",
       "84                  -0.0020                   0.0018                  -0.0056   \n",
       "\n",
       "    permutation_importance4  permutation_importance5  permutation_importance6  \\\n",
       "0                    0.2022                   0.9141                   0.9704   \n",
       "1                    0.1556                   0.3393                   0.3260   \n",
       "2                    0.0121                   0.0347                   0.0707   \n",
       "3                    0.0062                   0.0235                   0.0321   \n",
       "7                    0.0060                   0.0106                   0.0018   \n",
       "4                    0.0083                   0.0109                   0.0222   \n",
       "5                    0.0042                   0.0092                   0.0178   \n",
       "6                    0.0019                   0.0041                   0.0116   \n",
       "9                    0.0040                   0.0059                   0.0071   \n",
       "11                   0.0011                   0.0014                   0.0022   \n",
       "8                    0.0004                   0.0020                   0.0046   \n",
       "13                   0.0021                   0.0022                   0.0007   \n",
       "23                   0.0038                   0.0031                   0.0043   \n",
       "83                   0.0015                   0.0035                   0.0004   \n",
       "22                   0.0026                   0.0015                   0.0072   \n",
       "24                   0.0006                   0.0029                   0.0034   \n",
       "47                   0.0038                   0.0030                   0.0031   \n",
       "10                   0.0014                   0.0016                   0.0050   \n",
       "15                   0.0027                   0.0018                   0.0007   \n",
       "17                   0.0021                   0.0025                   0.0017   \n",
       "26                   0.0019                   0.0014                  -0.0061   \n",
       "12                   0.0019                   0.0026                   0.0019   \n",
       "18                   0.0019                   0.0019                   0.0013   \n",
       "27                   0.0023                   0.0025                   0.0018   \n",
       "67                   0.0019                   0.0017                   0.0030   \n",
       "16                   0.0014                   0.0017                   0.0018   \n",
       "33                   0.0018                   0.0015                   0.0022   \n",
       "31                   0.0015                   0.0015                   0.0019   \n",
       "14                   0.0015                   0.0009                  -0.0004   \n",
       "29                   0.0015                   0.0005                   0.0021   \n",
       "28                   0.0037                   0.0023                  -0.0095   \n",
       "41                   0.0019                   0.0019                   0.0012   \n",
       "39                   0.0003                   0.0027                   0.0028   \n",
       "19                   0.0016                   0.0013                   0.0021   \n",
       "20                   0.0010                   0.0025                   0.0023   \n",
       "34                   0.0015                   0.0021                   0.0011   \n",
       "30                   0.0012                   0.0012                   0.0023   \n",
       "32                   0.0015                   0.0025                  -0.0022   \n",
       "25                   0.0020                   0.0011                   0.0016   \n",
       "35                   0.0008                   0.0046                   0.0032   \n",
       "45                   0.0007                   0.0006                   0.0037   \n",
       "37                   0.0022                   0.0019                   0.0011   \n",
       "42                   0.0014                   0.0017                   0.0015   \n",
       "36                   0.0015                   0.0013                   0.0010   \n",
       "46                   0.0007                   0.0003                   0.0009   \n",
       "56                   0.0004                   0.0006                   0.0051   \n",
       "21                   0.0006                   0.0010                   0.0030   \n",
       "53                   0.0010                   0.0007                   0.0037   \n",
       "48                   0.0010                   0.0009                   0.0021   \n",
       "38                   0.0012                   0.0004                   0.0016   \n",
       "81                   0.0010                   0.0009                   0.0023   \n",
       "68                   0.0006                  -0.0001                  -0.0042   \n",
       "44                   0.0004                   0.0011                  -0.0004   \n",
       "49                   0.0008                   0.0008                   0.0000   \n",
       "43                   0.0003                   0.0005                   0.0035   \n",
       "40                   0.0004                   0.0010                   0.0019   \n",
       "57                   0.0007                   0.0005                   0.0009   \n",
       "79                   0.0006                  -0.0003                   0.0007   \n",
       "85                   0.0003                  -0.0014                  -0.0049   \n",
       "54                   0.0005                   0.0005                   0.0004   \n",
       "58                   0.0003                   0.0004                   0.0007   \n",
       "63                   0.0001                   0.0005                   0.0003   \n",
       "59                   0.0004                   0.0004                   0.0004   \n",
       "65                   0.0003                   0.0002                   0.0003   \n",
       "66                   0.0003                   0.0004                  -0.0006   \n",
       "64                   0.0003                   0.0002                   0.0004   \n",
       "77                  -0.0000                  -0.0003                   0.0001   \n",
       "52                   0.0007                   0.0004                  -0.0053   \n",
       "55                   0.0005                   0.0004                   0.0001   \n",
       "75                   0.0000                   0.0001                   0.0001   \n",
       "71                   0.0001                   0.0000                   0.0001   \n",
       "72                   0.0001                   0.0002                   0.0002   \n",
       "61                   0.0002                   0.0002                   0.0004   \n",
       "73                   0.0000                   0.0000                   0.0000   \n",
       "82                  -0.0000                  -0.0002                   0.0003   \n",
       "76                   0.0001                   0.0002                   0.0000   \n",
       "60                   0.0003                  -0.0003                   0.0004   \n",
       "78                   0.0000                   0.0001                  -0.0000   \n",
       "80                  -0.0001                  -0.0002                  -0.0005   \n",
       "74                   0.0000                   0.0000                   0.0000   \n",
       "70                   0.0001                   0.0001                  -0.0000   \n",
       "51                   0.0001                   0.0002                  -0.0036   \n",
       "50                   0.0006                   0.0005                  -0.0032   \n",
       "69                   0.0006                  -0.0001                  -0.0034   \n",
       "86                  -0.0001                  -0.0013                  -0.0085   \n",
       "62                   0.0008                  -0.0010                  -0.0050   \n",
       "84                   0.0000                  -0.0009                  -0.0056   \n",
       "\n",
       "    permutation_importance7  permutation_importance8  permutation_importance9  \\\n",
       "0                    0.8684                   0.4756                   1.4629   \n",
       "1                    0.3957                   0.2815                   0.6162   \n",
       "2                    0.0680                   0.0375                   0.0988   \n",
       "3                    0.0163                   0.0284                   0.0120   \n",
       "7                    0.0109                   0.0082                   0.0677   \n",
       "4                    0.0165                   0.0078                   0.0078   \n",
       "5                    0.0146                   0.0108                   0.0153   \n",
       "6                    0.0042                   0.0130                   0.0057   \n",
       "9                    0.0064                   0.0052                   0.0129   \n",
       "11                   0.0029                   0.0024                   0.0258   \n",
       "8                    0.0024                   0.0067                   0.0026   \n",
       "13                   0.0019                   0.0023                   0.0072   \n",
       "23                   0.0015                   0.0046                   0.0049   \n",
       "83                  -0.0008                   0.0037                   0.0173   \n",
       "22                   0.0034                   0.0018                   0.0032   \n",
       "24                   0.0014                   0.0037                   0.0010   \n",
       "47                   0.0021                   0.0028                   0.0045   \n",
       "10                   0.0018                   0.0021                   0.0064   \n",
       "15                   0.0021                   0.0035                   0.0056   \n",
       "17                   0.0038                   0.0026                   0.0032   \n",
       "26                  -0.0006                   0.0025                   0.0108   \n",
       "12                   0.0040                   0.0020                   0.0018   \n",
       "18                   0.0031                   0.0020                   0.0015   \n",
       "27                   0.0022                   0.0031                   0.0031   \n",
       "67                   0.0014                   0.0024                   0.0043   \n",
       "16                   0.0037                   0.0019                   0.0030   \n",
       "33                   0.0020                   0.0020                   0.0016   \n",
       "31                   0.0028                   0.0013                   0.0024   \n",
       "14                   0.0017                   0.0021                   0.0029   \n",
       "29                   0.0025                   0.0011                   0.0045   \n",
       "28                   0.0026                   0.0044                   0.0042   \n",
       "41                   0.0016                   0.0020                   0.0023   \n",
       "39                   0.0011                   0.0001                   0.0001   \n",
       "19                   0.0020                   0.0016                   0.0010   \n",
       "20                   0.0015                   0.0011                   0.0017   \n",
       "34                   0.0026                   0.0017                   0.0009   \n",
       "30                   0.0012                   0.0014                   0.0017   \n",
       "32                   0.0029                   0.0032                   0.0051   \n",
       "25                   0.0017                   0.0017                   0.0017   \n",
       "35                   0.0021                   0.0009                   0.0004   \n",
       "45                   0.0030                   0.0006                   0.0010   \n",
       "37                   0.0005                   0.0027                   0.0033   \n",
       "42                   0.0013                   0.0016                   0.0014   \n",
       "36                   0.0011                   0.0014                   0.0015   \n",
       "46                   0.0028                   0.0005                   0.0000   \n",
       "56                   0.0032                   0.0007                   0.0018   \n",
       "21                   0.0008                   0.0010                   0.0006   \n",
       "53                   0.0041                   0.0005                  -0.0000   \n",
       "48                   0.0020                   0.0006                   0.0006   \n",
       "38                   0.0014                   0.0013                   0.0019   \n",
       "81                  -0.0005                   0.0011                   0.0035   \n",
       "68                  -0.0011                   0.0007                   0.0030   \n",
       "44                   0.0004                   0.0010                   0.0014   \n",
       "49                   0.0012                   0.0010                   0.0015   \n",
       "43                   0.0022                   0.0008                   0.0015   \n",
       "40                   0.0011                   0.0004                   0.0006   \n",
       "57                   0.0006                   0.0007                   0.0009   \n",
       "79                  -0.0002                   0.0007                   0.0013   \n",
       "85                  -0.0012                   0.0005                   0.0103   \n",
       "54                   0.0004                   0.0008                   0.0013   \n",
       "58                   0.0003                   0.0003                   0.0011   \n",
       "63                   0.0006                   0.0002                   0.0032   \n",
       "59                   0.0006                   0.0005                   0.0018   \n",
       "65                  -0.0000                   0.0004                   0.0003   \n",
       "66                   0.0007                   0.0005                   0.0007   \n",
       "64                   0.0004                   0.0003                   0.0006   \n",
       "77                   0.0002                  -0.0008                   0.0016   \n",
       "52                   0.0011                   0.0006                   0.0037   \n",
       "55                   0.0004                   0.0007                  -0.0011   \n",
       "75                   0.0001                   0.0000                   0.0000   \n",
       "71                   0.0003                   0.0001                  -0.0000   \n",
       "72                   0.0001                   0.0010                   0.0002   \n",
       "61                  -0.0000                   0.0004                   0.0004   \n",
       "73                   0.0000                   0.0001                   0.0011   \n",
       "82                   0.0003                   0.0001                   0.0006   \n",
       "76                   0.0001                   0.0002                   0.0001   \n",
       "60                   0.0004                   0.0002                   0.0003   \n",
       "78                   0.0000                  -0.0000                   0.0002   \n",
       "80                   0.0003                  -0.0000                   0.0003   \n",
       "74                   0.0000                   0.0000                   0.0000   \n",
       "70                   0.0001                   0.0000                   0.0001   \n",
       "51                  -0.0007                   0.0003                   0.0022   \n",
       "50                  -0.0020                   0.0000                   0.0007   \n",
       "69                  -0.0006                   0.0004                   0.0005   \n",
       "86                  -0.0021                   0.0015                   0.0007   \n",
       "62                  -0.0004                   0.0007                   0.0043   \n",
       "84                  -0.0008                   0.0008                   0.0010   \n",
       "\n",
       "    permutation_importance10  \n",
       "0                     1.3514  \n",
       "1                     0.4158  \n",
       "2                     0.0782  \n",
       "3                     0.0475  \n",
       "7                     0.0222  \n",
       "4                     0.0243  \n",
       "5                     0.0151  \n",
       "6                     0.0141  \n",
       "9                     0.0082  \n",
       "11                    0.0090  \n",
       "8                     0.0071  \n",
       "13                    0.0060  \n",
       "23                    0.0031  \n",
       "83                    0.0055  \n",
       "22                    0.0038  \n",
       "24                    0.0046  \n",
       "47                    0.0037  \n",
       "10                    0.0016  \n",
       "15                    0.0024  \n",
       "17                    0.0018  \n",
       "26                    0.0054  \n",
       "12                    0.0013  \n",
       "18                    0.0020  \n",
       "27                    0.0026  \n",
       "67                    0.0028  \n",
       "16                    0.0007  \n",
       "33                    0.0019  \n",
       "31                    0.0013  \n",
       "14                    0.0021  \n",
       "29                    0.0020  \n",
       "28                    0.0025  \n",
       "41                    0.0018  \n",
       "39                    0.0000  \n",
       "19                    0.0019  \n",
       "20                    0.0015  \n",
       "34                    0.0016  \n",
       "30                    0.0027  \n",
       "32                    0.0015  \n",
       "25                    0.0012  \n",
       "35                    0.0008  \n",
       "45                    0.0026  \n",
       "37                    0.0017  \n",
       "42                    0.0012  \n",
       "36                    0.0016  \n",
       "46                    0.0018  \n",
       "56                    0.0007  \n",
       "21                    0.0014  \n",
       "53                    0.0014  \n",
       "48                    0.0016  \n",
       "38                    0.0014  \n",
       "81                    0.0024  \n",
       "68                    0.0040  \n",
       "44                    0.0013  \n",
       "49                    0.0013  \n",
       "43                    0.0007  \n",
       "40                    0.0021  \n",
       "57                   -0.0006  \n",
       "79                    0.0036  \n",
       "85                    0.0093  \n",
       "54                    0.0008  \n",
       "58                    0.0006  \n",
       "63                   -0.0005  \n",
       "59                    0.0002  \n",
       "65                    0.0003  \n",
       "66                    0.0002  \n",
       "64                    0.0004  \n",
       "77                   -0.0001  \n",
       "52                    0.0023  \n",
       "55                    0.0007  \n",
       "75                    0.0001  \n",
       "71                    0.0005  \n",
       "72                    0.0003  \n",
       "61                    0.0004  \n",
       "73                    0.0003  \n",
       "82                    0.0009  \n",
       "76                    0.0001  \n",
       "60                    0.0003  \n",
       "78                    0.0002  \n",
       "80                    0.0004  \n",
       "74                    0.0000  \n",
       "70                    0.0001  \n",
       "51                    0.0013  \n",
       "50                    0.0008  \n",
       "69                    0.0014  \n",
       "86                    0.0040  \n",
       "62                    0.0040  \n",
       "84                    0.0016  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def make_pca(df, pca_col, n_days):\n",
    "    print('PCA:', pca_col, n_days)\n",
    "    \n",
    "    # We don't need any other columns to make pca\n",
    "    pca_df = df[[pca_col,'d',TARGET]]\n",
    "    \n",
    "    # If we are doing pca for other series \"levels\" \n",
    "    # we need to agg first\n",
    "    if pca_col != 'id':\n",
    "        merge_base = pca_df[[pca_col,'d']]\n",
    "        pca_df = pca_df.groupby([pca_col,'d'])[TARGET].agg(['sum']).reset_index()\n",
    "        pca_df[TARGET] = pca_df['sum']\n",
    "        del pca_df['sum']\n",
    "    \n",
    "    # Min/Max scaling\n",
    "    pca_df[TARGET] = pca_df[TARGET]/pca_df[TARGET].max()\n",
    "    \n",
    "    # Making \"lag\" in old way (not parallel)\n",
    "    LAG_DAYS = [col for col in range(1,n_days+1)]\n",
    "    format_s = '{}_pca_'+pca_col+str(n_days)+'_{}'\n",
    "    pca_df = pca_df.assign(**{\n",
    "            format_s.format(col, l): pca_df.groupby([pca_col])[col].transform(lambda x: x.shift(l))\n",
    "            for l in LAG_DAYS\n",
    "            for col in [TARGET]\n",
    "        })\n",
    "    \n",
    "    pca_columns = list(pca_df)[3:]\n",
    "    \n",
    "    pca_df[pca_columns] = pca_df[pca_columns].fillna(-999999)\n",
    "    pca = PCA(random_state=SEED)\n",
    "    \n",
    "    # You can use fit_transform here\n",
    "    \n",
    "    pca.fit(pca_df[pca_columns])\n",
    "    pca_df[pca_columns] = pca.transform(pca_df[pca_columns])\n",
    "    \n",
    "    print(pca.explained_variance_ratio_)\n",
    "    \n",
    "    # we will keep only 3 most \"valuable\" columns/dimensions \n",
    "    keep_cols = pca_columns[:3]\n",
    "    print('Columns to keep:', keep_cols)\n",
    "    \n",
    "    # If we are doing pca for other series \"levels\"\n",
    "    # we need merge back our results to merge_base df\n",
    "    # and only than return resulted df\n",
    "    # I'll skip that step here\n",
    "    \n",
    "    return pca_df[keep_cols]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict | Day: 1\n",
      "##########  0.40 min round |  0.40 min total |  37017.23 day sales |\n",
      "Predict | Day: 2\n",
      "##########  0.39 min round |  0.79 min total |  34847.97 day sales |\n",
      "Predict | Day: 3\n",
      "##########  0.39 min round |  1.18 min total |  34410.46 day sales |\n",
      "Predict | Day: 4\n",
      "##########  0.39 min round |  1.57 min total |  34847.52 day sales |\n",
      "Predict | Day: 5\n",
      "##########  0.40 min round |  1.97 min total |  40452.51 day sales |\n",
      "Predict | Day: 6\n",
      "##########  0.39 min round |  2.36 min total |  49418.73 day sales |\n",
      "Predict | Day: 7\n",
      "##########  0.39 min round |  2.75 min total |  53106.42 day sales |\n",
      "Predict | Day: 8\n",
      "##########  0.40 min round |  3.15 min total |  44475.07 day sales |\n",
      "Predict | Day: 9\n",
      "##########  0.39 min round |  3.54 min total |  43574.40 day sales |\n",
      "Predict | Day: 10\n",
      "##########  0.39 min round |  3.93 min total |  38899.64 day sales |\n",
      "Predict | Day: 11\n",
      "##########  0.39 min round |  4.33 min total |  40427.91 day sales |\n",
      "Predict | Day: 12\n",
      "##########  0.39 min round |  4.72 min total |  46355.96 day sales |\n",
      "Predict | Day: 13\n",
      "##########  0.39 min round |  5.11 min total |  53930.34 day sales |\n",
      "Predict | Day: 14\n",
      "##########  0.38 min round |  5.49 min total |  46719.34 day sales |\n",
      "Predict | Day: 15\n",
      "##########  0.40 min round |  5.89 min total |  44361.25 day sales |\n",
      "Predict | Day: 16\n",
      "##########  0.40 min round |  6.29 min total |  39044.53 day sales |\n",
      "Predict | Day: 17\n",
      "##########  0.40 min round |  6.69 min total |  40629.12 day sales |\n",
      "Predict | Day: 18\n",
      "##########  0.39 min round |  7.08 min total |  40979.26 day sales |\n",
      "Predict | Day: 19\n",
      "##########  0.39 min round |  7.48 min total |  44321.01 day sales |\n",
      "Predict | Day: 20\n",
      "##########  0.40 min round |  7.87 min total |  53924.25 day sales |\n",
      "Predict | Day: 21\n",
      "##########  0.39 min round |  8.27 min total |  55391.53 day sales |\n",
      "Predict | Day: 22\n",
      "##########  0.40 min round |  8.66 min total |  41214.67 day sales |\n",
      "Predict | Day: 23\n",
      "##########  0.40 min round |  9.06 min total |  37750.15 day sales |\n",
      "Predict | Day: 24\n",
      "##########  0.39 min round |  9.45 min total |  37108.34 day sales |\n",
      "Predict | Day: 25\n",
      "##########  0.40 min round |  9.85 min total |  37068.12 day sales |\n",
      "Predict | Day: 26\n",
      "##########  0.39 min round |  10.25 min total |  42044.93 day sales |\n",
      "Predict | Day: 27\n",
      "##########  0.40 min round |  10.64 min total |  50806.43 day sales |\n",
      "Predict | Day: 28\n",
      "##########  0.40 min round |  11.04 min total |  50947.18 day sales |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.781191</td>\n",
       "      <td>0.737819</td>\n",
       "      <td>0.693788</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>0.931213</td>\n",
       "      <td>1.045179</td>\n",
       "      <td>1.131295</td>\n",
       "      <td>0.977368</td>\n",
       "      <td>1.029436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853931</td>\n",
       "      <td>1.071140</td>\n",
       "      <td>1.012690</td>\n",
       "      <td>0.813684</td>\n",
       "      <td>0.837206</td>\n",
       "      <td>0.776901</td>\n",
       "      <td>0.739296</td>\n",
       "      <td>0.994093</td>\n",
       "      <td>1.058626</td>\n",
       "      <td>1.011238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.146719</td>\n",
       "      <td>0.160543</td>\n",
       "      <td>0.164092</td>\n",
       "      <td>0.162682</td>\n",
       "      <td>0.202359</td>\n",
       "      <td>0.270320</td>\n",
       "      <td>0.315719</td>\n",
       "      <td>0.248348</td>\n",
       "      <td>0.241531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196759</td>\n",
       "      <td>0.259468</td>\n",
       "      <td>0.246624</td>\n",
       "      <td>0.169012</td>\n",
       "      <td>0.173103</td>\n",
       "      <td>0.173452</td>\n",
       "      <td>0.197364</td>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.251847</td>\n",
       "      <td>0.250947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.550704</td>\n",
       "      <td>0.490335</td>\n",
       "      <td>0.493414</td>\n",
       "      <td>0.532273</td>\n",
       "      <td>0.628262</td>\n",
       "      <td>0.771446</td>\n",
       "      <td>0.726727</td>\n",
       "      <td>0.585654</td>\n",
       "      <td>0.576871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598278</td>\n",
       "      <td>0.702515</td>\n",
       "      <td>0.721026</td>\n",
       "      <td>0.549122</td>\n",
       "      <td>0.525873</td>\n",
       "      <td>0.547755</td>\n",
       "      <td>0.564779</td>\n",
       "      <td>0.652027</td>\n",
       "      <td>0.689392</td>\n",
       "      <td>0.656422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1.735303</td>\n",
       "      <td>1.339274</td>\n",
       "      <td>1.279435</td>\n",
       "      <td>1.447430</td>\n",
       "      <td>1.853449</td>\n",
       "      <td>2.891171</td>\n",
       "      <td>3.212673</td>\n",
       "      <td>1.865653</td>\n",
       "      <td>1.496920</td>\n",
       "      <td>...</td>\n",
       "      <td>1.773265</td>\n",
       "      <td>2.837330</td>\n",
       "      <td>3.426651</td>\n",
       "      <td>2.000002</td>\n",
       "      <td>1.496414</td>\n",
       "      <td>1.297739</td>\n",
       "      <td>1.404536</td>\n",
       "      <td>1.862203</td>\n",
       "      <td>3.100143</td>\n",
       "      <td>3.420127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.962112</td>\n",
       "      <td>0.896366</td>\n",
       "      <td>0.887831</td>\n",
       "      <td>0.947995</td>\n",
       "      <td>1.045938</td>\n",
       "      <td>1.611036</td>\n",
       "      <td>1.631309</td>\n",
       "      <td>0.972528</td>\n",
       "      <td>0.956437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051034</td>\n",
       "      <td>1.568430</td>\n",
       "      <td>1.608332</td>\n",
       "      <td>1.002504</td>\n",
       "      <td>0.891765</td>\n",
       "      <td>0.901244</td>\n",
       "      <td>0.852647</td>\n",
       "      <td>1.009962</td>\n",
       "      <td>1.474109</td>\n",
       "      <td>1.416456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.313053</td>\n",
       "      <td>0.299497</td>\n",
       "      <td>0.298417</td>\n",
       "      <td>0.276051</td>\n",
       "      <td>0.314564</td>\n",
       "      <td>0.363590</td>\n",
       "      <td>0.427211</td>\n",
       "      <td>0.444330</td>\n",
       "      <td>0.482609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443408</td>\n",
       "      <td>0.527926</td>\n",
       "      <td>0.634457</td>\n",
       "      <td>0.416124</td>\n",
       "      <td>0.361947</td>\n",
       "      <td>0.343189</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.319124</td>\n",
       "      <td>0.415056</td>\n",
       "      <td>0.505594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.277690</td>\n",
       "      <td>0.247147</td>\n",
       "      <td>0.230371</td>\n",
       "      <td>0.229777</td>\n",
       "      <td>0.242099</td>\n",
       "      <td>0.278417</td>\n",
       "      <td>0.305717</td>\n",
       "      <td>0.352961</td>\n",
       "      <td>0.279749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286933</td>\n",
       "      <td>0.374302</td>\n",
       "      <td>0.402373</td>\n",
       "      <td>0.286608</td>\n",
       "      <td>0.236044</td>\n",
       "      <td>0.232470</td>\n",
       "      <td>0.198073</td>\n",
       "      <td>0.200154</td>\n",
       "      <td>0.265566</td>\n",
       "      <td>0.254415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.677644</td>\n",
       "      <td>0.558143</td>\n",
       "      <td>0.492277</td>\n",
       "      <td>0.565036</td>\n",
       "      <td>0.586838</td>\n",
       "      <td>0.733219</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>1.046266</td>\n",
       "      <td>1.068431</td>\n",
       "      <td>...</td>\n",
       "      <td>1.122828</td>\n",
       "      <td>1.372197</td>\n",
       "      <td>1.507528</td>\n",
       "      <td>1.024560</td>\n",
       "      <td>0.855999</td>\n",
       "      <td>0.749650</td>\n",
       "      <td>0.666131</td>\n",
       "      <td>0.728410</td>\n",
       "      <td>0.931452</td>\n",
       "      <td>1.019991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>0.904145</td>\n",
       "      <td>0.870684</td>\n",
       "      <td>0.824765</td>\n",
       "      <td>0.771901</td>\n",
       "      <td>0.880479</td>\n",
       "      <td>1.158155</td>\n",
       "      <td>1.036926</td>\n",
       "      <td>1.130491</td>\n",
       "      <td>1.177652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961502</td>\n",
       "      <td>1.291709</td>\n",
       "      <td>1.328578</td>\n",
       "      <td>0.893950</td>\n",
       "      <td>0.895090</td>\n",
       "      <td>0.822411</td>\n",
       "      <td>0.847574</td>\n",
       "      <td>0.891789</td>\n",
       "      <td>1.038828</td>\n",
       "      <td>1.082830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.209832</td>\n",
       "      <td>0.853229</td>\n",
       "      <td>0.933898</td>\n",
       "      <td>1.249009</td>\n",
       "      <td>1.506291</td>\n",
       "      <td>2.023410</td>\n",
       "      <td>2.253091</td>\n",
       "      <td>1.901656</td>\n",
       "      <td>1.978647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.669848</td>\n",
       "      <td>2.022612</td>\n",
       "      <td>1.931924</td>\n",
       "      <td>1.404826</td>\n",
       "      <td>1.355725</td>\n",
       "      <td>1.316962</td>\n",
       "      <td>1.279496</td>\n",
       "      <td>1.605409</td>\n",
       "      <td>1.919060</td>\n",
       "      <td>1.886144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        F1        F2        F3        F4  \\\n",
       "0      HOBBIES_1_001_CA_1_validation  0.781191  0.737819  0.693788  0.670643   \n",
       "1      HOBBIES_1_002_CA_1_validation  0.146719  0.160543  0.164092  0.162682   \n",
       "2      HOBBIES_1_003_CA_1_validation  0.550704  0.490335  0.493414  0.532273   \n",
       "3      HOBBIES_1_004_CA_1_validation  1.735303  1.339274  1.279435  1.447430   \n",
       "4      HOBBIES_1_005_CA_1_validation  0.962112  0.896366  0.887831  0.947995   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "30485    FOODS_3_823_WI_3_validation  0.313053  0.299497  0.298417  0.276051   \n",
       "30486    FOODS_3_824_WI_3_validation  0.277690  0.247147  0.230371  0.229777   \n",
       "30487    FOODS_3_825_WI_3_validation  0.677644  0.558143  0.492277  0.565036   \n",
       "30488    FOODS_3_826_WI_3_validation  0.904145  0.870684  0.824765  0.771901   \n",
       "30489    FOODS_3_827_WI_3_validation  0.209832  0.853229  0.933898  1.249009   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0      0.931213  1.045179  1.131295  0.977368  1.029436  ...  0.853931   \n",
       "1      0.202359  0.270320  0.315719  0.248348  0.241531  ...  0.196759   \n",
       "2      0.628262  0.771446  0.726727  0.585654  0.576871  ...  0.598278   \n",
       "3      1.853449  2.891171  3.212673  1.865653  1.496920  ...  1.773265   \n",
       "4      1.045938  1.611036  1.631309  0.972528  0.956437  ...  1.051034   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "30485  0.314564  0.363590  0.427211  0.444330  0.482609  ...  0.443408   \n",
       "30486  0.242099  0.278417  0.305717  0.352961  0.279749  ...  0.286933   \n",
       "30487  0.586838  0.733219  0.929167  1.046266  1.068431  ...  1.122828   \n",
       "30488  0.880479  1.158155  1.036926  1.130491  1.177652  ...  0.961502   \n",
       "30489  1.506291  2.023410  2.253091  1.901656  1.978647  ...  1.669848   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0      1.071140  1.012690  0.813684  0.837206  0.776901  0.739296  0.994093   \n",
       "1      0.259468  0.246624  0.169012  0.173103  0.173452  0.197364  0.208930   \n",
       "2      0.702515  0.721026  0.549122  0.525873  0.547755  0.564779  0.652027   \n",
       "3      2.837330  3.426651  2.000002  1.496414  1.297739  1.404536  1.862203   \n",
       "4      1.568430  1.608332  1.002504  0.891765  0.901244  0.852647  1.009962   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "30485  0.527926  0.634457  0.416124  0.361947  0.343189  0.302200  0.319124   \n",
       "30486  0.374302  0.402373  0.286608  0.236044  0.232470  0.198073  0.200154   \n",
       "30487  1.372197  1.507528  1.024560  0.855999  0.749650  0.666131  0.728410   \n",
       "30488  1.291709  1.328578  0.893950  0.895090  0.822411  0.847574  0.891789   \n",
       "30489  2.022612  1.931924  1.404826  1.355725  1.316962  1.279496  1.605409   \n",
       "\n",
       "            F27       F28  \n",
       "0      1.058626  1.011238  \n",
       "1      0.251847  0.250947  \n",
       "2      0.689392  0.656422  \n",
       "3      3.100143  3.420127  \n",
       "4      1.474109  1.416456  \n",
       "...         ...       ...  \n",
       "30485  0.415056  0.505594  \n",
       "30486  0.265566  0.254415  \n",
       "30487  0.931452  1.019991  \n",
       "30488  1.038828  1.082830  \n",
       "30489  1.919060  1.886144  \n",
       "\n",
       "[30490 rows x 29 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### Predict\n",
    "#################################################################################\n",
    "\n",
    "# Create Dummy DataFrame to store predictions\n",
    "all_preds = pd.DataFrame()\n",
    "\n",
    "# Join back the Test dataset with \n",
    "# a small part of the training data \n",
    "# to make recursive features\n",
    "base_test = get_base_test()\n",
    "\n",
    "# Timer to measure predictions time \n",
    "main_time = time.time()\n",
    "\n",
    "# Loop over each prediction day\n",
    "# As rolling lags are the most timeconsuming\n",
    "# we will calculate it for whole day\n",
    "for PREDICT_DAY in range(1,29):    \n",
    "    print('Predict | Day:', PREDICT_DAY)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Make temporary grid to calculate rolling lags\n",
    "    grid_df = base_test.copy()\n",
    "    grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1)\n",
    "    # Make PCA\n",
    "    grid_df = pd.concat([grid_df, make_pca(grid_df,'id',7)], axis=1)\n",
    "    \n",
    "        \n",
    "    for store_id in STORES_IDS:\n",
    "        \n",
    "        # Read all our models and make predictions\n",
    "        # for each day/store pairs\n",
    "        model_path = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin' \n",
    "        USE_AUX = False\n",
    "        if USE_AUX:\n",
    "            model_path = AUX_MODELS + model_path\n",
    "        \n",
    "        estimator = pickle.load(open(model_path, 'rb'))\n",
    "        \n",
    "        day_mask = base_test['d']==(END_TRAIN+PREDICT_DAY)\n",
    "        store_mask = base_test['store_id']==store_id\n",
    "        \n",
    "        mask = (day_mask)&(store_mask)\n",
    "        base_test[TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
    "    \n",
    "    # Make good column naming and add \n",
    "    # to all_preds DataFrame\n",
    "    temp_df = base_test[day_mask][['id',TARGET]]\n",
    "    temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n",
    "    if 'id' in list(all_preds):\n",
    "        all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
    "    else:\n",
    "        all_preds = temp_df.copy()\n",
    "        \n",
    "    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
    "                  ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
    "                  ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
    "    del temp_df\n",
    "    \n",
    "all_preds = all_preds.reset_index(drop=True)\n",
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Export\n",
    "#################################################################################\n",
    "# Reading competition sample submission and\n",
    "# merging our predictions\n",
    "# As we have predictions only for \"_validation\" data\n",
    "# we need to do fillna() for \"_evaluation\" items\n",
    "submission = pd.read_csv(ORIGINAL+'sample_submission.csv')[['id']]\n",
    "submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
    "submission.to_csv('submission_v'+str(VER)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "\n",
    "# Of course here is no magic at all.\n",
    "# No \"Novel\" features and no brilliant ideas.\n",
    "# We just carefully joined all\n",
    "# our previous fe work and created a model.\n",
    "\n",
    "# Also!\n",
    "# In my opinion this strategy is a \"dead end\".\n",
    "# Overfits a lot LB and with 1 final submission \n",
    "# you have no option to risk.\n",
    "\n",
    "\n",
    "# Improvement should come from:\n",
    "# Loss function\n",
    "# Data representation\n",
    "# Stable CV\n",
    "# Good features reduction strategy\n",
    "# Predictions stabilization with NN\n",
    "# Trend prediction\n",
    "# Real zero sales detection/classification\n",
    "\n",
    "\n",
    "# Good kernels references \n",
    "## (the order is random and the list is not complete):\n",
    "# https://www.kaggle.com/ragnar123/simple-lgbm-groupkfold-cv\n",
    "# https://www.kaggle.com/jpmiller/grouping-items-by-stockout-pattern\n",
    "# https://www.kaggle.com/headsortails/back-to-predict-the-future-interactive-m5-eda\n",
    "# https://www.kaggle.com/sibmike/m5-out-of-stock-feature\n",
    "# https://www.kaggle.com/mayer79/m5-forecast-attack-of-the-data-table\n",
    "# https://www.kaggle.com/yassinealouini/seq2seq\n",
    "# https://www.kaggle.com/kailex/m5-forecaster-v2\n",
    "# https://www.kaggle.com/aerdem4/m5-lofo-importance-on-gpu-via-rapids-xgboost\n",
    "\n",
    "\n",
    "# Features were created in these kernels:\n",
    "## \n",
    "# Mean encodings and PCA options\n",
    "# https://www.kaggle.com/kyakovlev/m5-custom-features\n",
    "##\n",
    "# Lags and rolling lags\n",
    "# https://www.kaggle.com/kyakovlev/m5-lags-features\n",
    "##\n",
    "# Base Grid and base features (calendar/price/etc)\n",
    "# https://www.kaggle.com/kyakovlev/m5-simple-fe\n",
    "\n",
    "\n",
    "# Personal request\n",
    "# Please don't upvote any ensemble and copypaste kernels\n",
    "## The worst case is ensemble without any analyse.\n",
    "## The best choice - just ignore it.\n",
    "## I would like to see more kernels with interesting and original approaches.\n",
    "## Don't feed copypasters with upvotes.\n",
    "\n",
    "## It doesn't mean that you should not fork and improve others kernels\n",
    "## but I would like to see params and code tuning based on some CV and analyse\n",
    "## and not only on LB probing.\n",
    "## Small changes could be shared in comments and authors can improve their kernel.\n",
    "\n",
    "## Feel free to criticize this kernel as my knowlege is very limited\n",
    "## and I can be wrong in code and descriptions. \n",
    "## Thank you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
