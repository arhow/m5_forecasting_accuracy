{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from module.prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "END_TRAIN = 1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEMP_FEATURE_PKL):\n",
    "    train_df = pd.read_csv(f'{ORI_CSV_PATH}/sales_train_evaluation.csv')\n",
    "#     train_df = train_df[train_df['id'].isin(IDS[:100])]\n",
    "    prices_df = pd.read_csv(f'{ORI_CSV_PATH}/sell_prices.csv')\n",
    "    calendar_df = pd.read_csv(f'{ORI_CSV_PATH}/calendar.csv')\n",
    "    try:\n",
    "        if not os.path.exists(BASE_PATH):\n",
    "            os.makedirs(BASE_PATH)\n",
    "    except OSError:\n",
    "        print(\"Creation of the directory %s failed\" % BASE_PATH)\n",
    "    else:\n",
    "        print(\"Successfully created the directory %s\" % BASE_PATH)\n",
    "\n",
    "    grid_df = extract_features(train_df, prices_df, calendar_df, target=TARGET, nan_mask_d=1913+28)\n",
    "    \n",
    "    grid_df['item_id'] = grid_df['item_id'].astype('category')\n",
    "    grid_df['dept_id'] = grid_df['dept_id'].astype('category')\n",
    "    grid_df['cat_id'] = grid_df['cat_id'].astype('category')\n",
    "#     grid_df['item_id'] = grid_df['item_id'].apply(lambda x: int(x.split('_')[-1])).astype('category')\n",
    "#     grid_df['dept_id'] = grid_df['dept_id'].apply(lambda x: int(x.split('_')[-1])).astype('category')\n",
    "#     grid_df['cat_id'] = grid_df['cat_id'].replace({'HOBBIES': 0, 'HOUSEHOLD': 1, 'FOODS': 2}).astype('category')\n",
    "#     for col in ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']:\n",
    "#         grid_df[col] = grid_df[col].replace(\n",
    "#             dict(zip(grid_df[col].unique(), np.arange(grid_df[col].unique().shape[0])))).astype('category')\n",
    "    grid_df = reduce_mem_usage(grid_df)\n",
    "    grid_df.to_pickle(TEMP_FEATURE_PKL)\n",
    "    del grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.catboost_baseline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_cols = dict(zip(STORES_IDS, [M5_FEATURES]*len(STORES_IDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {'iterations': 1400,\n",
    " 'loss_function': 'Tweedie:variance_power=1.1',\n",
    " 'eval_metric': 'Tweedie:variance_power=1.1',\n",
    " 'subsample': 0.5,\n",
    " 'learning_rate': 0.18,\n",
    " 'random_strength': 0.5,\n",
    " 'depth': 6,\n",
    " 'verbose': 1,\n",
    " 'random_seed': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_name_1 category 0\n",
      "event_type_1 category 0\n",
      "event_name_2 category 0\n",
      "event_type_2 category 0\n"
     ]
    }
   ],
   "source": [
    "grid_df = pd.read_pickle(TEMP_FEATURE_PKL)\n",
    "for col in ['item_id','dept_id','cat_id','event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']:\n",
    "    n_nan = grid_df[col].isna().sum()\n",
    "    if n_nan > 0:\n",
    "        grid_df[col] = grid_df[col].astype(str).fillna('NONE').astype('category')\n",
    "        print(col, grid_df[col].dtype, grid_df[col].isna().sum())\n",
    "grid_df.to_pickle(TEMP_FEATURE_PKL)\n",
    "del grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_1\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train CA_2\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train CA_3\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train CA_4\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train TX_1\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train TX_2\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n"
     ]
    }
   ],
   "source": [
    "history_df = train_evaluate_model(useful_cols, TARGET, BASE_PATH)#stores_ids=['CA_1']\n",
    "print(history_df.rmse_trn.mean(), history_df.rmse_val.mean(), history_df.rmse_diff.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.to_pickle(f'{BASE_PATH}/catboost_history_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_1\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train CA_2\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train CA_3\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train CA_4\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train TX_1\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train TX_2\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train TX_3\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train WI_1\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train WI_2\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Train WI_3\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "1.815833035880111 2.329853734094095 0.5140206982139836\n"
     ]
    }
   ],
   "source": [
    "history_df = train_evaluate_model(useful_cols, TARGET, BASE_PATH)#stores_ids=['CA_1']\n",
    "print(history_df.rmse_trn.mean(), history_df.rmse_val.mean(), history_df.rmse_diff.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD0 Predict | Day:1\n"
     ]
    }
   ],
   "source": [
    "final_all_preds = predict_test(useful_cols, TARGET, BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
